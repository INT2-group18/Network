{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuiepDWOGyAWXuHqjaiXU9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/INT2-group18/Network/blob/main/INT2-NeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LWLZiIRvMfzp",
        "outputId": "074cd48c-bf65-4f86-900b-a029a93a507b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 344862509/344862509 [00:09<00:00, 35096972.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 502/502 [00:00<00:00, 681846.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14989/14989 [00:00<00:00, 10596396.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.1, inplace=False)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv5): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (conv6): Sequential(\n",
            "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (conv7): Sequential(\n",
            "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv8): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (conv9): Sequential(\n",
            "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc1): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (fc2): Sequential(\n",
            "    (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (fc3): Sequential(\n",
            "    (0): Linear(in_features=4096, out_features=102, bias=True)\n",
            "  )\n",
            ")\n",
            "Epoch [1/80], Step [16/32], Step Loss: 4.9541\n",
            "Epoch [1/80], Step [32/32], Step Loss: 4.8033\n",
            "Epoch [1/80], Validation Accuracy: 0.98%\n",
            "Epoch [2/80], Step [16/32], Step Loss: 4.7528\n",
            "Epoch [2/80], Step [32/32], Step Loss: 4.7489\n",
            "Epoch [2/80], Validation Accuracy: 2.75%\n",
            "Epoch [3/80], Step [16/32], Step Loss: 4.5649\n",
            "Epoch [3/80], Step [32/32], Step Loss: 4.6591\n",
            "Epoch [3/80], Validation Accuracy: 2.84%\n",
            "Epoch [4/80], Step [16/32], Step Loss: 4.4842\n",
            "Epoch [4/80], Step [32/32], Step Loss: 4.4513\n",
            "Epoch [4/80], Validation Accuracy: 3.33%\n",
            "Epoch [5/80], Step [16/32], Step Loss: 4.5077\n",
            "Epoch [5/80], Step [32/32], Step Loss: 4.2792\n",
            "Epoch [5/80], Validation Accuracy: 2.55%\n",
            "Epoch [6/80], Step [16/32], Step Loss: 4.1757\n",
            "Epoch [6/80], Step [32/32], Step Loss: 4.3642\n",
            "Epoch [6/80], Validation Accuracy: 4.22%\n",
            "Epoch [7/80], Step [16/32], Step Loss: 4.2217\n",
            "Epoch [7/80], Step [32/32], Step Loss: 4.4785\n",
            "Epoch [7/80], Validation Accuracy: 4.61%\n",
            "Epoch [8/80], Step [16/32], Step Loss: 4.4356\n",
            "Epoch [8/80], Step [32/32], Step Loss: 4.3183\n",
            "Epoch [8/80], Validation Accuracy: 6.76%\n",
            "Epoch [9/80], Step [16/32], Step Loss: 4.3199\n",
            "Epoch [9/80], Step [32/32], Step Loss: 4.2509\n",
            "Epoch [9/80], Validation Accuracy: 5.10%\n",
            "Epoch [10/80], Step [16/32], Step Loss: 4.2908\n",
            "Epoch [10/80], Step [32/32], Step Loss: 4.0178\n",
            "Epoch [10/80], Validation Accuracy: 6.08%\n",
            "Epoch [11/80], Step [16/32], Step Loss: 3.8630\n",
            "Epoch [11/80], Step [32/32], Step Loss: 4.0378\n",
            "Epoch [11/80], Validation Accuracy: 6.86%\n",
            "Epoch [12/80], Step [16/32], Step Loss: 3.6891\n",
            "Epoch [12/80], Step [32/32], Step Loss: 3.9538\n",
            "Epoch [12/80], Validation Accuracy: 8.24%\n",
            "Epoch [13/80], Step [16/32], Step Loss: 3.8462\n",
            "Epoch [13/80], Step [32/32], Step Loss: 4.1709\n",
            "Epoch [13/80], Validation Accuracy: 8.73%\n",
            "Epoch [14/80], Step [16/32], Step Loss: 4.0127\n",
            "Epoch [14/80], Step [32/32], Step Loss: 3.7930\n",
            "Epoch [14/80], Validation Accuracy: 11.86%\n",
            "Epoch [15/80], Step [16/32], Step Loss: 3.7728\n",
            "Epoch [15/80], Step [32/32], Step Loss: 3.2661\n",
            "Epoch [15/80], Validation Accuracy: 13.14%\n",
            "Epoch [16/80], Step [16/32], Step Loss: 3.6627\n",
            "Epoch [16/80], Step [32/32], Step Loss: 3.8672\n",
            "Epoch [16/80], Validation Accuracy: 12.75%\n",
            "Epoch [17/80], Step [16/32], Step Loss: 3.2794\n",
            "Epoch [17/80], Step [32/32], Step Loss: 3.4133\n",
            "Epoch [17/80], Validation Accuracy: 13.53%\n",
            "Epoch [18/80], Step [16/32], Step Loss: 3.5261\n",
            "Epoch [18/80], Step [32/32], Step Loss: 3.6720\n",
            "Epoch [18/80], Validation Accuracy: 14.22%\n",
            "Epoch [19/80], Step [16/32], Step Loss: 3.5287\n",
            "Epoch [19/80], Step [32/32], Step Loss: 3.5172\n",
            "Epoch [19/80], Validation Accuracy: 15.59%\n",
            "Epoch [20/80], Step [16/32], Step Loss: 3.0460\n",
            "Epoch [20/80], Step [32/32], Step Loss: 3.2510\n",
            "Epoch [20/80], Validation Accuracy: 16.18%\n",
            "Epoch [21/80], Step [16/32], Step Loss: 3.3036\n",
            "Epoch [21/80], Step [32/32], Step Loss: 3.4843\n",
            "Epoch [21/80], Validation Accuracy: 19.02%\n",
            "Epoch [22/80], Step [16/32], Step Loss: 2.8553\n",
            "Epoch [22/80], Step [32/32], Step Loss: 3.3833\n",
            "Epoch [22/80], Validation Accuracy: 18.14%\n",
            "Epoch [23/80], Step [16/32], Step Loss: 3.1189\n",
            "Epoch [23/80], Step [32/32], Step Loss: 2.9687\n",
            "Epoch [23/80], Validation Accuracy: 19.41%\n",
            "Epoch [24/80], Step [16/32], Step Loss: 2.8577\n",
            "Epoch [24/80], Step [32/32], Step Loss: 3.0192\n",
            "Epoch [24/80], Validation Accuracy: 19.51%\n",
            "Epoch [25/80], Step [16/32], Step Loss: 3.3903\n",
            "Epoch [25/80], Step [32/32], Step Loss: 2.8580\n",
            "Epoch [25/80], Validation Accuracy: 18.73%\n",
            "Epoch [26/80], Step [16/32], Step Loss: 2.4805\n",
            "Epoch [26/80], Step [32/32], Step Loss: 3.0757\n",
            "Epoch [26/80], Validation Accuracy: 20.49%\n",
            "Epoch [27/80], Step [16/32], Step Loss: 2.2650\n",
            "Epoch [27/80], Step [32/32], Step Loss: 2.6008\n",
            "Epoch [27/80], Validation Accuracy: 21.47%\n",
            "Epoch [28/80], Step [16/32], Step Loss: 2.9035\n",
            "Epoch [28/80], Step [32/32], Step Loss: 2.7777\n",
            "Epoch [28/80], Validation Accuracy: 21.27%\n",
            "Epoch [29/80], Step [16/32], Step Loss: 2.7669\n",
            "Epoch [29/80], Step [32/32], Step Loss: 2.3975\n",
            "Epoch [29/80], Validation Accuracy: 24.22%\n",
            "Epoch [30/80], Step [16/32], Step Loss: 2.4490\n",
            "Epoch [30/80], Step [32/32], Step Loss: 3.0768\n",
            "Epoch [30/80], Validation Accuracy: 23.24%\n",
            "Epoch [31/80], Step [16/32], Step Loss: 2.3702\n",
            "Epoch [31/80], Step [32/32], Step Loss: 2.8227\n",
            "Epoch [31/80], Validation Accuracy: 26.08%\n",
            "Epoch [32/80], Step [16/32], Step Loss: 2.8216\n",
            "Epoch [32/80], Step [32/32], Step Loss: 2.3385\n",
            "Epoch [32/80], Validation Accuracy: 26.76%\n",
            "Epoch [33/80], Step [16/32], Step Loss: 2.2747\n",
            "Epoch [33/80], Step [32/32], Step Loss: 1.7396\n",
            "Epoch [33/80], Validation Accuracy: 27.06%\n",
            "Epoch [34/80], Step [16/32], Step Loss: 2.3765\n",
            "Epoch [34/80], Step [32/32], Step Loss: 2.2181\n",
            "Epoch [34/80], Validation Accuracy: 26.08%\n",
            "Epoch [35/80], Step [16/32], Step Loss: 2.1636\n",
            "Epoch [35/80], Step [32/32], Step Loss: 2.2471\n",
            "Epoch [35/80], Validation Accuracy: 24.22%\n",
            "Epoch [36/80], Step [16/32], Step Loss: 2.1044\n",
            "Epoch [36/80], Step [32/32], Step Loss: 1.8556\n",
            "Epoch [36/80], Validation Accuracy: 28.24%\n",
            "Epoch [37/80], Step [16/32], Step Loss: 2.0908\n",
            "Epoch [37/80], Step [32/32], Step Loss: 2.3149\n",
            "Epoch [37/80], Validation Accuracy: 28.24%\n",
            "Epoch [38/80], Step [16/32], Step Loss: 1.9288\n",
            "Epoch [38/80], Step [32/32], Step Loss: 2.3264\n",
            "Epoch [38/80], Validation Accuracy: 28.43%\n",
            "Epoch [39/80], Step [16/32], Step Loss: 2.4198\n",
            "Epoch [39/80], Step [32/32], Step Loss: 2.4852\n",
            "Epoch [39/80], Validation Accuracy: 29.90%\n",
            "Epoch [40/80], Step [16/32], Step Loss: 1.4817\n",
            "Epoch [40/80], Step [32/32], Step Loss: 2.6086\n",
            "Epoch [40/80], Validation Accuracy: 29.41%\n",
            "Epoch [41/80], Step [16/32], Step Loss: 1.6868\n",
            "Epoch [41/80], Step [32/32], Step Loss: 2.4420\n",
            "Epoch [41/80], Validation Accuracy: 29.80%\n",
            "Epoch [42/80], Step [16/32], Step Loss: 1.7985\n",
            "Epoch [42/80], Step [32/32], Step Loss: 2.0402\n",
            "Epoch [42/80], Validation Accuracy: 25.88%\n",
            "Epoch [43/80], Step [16/32], Step Loss: 1.7986\n",
            "Epoch [43/80], Step [32/32], Step Loss: 1.6156\n",
            "Epoch [43/80], Validation Accuracy: 29.90%\n",
            "Epoch [44/80], Step [16/32], Step Loss: 1.5138\n",
            "Epoch [44/80], Step [32/32], Step Loss: 1.7260\n",
            "Epoch [44/80], Validation Accuracy: 30.88%\n",
            "Epoch [45/80], Step [16/32], Step Loss: 1.6506\n",
            "Epoch [45/80], Step [32/32], Step Loss: 2.2720\n",
            "Epoch [45/80], Validation Accuracy: 30.88%\n",
            "Epoch [46/80], Step [16/32], Step Loss: 1.5888\n",
            "Epoch [46/80], Step [32/32], Step Loss: 1.2343\n",
            "Epoch [46/80], Validation Accuracy: 31.96%\n",
            "Epoch [47/80], Step [16/32], Step Loss: 1.7951\n",
            "Epoch [47/80], Step [32/32], Step Loss: 1.7709\n",
            "Epoch [47/80], Validation Accuracy: 30.78%\n",
            "Epoch [48/80], Step [16/32], Step Loss: 1.4862\n",
            "Epoch [48/80], Step [32/32], Step Loss: 2.1869\n",
            "Epoch [48/80], Validation Accuracy: 31.76%\n",
            "Epoch [49/80], Step [16/32], Step Loss: 1.1623\n",
            "Epoch [49/80], Step [32/32], Step Loss: 1.7679\n",
            "Epoch [49/80], Validation Accuracy: 32.06%\n",
            "Epoch [50/80], Step [16/32], Step Loss: 1.5736\n",
            "Epoch [50/80], Step [32/32], Step Loss: 1.5330\n",
            "Epoch [50/80], Validation Accuracy: 33.04%\n",
            "Epoch [51/80], Step [16/32], Step Loss: 1.4542\n",
            "Epoch [51/80], Step [32/32], Step Loss: 1.2789\n",
            "Epoch [51/80], Validation Accuracy: 34.22%\n",
            "Epoch [52/80], Step [16/32], Step Loss: 1.3139\n",
            "Epoch [52/80], Step [32/32], Step Loss: 1.9965\n",
            "Epoch [52/80], Validation Accuracy: 31.18%\n",
            "Epoch [53/80], Step [16/32], Step Loss: 1.5921\n",
            "Epoch [53/80], Step [32/32], Step Loss: 1.4752\n",
            "Epoch [53/80], Validation Accuracy: 32.25%\n",
            "Epoch [54/80], Step [16/32], Step Loss: 1.3515\n",
            "Epoch [54/80], Step [32/32], Step Loss: 1.2820\n",
            "Epoch [54/80], Validation Accuracy: 32.94%\n",
            "Epoch [55/80], Step [16/32], Step Loss: 1.3002\n",
            "Epoch [55/80], Step [32/32], Step Loss: 0.9889\n",
            "Epoch [55/80], Validation Accuracy: 33.73%\n",
            "Epoch [56/80], Step [16/32], Step Loss: 1.1076\n",
            "Epoch [56/80], Step [32/32], Step Loss: 1.1164\n",
            "Epoch [56/80], Validation Accuracy: 32.35%\n",
            "Epoch [57/80], Step [16/32], Step Loss: 0.9191\n",
            "Epoch [57/80], Step [32/32], Step Loss: 1.4918\n",
            "Epoch [57/80], Validation Accuracy: 33.24%\n",
            "Epoch [58/80], Step [16/32], Step Loss: 0.9468\n",
            "Epoch [58/80], Step [32/32], Step Loss: 1.2659\n",
            "Epoch [58/80], Validation Accuracy: 34.31%\n",
            "Epoch [59/80], Step [16/32], Step Loss: 1.4691\n",
            "Epoch [59/80], Step [32/32], Step Loss: 1.2536\n",
            "Epoch [59/80], Validation Accuracy: 36.08%\n",
            "Epoch [60/80], Step [16/32], Step Loss: 0.9664\n",
            "Epoch [60/80], Step [32/32], Step Loss: 1.2008\n",
            "Epoch [60/80], Validation Accuracy: 36.57%\n",
            "Epoch [61/80], Step [16/32], Step Loss: 1.0148\n",
            "Epoch [61/80], Step [32/32], Step Loss: 1.1683\n",
            "Epoch [61/80], Validation Accuracy: 35.29%\n",
            "Epoch [62/80], Step [16/32], Step Loss: 0.7604\n",
            "Epoch [62/80], Step [32/32], Step Loss: 1.0395\n",
            "Epoch [62/80], Validation Accuracy: 34.31%\n",
            "Epoch [63/80], Step [16/32], Step Loss: 0.8580\n",
            "Epoch [63/80], Step [32/32], Step Loss: 0.7992\n",
            "Epoch [63/80], Validation Accuracy: 35.39%\n",
            "Epoch [64/80], Step [16/32], Step Loss: 0.9045\n",
            "Epoch [64/80], Step [32/32], Step Loss: 0.6301\n",
            "Epoch [64/80], Validation Accuracy: 35.39%\n",
            "Epoch [65/80], Step [16/32], Step Loss: 0.9832\n",
            "Epoch [65/80], Step [32/32], Step Loss: 1.1018\n",
            "Epoch [65/80], Validation Accuracy: 35.59%\n",
            "Epoch [66/80], Step [16/32], Step Loss: 1.0222\n",
            "Epoch [66/80], Step [32/32], Step Loss: 1.0268\n",
            "Epoch [66/80], Validation Accuracy: 36.86%\n",
            "Epoch [67/80], Step [16/32], Step Loss: 0.9978\n",
            "Epoch [67/80], Step [32/32], Step Loss: 1.4399\n",
            "Epoch [67/80], Validation Accuracy: 37.06%\n",
            "Epoch [68/80], Step [16/32], Step Loss: 0.8287\n",
            "Epoch [68/80], Step [32/32], Step Loss: 0.9210\n",
            "Epoch [68/80], Validation Accuracy: 37.75%\n",
            "Epoch [69/80], Step [16/32], Step Loss: 0.7228\n",
            "Epoch [69/80], Step [32/32], Step Loss: 0.9591\n",
            "Epoch [69/80], Validation Accuracy: 38.63%\n",
            "Epoch [70/80], Step [16/32], Step Loss: 0.7328\n",
            "Epoch [70/80], Step [32/32], Step Loss: 0.9644\n",
            "Epoch [70/80], Validation Accuracy: 37.25%\n",
            "Epoch [71/80], Step [16/32], Step Loss: 0.9344\n",
            "Epoch [71/80], Step [32/32], Step Loss: 0.7127\n",
            "Epoch [71/80], Validation Accuracy: 37.06%\n",
            "Epoch [72/80], Step [16/32], Step Loss: 0.9094\n",
            "Epoch [72/80], Step [32/32], Step Loss: 0.9619\n",
            "Epoch [72/80], Validation Accuracy: 37.45%\n",
            "Epoch [73/80], Step [16/32], Step Loss: 0.5785\n",
            "Epoch [73/80], Step [32/32], Step Loss: 0.6018\n",
            "Epoch [73/80], Validation Accuracy: 37.16%\n",
            "Epoch [74/80], Step [16/32], Step Loss: 1.0379\n",
            "Epoch [74/80], Step [32/32], Step Loss: 0.7442\n",
            "Epoch [74/80], Validation Accuracy: 35.88%\n",
            "Epoch [75/80], Step [16/32], Step Loss: 0.4296\n",
            "Epoch [75/80], Step [32/32], Step Loss: 0.6288\n",
            "Epoch [75/80], Validation Accuracy: 36.18%\n",
            "Epoch [76/80], Step [16/32], Step Loss: 0.7148\n",
            "Epoch [76/80], Step [32/32], Step Loss: 0.9896\n",
            "Epoch [76/80], Validation Accuracy: 39.12%\n",
            "Epoch [77/80], Step [16/32], Step Loss: 0.6170\n",
            "Epoch [77/80], Step [32/32], Step Loss: 0.7976\n",
            "Epoch [77/80], Validation Accuracy: 36.08%\n",
            "Epoch [78/80], Step [16/32], Step Loss: 0.4362\n",
            "Epoch [78/80], Step [32/32], Step Loss: 0.6109\n",
            "Epoch [78/80], Validation Accuracy: 38.04%\n",
            "Epoch [79/80], Step [16/32], Step Loss: 0.6317\n",
            "Epoch [79/80], Step [32/32], Step Loss: 1.0368\n",
            "Epoch [79/80], Validation Accuracy: 36.08%\n",
            "Epoch [80/80], Step [16/32], Step Loss: 0.8509\n",
            "Epoch [80/80], Step [32/32], Step Loss: 0.6637\n",
            "Epoch [80/80], Validation Accuracy: 38.24%\n",
            "Training Complete in: 00h 49m 51s\n"
          ]
        }
      ],
      "source": [
        "import torch, time, gc\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as grid\n",
        "\n",
        "# Setup device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "SAVE_PATH = \"./neural_net.pth\"\n",
        "\n",
        "# Training variables\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 80\n",
        "LEARNING_RATE = 0.00005\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256, antialias=True),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
        "    transforms.RandomGrayscale(p=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the train and test datasets\n",
        "train_dataset = datasets.Flowers102(root=\"./data\", split=\"train\", transform=transform, download=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "test_dataset = datasets.Flowers102(root=\"./data\", split=\"test\", transform=transform, download=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "val_dataset = datasets.Flowers102(root=\"./data\", split=\"val\", transform=transform, download=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "val_accuracies = []\n",
        "\n",
        "\n",
        "# Define the CNN architecture\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(64),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2)) # 224 -> 112\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(128),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.Dropout(p=0.1),\n",
        "                                   nn.MaxPool2d(2, 2)) # 112 -> 56\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(128),\n",
        "                                   nn.ReLU())\n",
        "        self.conv4 = nn.Sequential(nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(128),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2)) # 56 -> 28\n",
        "        self.conv5 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(256),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.Dropout(p=0.1))\n",
        "        self.conv6 = nn.Sequential(nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(256),\n",
        "                                   nn.ReLU())\n",
        "        self.conv7 = nn.Sequential(nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(256),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2)) # 28 -> 14\n",
        "        self.conv8 = nn.Sequential(nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(512),\n",
        "                                   nn.ReLU())\n",
        "        self.conv9 = nn.Sequential(nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(512),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2)) # 14 -> 7\n",
        "        self.fc1 = nn.Sequential(nn.Linear(7 * 7 * 512, 4096),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Dropout(0.5))\n",
        "        self.fc2 = nn.Sequential(nn.Linear(4096, 4096),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Dropout(0.5))\n",
        "        self.fc3 = nn.Sequential(nn.Linear(4096, 102))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.conv6(x)\n",
        "        x = self.conv7(x)\n",
        "        x = self.conv8(x)\n",
        "        x = self.conv9(x)\n",
        "        x = x.view(-1, 7 * 7 * 512)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Clear cuda cache\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Create an instance of the CNN and move it to the device\n",
        "cnn = CNN().to(device)\n",
        "print(cnn)\n",
        "\n",
        "# Define the loss function and the optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cnn.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Setup timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the CNN\n",
        "for epoch in range(EPOCHS):\n",
        "    cnn.train()\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        labels = torch.eye(102)[labels] # one hot encode\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = cnn(images) # train\n",
        "        labels = torch.argmax(labels, dim=1) # one hot decode\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 16 == 0:\n",
        "            print(f\"Epoch [{epoch + 1}/{EPOCHS}], Step [{i + 1}/{len(train_loader)}], Step Loss: {loss.item():.4f}\")\n",
        "\n",
        "    # Evaluate model after each training epoch\n",
        "    cnn.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = cnn(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f'Epoch [{epoch+1}/{EPOCHS}], Validation Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "    # save accuracy\n",
        "    val_accuracies.append(accuracy)\n",
        "\n",
        "# Output time taken to train\n",
        "end_time = time.time()\n",
        "print(\"Training Complete in: \" + time.strftime(\"%Hh %Mm %Ss\", time.gmtime(end_time - start_time)))"
      ]
    }
  ]
}