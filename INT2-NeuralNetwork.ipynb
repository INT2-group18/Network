{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LWLZiIRvMfzp",
        "outputId": "f8dde15f-2031-4456-a2ef-823b2663831a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv5): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (conv6): Sequential(\n",
            "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (conv7): Sequential(\n",
            "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv8): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (conv9): Sequential(\n",
            "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc1): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (fc2): Sequential(\n",
            "    (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "  )\n",
            "  (fc3): Sequential(\n",
            "    (0): Linear(in_features=4096, out_features=102, bias=True)\n",
            "  )\n",
            ")\n",
            "Epoch [1/300], Step [16/32], Step Loss: 4.6480\n",
            "Epoch [1/300], Step [32/32], Step Loss: 4.6459\n",
            "Training accuracy: 1.37%\n",
            "Epoch [1/300], Validation Accuracy: 1.76%\n",
            "Epoch [2/300], Step [16/32], Step Loss: 4.5263\n",
            "Epoch [2/300], Step [32/32], Step Loss: 4.5176\n",
            "Training accuracy: 6.86%\n",
            "Epoch [2/300], Validation Accuracy: 5.59%\n",
            "Epoch [3/300], Step [16/32], Step Loss: 4.2995\n",
            "Epoch [3/300], Step [32/32], Step Loss: 4.2923\n",
            "Training accuracy: 13.82%\n",
            "Epoch [3/300], Validation Accuracy: 11.57%\n",
            "Epoch [4/300], Step [16/32], Step Loss: 4.2492\n",
            "Epoch [4/300], Step [32/32], Step Loss: 4.1540\n",
            "Training accuracy: 19.41%\n",
            "Epoch [4/300], Validation Accuracy: 15.88%\n",
            "Epoch [5/300], Step [16/32], Step Loss: 3.9402\n",
            "Epoch [5/300], Step [32/32], Step Loss: 3.8100\n",
            "Training accuracy: 30.29%\n",
            "Epoch [5/300], Validation Accuracy: 15.88%\n",
            "Epoch [6/300], Step [16/32], Step Loss: 3.7059\n",
            "Epoch [6/300], Step [32/32], Step Loss: 3.4876\n",
            "Training accuracy: 34.02%\n",
            "Epoch [6/300], Validation Accuracy: 19.90%\n",
            "Epoch [7/300], Step [16/32], Step Loss: 3.3867\n",
            "Epoch [7/300], Step [32/32], Step Loss: 3.5752\n",
            "Training accuracy: 41.08%\n",
            "Epoch [7/300], Validation Accuracy: 21.08%\n",
            "Epoch [8/300], Step [16/32], Step Loss: 3.1678\n",
            "Epoch [8/300], Step [32/32], Step Loss: 3.3931\n",
            "Training accuracy: 45.39%\n",
            "Epoch [8/300], Validation Accuracy: 22.84%\n",
            "Epoch [9/300], Step [16/32], Step Loss: 2.8617\n",
            "Epoch [9/300], Step [32/32], Step Loss: 2.9256\n",
            "Training accuracy: 54.71%\n",
            "Epoch [9/300], Validation Accuracy: 25.10%\n",
            "Epoch [10/300], Step [16/32], Step Loss: 2.7503\n",
            "Epoch [10/300], Step [32/32], Step Loss: 2.4489\n",
            "Training accuracy: 56.67%\n",
            "Epoch [10/300], Validation Accuracy: 26.47%\n",
            "Epoch [11/300], Step [16/32], Step Loss: 2.2414\n",
            "Epoch [11/300], Step [32/32], Step Loss: 2.4243\n",
            "Training accuracy: 62.55%\n",
            "Epoch [11/300], Validation Accuracy: 27.55%\n",
            "Epoch [12/300], Step [16/32], Step Loss: 2.2723\n",
            "Epoch [12/300], Step [32/32], Step Loss: 2.5094\n",
            "Training accuracy: 67.94%\n",
            "Epoch [12/300], Validation Accuracy: 29.61%\n",
            "Epoch [13/300], Step [16/32], Step Loss: 2.0461\n",
            "Epoch [13/300], Step [32/32], Step Loss: 2.3214\n",
            "Training accuracy: 72.75%\n",
            "Epoch [13/300], Validation Accuracy: 30.69%\n",
            "Epoch [14/300], Step [16/32], Step Loss: 1.8507\n",
            "Epoch [14/300], Step [32/32], Step Loss: 2.0643\n",
            "Training accuracy: 75.88%\n",
            "Epoch [14/300], Validation Accuracy: 29.90%\n",
            "Epoch [15/300], Step [16/32], Step Loss: 1.7819\n",
            "Epoch [15/300], Step [32/32], Step Loss: 1.7525\n",
            "Training accuracy: 78.82%\n",
            "Epoch [15/300], Validation Accuracy: 32.06%\n",
            "Epoch [16/300], Step [16/32], Step Loss: 1.5960\n",
            "Epoch [16/300], Step [32/32], Step Loss: 1.4668\n",
            "Training accuracy: 84.22%\n",
            "Epoch [16/300], Validation Accuracy: 32.55%\n",
            "Epoch [17/300], Step [16/32], Step Loss: 1.8027\n",
            "Epoch [17/300], Step [32/32], Step Loss: 1.2353\n",
            "Training accuracy: 84.41%\n",
            "Epoch [17/300], Validation Accuracy: 32.65%\n",
            "Epoch [18/300], Step [16/32], Step Loss: 1.4179\n",
            "Epoch [18/300], Step [32/32], Step Loss: 1.3733\n",
            "Training accuracy: 85.88%\n",
            "Epoch [18/300], Validation Accuracy: 33.43%\n",
            "Epoch [19/300], Step [16/32], Step Loss: 0.9538\n",
            "Epoch [19/300], Step [32/32], Step Loss: 1.1432\n",
            "Training accuracy: 89.90%\n",
            "Epoch [19/300], Validation Accuracy: 34.31%\n",
            "Epoch [20/300], Step [16/32], Step Loss: 0.9548\n",
            "Epoch [20/300], Step [32/32], Step Loss: 1.0744\n",
            "Training accuracy: 90.69%\n",
            "Epoch [20/300], Validation Accuracy: 35.10%\n",
            "Epoch [21/300], Step [16/32], Step Loss: 0.8664\n",
            "Epoch [21/300], Step [32/32], Step Loss: 1.1754\n",
            "Training accuracy: 93.33%\n",
            "Epoch [21/300], Validation Accuracy: 35.39%\n",
            "Epoch [22/300], Step [16/32], Step Loss: 0.8056\n",
            "Epoch [22/300], Step [32/32], Step Loss: 0.8162\n",
            "Training accuracy: 94.12%\n",
            "Epoch [22/300], Validation Accuracy: 35.00%\n",
            "Epoch [23/300], Step [16/32], Step Loss: 0.8560\n",
            "Epoch [23/300], Step [32/32], Step Loss: 0.7950\n",
            "Training accuracy: 95.20%\n",
            "Epoch [23/300], Validation Accuracy: 36.18%\n",
            "Epoch [24/300], Step [16/32], Step Loss: 0.6677\n",
            "Epoch [24/300], Step [32/32], Step Loss: 0.6482\n",
            "Training accuracy: 96.27%\n",
            "Epoch [24/300], Validation Accuracy: 37.06%\n",
            "Epoch [25/300], Step [16/32], Step Loss: 0.6560\n",
            "Epoch [25/300], Step [32/32], Step Loss: 0.6433\n",
            "Training accuracy: 97.06%\n",
            "Epoch [25/300], Validation Accuracy: 35.88%\n",
            "Epoch [26/300], Step [16/32], Step Loss: 0.5760\n",
            "Epoch [26/300], Step [32/32], Step Loss: 0.6025\n",
            "Training accuracy: 97.94%\n",
            "Epoch [26/300], Validation Accuracy: 37.84%\n",
            "Epoch [27/300], Step [16/32], Step Loss: 0.5989\n",
            "Epoch [27/300], Step [32/32], Step Loss: 0.4683\n",
            "Training accuracy: 98.63%\n",
            "Epoch [27/300], Validation Accuracy: 38.04%\n",
            "Epoch [28/300], Step [16/32], Step Loss: 0.3297\n",
            "Epoch [28/300], Step [32/32], Step Loss: 0.4283\n",
            "Training accuracy: 98.73%\n",
            "Epoch [28/300], Validation Accuracy: 37.84%\n",
            "Epoch [29/300], Step [16/32], Step Loss: 0.3476\n",
            "Epoch [29/300], Step [32/32], Step Loss: 0.2701\n",
            "Training accuracy: 99.41%\n",
            "Epoch [29/300], Validation Accuracy: 38.14%\n",
            "Epoch [30/300], Step [16/32], Step Loss: 0.3002\n",
            "Epoch [30/300], Step [32/32], Step Loss: 0.3218\n",
            "Training accuracy: 99.61%\n",
            "Epoch [30/300], Validation Accuracy: 38.24%\n",
            "Epoch [31/300], Step [16/32], Step Loss: 0.2899\n",
            "Epoch [31/300], Step [32/32], Step Loss: 0.7058\n",
            "Training accuracy: 99.22%\n",
            "Epoch [31/300], Validation Accuracy: 37.94%\n",
            "Epoch [32/300], Step [16/32], Step Loss: 0.4195\n",
            "Epoch [32/300], Step [32/32], Step Loss: 0.2819\n",
            "Training accuracy: 99.61%\n",
            "Epoch [32/300], Validation Accuracy: 38.73%\n",
            "Epoch [33/300], Step [16/32], Step Loss: 0.3970\n",
            "Epoch [33/300], Step [32/32], Step Loss: 0.2288\n",
            "Training accuracy: 99.90%\n",
            "Epoch [33/300], Validation Accuracy: 38.63%\n",
            "Epoch [34/300], Step [16/32], Step Loss: 0.2670\n",
            "Epoch [34/300], Step [32/32], Step Loss: 0.2227\n",
            "Training accuracy: 99.71%\n",
            "Epoch [34/300], Validation Accuracy: 38.53%\n",
            "Epoch [35/300], Step [16/32], Step Loss: 0.1476\n",
            "Epoch [35/300], Step [32/32], Step Loss: 0.2554\n",
            "Training accuracy: 99.80%\n",
            "Epoch [35/300], Validation Accuracy: 40.39%\n",
            "Epoch [36/300], Step [16/32], Step Loss: 0.1787\n",
            "Epoch [36/300], Step [32/32], Step Loss: 0.4009\n",
            "Training accuracy: 99.80%\n",
            "Epoch [36/300], Validation Accuracy: 39.61%\n",
            "Epoch [37/300], Step [16/32], Step Loss: 0.2297\n",
            "Epoch [37/300], Step [32/32], Step Loss: 0.1592\n",
            "Training accuracy: 100.00%\n",
            "Epoch [37/300], Validation Accuracy: 39.12%\n",
            "Epoch [38/300], Step [16/32], Step Loss: 0.1388\n",
            "Epoch [38/300], Step [32/32], Step Loss: 0.1507\n",
            "Training accuracy: 99.90%\n",
            "Epoch [38/300], Validation Accuracy: 38.53%\n",
            "Epoch [39/300], Step [16/32], Step Loss: 0.1180\n",
            "Epoch [39/300], Step [32/32], Step Loss: 0.1691\n",
            "Training accuracy: 99.90%\n",
            "Epoch [39/300], Validation Accuracy: 38.82%\n",
            "Epoch [40/300], Step [16/32], Step Loss: 0.1305\n",
            "Epoch [40/300], Step [32/32], Step Loss: 0.1415\n",
            "Training accuracy: 99.90%\n",
            "Epoch [40/300], Validation Accuracy: 39.90%\n",
            "Epoch [41/300], Step [16/32], Step Loss: 0.1215\n",
            "Epoch [41/300], Step [32/32], Step Loss: 0.1590\n",
            "Training accuracy: 100.00%\n",
            "Epoch [41/300], Validation Accuracy: 40.78%\n",
            "Epoch [42/300], Step [16/32], Step Loss: 0.1287\n",
            "Epoch [42/300], Step [32/32], Step Loss: 0.1119\n",
            "Training accuracy: 99.90%\n",
            "Epoch [42/300], Validation Accuracy: 39.90%\n",
            "Epoch [43/300], Step [16/32], Step Loss: 0.1130\n",
            "Epoch [43/300], Step [32/32], Step Loss: 0.1174\n",
            "Training accuracy: 100.00%\n",
            "Epoch [43/300], Validation Accuracy: 40.10%\n",
            "Epoch [44/300], Step [16/32], Step Loss: 0.1122\n",
            "Epoch [44/300], Step [32/32], Step Loss: 0.1169\n",
            "Training accuracy: 100.00%\n",
            "Epoch [44/300], Validation Accuracy: 39.61%\n",
            "Epoch [45/300], Step [16/32], Step Loss: 0.0772\n",
            "Epoch [45/300], Step [32/32], Step Loss: 0.1631\n",
            "Training accuracy: 100.00%\n",
            "Epoch [45/300], Validation Accuracy: 41.76%\n",
            "Epoch [46/300], Step [16/32], Step Loss: 0.0968\n",
            "Epoch [46/300], Step [32/32], Step Loss: 0.0888\n",
            "Training accuracy: 100.00%\n",
            "Epoch [46/300], Validation Accuracy: 39.80%\n",
            "Epoch [47/300], Step [16/32], Step Loss: 0.0871\n",
            "Epoch [47/300], Step [32/32], Step Loss: 0.0963\n",
            "Training accuracy: 100.00%\n",
            "Epoch [47/300], Validation Accuracy: 40.39%\n",
            "Epoch [48/300], Step [16/32], Step Loss: 0.0567\n",
            "Epoch [48/300], Step [32/32], Step Loss: 0.0492\n",
            "Training accuracy: 100.00%\n",
            "Epoch [48/300], Validation Accuracy: 40.10%\n",
            "Epoch [49/300], Step [16/32], Step Loss: 0.0600\n",
            "Epoch [49/300], Step [32/32], Step Loss: 0.0539\n",
            "Training accuracy: 100.00%\n",
            "Epoch [49/300], Validation Accuracy: 40.49%\n",
            "Epoch [50/300], Step [16/32], Step Loss: 0.0732\n",
            "Epoch [50/300], Step [32/32], Step Loss: 0.1060\n",
            "Training accuracy: 99.90%\n",
            "Epoch [50/300], Validation Accuracy: 41.27%\n",
            "Epoch [51/300], Step [16/32], Step Loss: 0.0995\n",
            "Epoch [51/300], Step [32/32], Step Loss: 0.0619\n",
            "Training accuracy: 100.00%\n",
            "Epoch [51/300], Validation Accuracy: 40.59%\n",
            "Epoch [52/300], Step [16/32], Step Loss: 0.0408\n",
            "Epoch [52/300], Step [32/32], Step Loss: 0.1279\n",
            "Training accuracy: 100.00%\n",
            "Epoch [52/300], Validation Accuracy: 39.80%\n",
            "Epoch [53/300], Step [16/32], Step Loss: 0.0509\n",
            "Epoch [53/300], Step [32/32], Step Loss: 0.1164\n",
            "Training accuracy: 100.00%\n",
            "Epoch [53/300], Validation Accuracy: 40.49%\n",
            "Epoch [54/300], Step [16/32], Step Loss: 0.0464\n",
            "Epoch [54/300], Step [32/32], Step Loss: 0.0616\n",
            "Training accuracy: 100.00%\n",
            "Epoch [54/300], Validation Accuracy: 40.88%\n",
            "Epoch [55/300], Step [16/32], Step Loss: 0.0616\n",
            "Epoch [55/300], Step [32/32], Step Loss: 0.0402\n",
            "Training accuracy: 100.00%\n",
            "Epoch [55/300], Validation Accuracy: 40.49%\n",
            "Epoch [56/300], Step [16/32], Step Loss: 0.0551\n",
            "Epoch [56/300], Step [32/32], Step Loss: 0.0379\n",
            "Training accuracy: 100.00%\n",
            "Epoch [56/300], Validation Accuracy: 40.78%\n",
            "Epoch [57/300], Step [16/32], Step Loss: 0.0387\n",
            "Epoch [57/300], Step [32/32], Step Loss: 0.1109\n",
            "Training accuracy: 100.00%\n",
            "Epoch [57/300], Validation Accuracy: 40.00%\n",
            "Epoch [58/300], Step [16/32], Step Loss: 0.0477\n",
            "Epoch [58/300], Step [32/32], Step Loss: 0.0744\n",
            "Training accuracy: 100.00%\n",
            "Epoch [58/300], Validation Accuracy: 40.98%\n",
            "Epoch [59/300], Step [16/32], Step Loss: 0.0369\n",
            "Epoch [59/300], Step [32/32], Step Loss: 0.0337\n",
            "Training accuracy: 100.00%\n",
            "Epoch [59/300], Validation Accuracy: 41.08%\n",
            "Epoch [60/300], Step [16/32], Step Loss: 0.0281\n",
            "Epoch [60/300], Step [32/32], Step Loss: 0.0649\n",
            "Training accuracy: 100.00%\n",
            "Epoch [60/300], Validation Accuracy: 40.00%\n",
            "Epoch [61/300], Step [16/32], Step Loss: 0.0498\n",
            "Epoch [61/300], Step [32/32], Step Loss: 0.0408\n",
            "Training accuracy: 100.00%\n",
            "Epoch [61/300], Validation Accuracy: 41.37%\n",
            "Epoch [62/300], Step [16/32], Step Loss: 0.0346\n",
            "Epoch [62/300], Step [32/32], Step Loss: 0.0306\n",
            "Training accuracy: 100.00%\n",
            "Epoch [62/300], Validation Accuracy: 40.69%\n",
            "Epoch [63/300], Step [16/32], Step Loss: 0.0591\n",
            "Epoch [63/300], Step [32/32], Step Loss: 0.0434\n",
            "Training accuracy: 100.00%\n",
            "Epoch [63/300], Validation Accuracy: 41.18%\n",
            "Epoch [64/300], Step [16/32], Step Loss: 0.0220\n",
            "Epoch [64/300], Step [32/32], Step Loss: 0.0547\n",
            "Training accuracy: 100.00%\n",
            "Epoch [64/300], Validation Accuracy: 41.76%\n",
            "Epoch [65/300], Step [16/32], Step Loss: 0.0540\n",
            "Epoch [65/300], Step [32/32], Step Loss: 0.0420\n",
            "Training accuracy: 100.00%\n",
            "Epoch [65/300], Validation Accuracy: 40.59%\n",
            "Epoch [66/300], Step [16/32], Step Loss: 0.0351\n",
            "Epoch [66/300], Step [32/32], Step Loss: 0.0359\n",
            "Training accuracy: 100.00%\n",
            "Epoch [66/300], Validation Accuracy: 40.69%\n",
            "Epoch [67/300], Step [16/32], Step Loss: 0.0306\n",
            "Epoch [67/300], Step [32/32], Step Loss: 0.0380\n",
            "Training accuracy: 100.00%\n",
            "Epoch [67/300], Validation Accuracy: 41.37%\n",
            "Epoch [68/300], Step [16/32], Step Loss: 0.0226\n",
            "Epoch [68/300], Step [32/32], Step Loss: 0.0288\n",
            "Training accuracy: 100.00%\n",
            "Epoch [68/300], Validation Accuracy: 40.98%\n",
            "Epoch [69/300], Step [16/32], Step Loss: 0.0288\n",
            "Epoch [69/300], Step [32/32], Step Loss: 0.0222\n",
            "Training accuracy: 100.00%\n",
            "Epoch [69/300], Validation Accuracy: 40.39%\n",
            "Epoch [70/300], Step [16/32], Step Loss: 0.0166\n",
            "Epoch [70/300], Step [32/32], Step Loss: 0.0347\n",
            "Training accuracy: 100.00%\n",
            "Epoch [70/300], Validation Accuracy: 40.49%\n",
            "Epoch [71/300], Step [16/32], Step Loss: 0.0876\n",
            "Epoch [71/300], Step [32/32], Step Loss: 0.0401\n",
            "Training accuracy: 99.90%\n",
            "Epoch [71/300], Validation Accuracy: 40.39%\n",
            "Epoch [72/300], Step [16/32], Step Loss: 0.0137\n",
            "Epoch [72/300], Step [32/32], Step Loss: 0.0274\n",
            "Training accuracy: 100.00%\n",
            "Epoch [72/300], Validation Accuracy: 41.18%\n",
            "Epoch [73/300], Step [16/32], Step Loss: 0.0308\n",
            "Epoch [73/300], Step [32/32], Step Loss: 0.0193\n",
            "Training accuracy: 100.00%\n",
            "Epoch [73/300], Validation Accuracy: 41.47%\n",
            "Epoch [74/300], Step [16/32], Step Loss: 0.0258\n",
            "Epoch [74/300], Step [32/32], Step Loss: 0.0265\n",
            "Training accuracy: 100.00%\n",
            "Epoch [74/300], Validation Accuracy: 40.69%\n",
            "Epoch [75/300], Step [16/32], Step Loss: 0.0138\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-7c5286c73fd6>\u001b[0m in \u001b[0;36m<cell line: 113>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch, time, gc\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as grid\n",
        "\n",
        "# Setup device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "SAVE_PATH = \"./neural_net.pth\"\n",
        "\n",
        "# Training variables\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 300\n",
        "LEARNING_RATE = 0.000005\n",
        "\n",
        "# Allowed transformations for test dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256, antialias=True),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the train and test datasets\n",
        "train_dataset = datasets.Flowers102(root=\"./data\", split=\"train\", transform=transform, download=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "test_dataset = datasets.Flowers102(root=\"./data\", split=\"test\", transform=transform, download=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "val_dataset = datasets.Flowers102(root=\"./data\", split=\"val\", transform=transform, download=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "val_accuracies = []\n",
        "\n",
        "# Define the CNN architecture\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(64),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2)) # 224 -> 112\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(128),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2)) # 112 -> 56\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(128),\n",
        "                                   nn.ReLU())\n",
        "        self.conv4 = nn.Sequential(nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(128),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2)) # 56 -> 28\n",
        "        self.conv5 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(256),\n",
        "                                   nn.ReLU())\n",
        "        self.conv6 = nn.Sequential(nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(256),\n",
        "                                   nn.ReLU())\n",
        "        self.conv7 = nn.Sequential(nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(256),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2)) # 28 -> 14\n",
        "        self.conv8 = nn.Sequential(nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(512),\n",
        "                                   nn.ReLU())\n",
        "        self.conv9 = nn.Sequential(nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(512),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2)) # 14 -> 7\n",
        "        self.fc1 = nn.Sequential(nn.Linear(7 * 7 * 512, 4096),\n",
        "                                   nn.ReLU())\n",
        "        self.fc2 = nn.Sequential(nn.Linear(4096, 4096),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.Dropout(0.3))\n",
        "        self.fc3 = nn.Sequential(nn.Linear(4096, 102))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.conv6(x)\n",
        "        x = self.conv7(x)\n",
        "        x = self.conv8(x)\n",
        "        x = self.conv9(x)\n",
        "        x = x.view(-1, 7 * 7 * 512)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Clear cuda cache\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Create an instance of the CNN and move it to the device\n",
        "cnn = CNN().to(device)\n",
        "print(cnn)\n",
        "\n",
        "# Define the loss function and the optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cnn.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Setup timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the CNN\n",
        "for epoch in range(EPOCHS):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    cnn.train()\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        labels = torch.eye(102)[labels] # one hot encode\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = cnn(images) # train\n",
        "        labels = torch.argmax(labels, dim=1) # one hot decode\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()  \n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 16 == 0:\n",
        "            print(f\"Epoch [{epoch + 1}/{EPOCHS}], Step [{i + 1}/{len(train_loader)}], Step Loss: {loss.item():.4f}\")\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Training accuracy: {accuracy:.2f}%\")\n",
        "    # Evaluate model after each training epoch\n",
        "    cnn.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = cnn(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f'Epoch [{epoch+1}/{EPOCHS}], Validation Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "    # save accuracy\n",
        "    val_accuracies.append(accuracy)\n",
        "\n",
        "# Output time taken to train\n",
        "end_time = time.time()\n",
        "print(\"Training Complete in: \" + time.strftime(\"%Hh %Mm %Ss\", time.gmtime(end_time - start_time)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEY3nc4b0ygL"
      },
      "outputs": [],
      "source": []
    }
  ]
}