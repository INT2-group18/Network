{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkNAUxTWYJwgheJvuplrkf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/INT2-group18/Network/blob/main/INT2-NeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LWLZiIRvMfzp",
        "outputId": "d99e79ec-595f-49d1-882c-f440249aff2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.1, inplace=False)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv5): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (conv6): Sequential(\n",
            "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (conv7): Sequential(\n",
            "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv8): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (conv9): Sequential(\n",
            "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc1): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (fc2): Sequential(\n",
            "    (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (fc3): Sequential(\n",
            "    (0): Linear(in_features=4096, out_features=102, bias=True)\n",
            "  )\n",
            ")\n",
            "Epoch [1/300], Step [16/32], Step Loss: 4.7929\n",
            "Epoch [1/300], Step [32/32], Step Loss: 4.9036\n",
            "Epoch [1/300], Validation Accuracy: 1.18%\n",
            "Epoch [2/300], Step [16/32], Step Loss: 4.5548\n",
            "Epoch [2/300], Step [32/32], Step Loss: 4.6517\n",
            "Epoch [2/300], Validation Accuracy: 2.06%\n",
            "Epoch [3/300], Step [16/32], Step Loss: 4.5501\n",
            "Epoch [3/300], Step [32/32], Step Loss: 4.6182\n",
            "Epoch [3/300], Validation Accuracy: 2.65%\n",
            "Epoch [4/300], Step [16/32], Step Loss: 4.4799\n",
            "Epoch [4/300], Step [32/32], Step Loss: 4.4846\n",
            "Epoch [4/300], Validation Accuracy: 3.14%\n",
            "Epoch [5/300], Step [16/32], Step Loss: 4.4130\n",
            "Epoch [5/300], Step [32/32], Step Loss: 4.5393\n",
            "Epoch [5/300], Validation Accuracy: 2.45%\n",
            "Epoch [6/300], Step [16/32], Step Loss: 4.4345\n",
            "Epoch [6/300], Step [32/32], Step Loss: 4.3989\n",
            "Epoch [6/300], Validation Accuracy: 3.73%\n",
            "Epoch [7/300], Step [16/32], Step Loss: 4.4613\n",
            "Epoch [7/300], Step [32/32], Step Loss: 4.4226\n",
            "Epoch [7/300], Validation Accuracy: 3.63%\n",
            "Epoch [8/300], Step [16/32], Step Loss: 4.4601\n",
            "Epoch [8/300], Step [32/32], Step Loss: 4.4923\n",
            "Epoch [8/300], Validation Accuracy: 4.61%\n",
            "Epoch [9/300], Step [16/32], Step Loss: 4.2049\n",
            "Epoch [9/300], Step [32/32], Step Loss: 4.2013\n",
            "Epoch [9/300], Validation Accuracy: 4.02%\n",
            "Epoch [10/300], Step [16/32], Step Loss: 4.1638\n",
            "Epoch [10/300], Step [32/32], Step Loss: 4.3144\n",
            "Epoch [10/300], Validation Accuracy: 5.00%\n",
            "Epoch [11/300], Step [16/32], Step Loss: 4.1811\n",
            "Epoch [11/300], Step [32/32], Step Loss: 4.4946\n",
            "Epoch [11/300], Validation Accuracy: 5.69%\n",
            "Epoch [12/300], Step [16/32], Step Loss: 4.3454\n",
            "Epoch [12/300], Step [32/32], Step Loss: 4.1030\n",
            "Epoch [12/300], Validation Accuracy: 8.24%\n",
            "Epoch [13/300], Step [16/32], Step Loss: 4.0268\n",
            "Epoch [13/300], Step [32/32], Step Loss: 4.1207\n",
            "Epoch [13/300], Validation Accuracy: 6.57%\n",
            "Epoch [14/300], Step [16/32], Step Loss: 4.0138\n",
            "Epoch [14/300], Step [32/32], Step Loss: 3.9178\n",
            "Epoch [14/300], Validation Accuracy: 8.24%\n",
            "Epoch [15/300], Step [16/32], Step Loss: 4.1218\n",
            "Epoch [15/300], Step [32/32], Step Loss: 3.7834\n",
            "Epoch [15/300], Validation Accuracy: 9.90%\n",
            "Epoch [16/300], Step [16/32], Step Loss: 3.4742\n",
            "Epoch [16/300], Step [32/32], Step Loss: 3.6775\n",
            "Epoch [16/300], Validation Accuracy: 9.12%\n",
            "Epoch [17/300], Step [16/32], Step Loss: 3.6355\n",
            "Epoch [17/300], Step [32/32], Step Loss: 3.7230\n",
            "Epoch [17/300], Validation Accuracy: 11.37%\n",
            "Epoch [18/300], Step [16/32], Step Loss: 3.6225\n",
            "Epoch [18/300], Step [32/32], Step Loss: 3.4963\n",
            "Epoch [18/300], Validation Accuracy: 10.49%\n",
            "Epoch [19/300], Step [16/32], Step Loss: 3.9220\n",
            "Epoch [19/300], Step [32/32], Step Loss: 3.9817\n",
            "Epoch [19/300], Validation Accuracy: 14.02%\n",
            "Epoch [20/300], Step [16/32], Step Loss: 3.6502\n",
            "Epoch [20/300], Step [32/32], Step Loss: 3.8680\n",
            "Epoch [20/300], Validation Accuracy: 14.61%\n",
            "Epoch [21/300], Step [16/32], Step Loss: 3.3319\n",
            "Epoch [21/300], Step [32/32], Step Loss: 3.7841\n",
            "Epoch [21/300], Validation Accuracy: 13.92%\n",
            "Epoch [22/300], Step [16/32], Step Loss: 3.2864\n",
            "Epoch [22/300], Step [32/32], Step Loss: 3.2030\n",
            "Epoch [22/300], Validation Accuracy: 12.84%\n",
            "Epoch [23/300], Step [16/32], Step Loss: 3.3214\n",
            "Epoch [23/300], Step [32/32], Step Loss: 3.3372\n",
            "Epoch [23/300], Validation Accuracy: 16.57%\n",
            "Epoch [24/300], Step [16/32], Step Loss: 3.5275\n",
            "Epoch [24/300], Step [32/32], Step Loss: 3.6871\n",
            "Epoch [24/300], Validation Accuracy: 16.47%\n",
            "Epoch [25/300], Step [16/32], Step Loss: 3.6341\n",
            "Epoch [25/300], Step [32/32], Step Loss: 3.4252\n",
            "Epoch [25/300], Validation Accuracy: 17.94%\n",
            "Epoch [26/300], Step [16/32], Step Loss: 2.9533\n",
            "Epoch [26/300], Step [32/32], Step Loss: 3.2284\n",
            "Epoch [26/300], Validation Accuracy: 18.53%\n",
            "Epoch [27/300], Step [16/32], Step Loss: 2.6594\n",
            "Epoch [27/300], Step [32/32], Step Loss: 3.0605\n",
            "Epoch [27/300], Validation Accuracy: 17.06%\n",
            "Epoch [28/300], Step [16/32], Step Loss: 2.7413\n",
            "Epoch [28/300], Step [32/32], Step Loss: 3.4443\n",
            "Epoch [28/300], Validation Accuracy: 20.29%\n",
            "Epoch [29/300], Step [16/32], Step Loss: 2.7636\n",
            "Epoch [29/300], Step [32/32], Step Loss: 3.1688\n",
            "Epoch [29/300], Validation Accuracy: 20.39%\n",
            "Epoch [30/300], Step [16/32], Step Loss: 2.7763\n",
            "Epoch [30/300], Step [32/32], Step Loss: 3.4815\n",
            "Epoch [30/300], Validation Accuracy: 21.76%\n",
            "Epoch [31/300], Step [16/32], Step Loss: 2.9698\n",
            "Epoch [31/300], Step [32/32], Step Loss: 2.7835\n",
            "Epoch [31/300], Validation Accuracy: 21.67%\n",
            "Epoch [32/300], Step [16/32], Step Loss: 2.6851\n",
            "Epoch [32/300], Step [32/32], Step Loss: 2.5215\n",
            "Epoch [32/300], Validation Accuracy: 24.61%\n",
            "Epoch [33/300], Step [16/32], Step Loss: 2.4667\n",
            "Epoch [33/300], Step [32/32], Step Loss: 2.6804\n",
            "Epoch [33/300], Validation Accuracy: 18.43%\n",
            "Epoch [34/300], Step [16/32], Step Loss: 2.9864\n",
            "Epoch [34/300], Step [32/32], Step Loss: 2.2524\n",
            "Epoch [34/300], Validation Accuracy: 23.92%\n",
            "Epoch [35/300], Step [16/32], Step Loss: 2.2861\n",
            "Epoch [35/300], Step [32/32], Step Loss: 2.7444\n",
            "Epoch [35/300], Validation Accuracy: 21.96%\n",
            "Epoch [36/300], Step [16/32], Step Loss: 2.4005\n",
            "Epoch [36/300], Step [32/32], Step Loss: 2.6428\n",
            "Epoch [36/300], Validation Accuracy: 25.10%\n",
            "Epoch [37/300], Step [16/32], Step Loss: 2.2825\n",
            "Epoch [37/300], Step [32/32], Step Loss: 2.3314\n",
            "Epoch [37/300], Validation Accuracy: 24.22%\n",
            "Epoch [38/300], Step [16/32], Step Loss: 2.1860\n",
            "Epoch [38/300], Step [32/32], Step Loss: 2.4230\n",
            "Epoch [38/300], Validation Accuracy: 25.20%\n",
            "Epoch [39/300], Step [16/32], Step Loss: 1.9797\n",
            "Epoch [39/300], Step [32/32], Step Loss: 2.2489\n",
            "Epoch [39/300], Validation Accuracy: 25.98%\n",
            "Epoch [40/300], Step [16/32], Step Loss: 2.3178\n",
            "Epoch [40/300], Step [32/32], Step Loss: 2.3970\n",
            "Epoch [40/300], Validation Accuracy: 25.69%\n",
            "Epoch [41/300], Step [16/32], Step Loss: 2.3221\n",
            "Epoch [41/300], Step [32/32], Step Loss: 2.6142\n",
            "Epoch [41/300], Validation Accuracy: 27.06%\n",
            "Epoch [42/300], Step [16/32], Step Loss: 2.1185\n",
            "Epoch [42/300], Step [32/32], Step Loss: 2.0055\n",
            "Epoch [42/300], Validation Accuracy: 29.22%\n",
            "Epoch [43/300], Step [16/32], Step Loss: 1.8823\n",
            "Epoch [43/300], Step [32/32], Step Loss: 2.6568\n",
            "Epoch [43/300], Validation Accuracy: 26.37%\n",
            "Epoch [44/300], Step [16/32], Step Loss: 2.1112\n",
            "Epoch [44/300], Step [32/32], Step Loss: 1.8135\n",
            "Epoch [44/300], Validation Accuracy: 26.27%\n",
            "Epoch [45/300], Step [16/32], Step Loss: 2.1829\n",
            "Epoch [45/300], Step [32/32], Step Loss: 2.4246\n",
            "Epoch [45/300], Validation Accuracy: 26.76%\n",
            "Epoch [46/300], Step [16/32], Step Loss: 2.1929\n",
            "Epoch [46/300], Step [32/32], Step Loss: 2.5412\n",
            "Epoch [46/300], Validation Accuracy: 27.45%\n",
            "Epoch [47/300], Step [16/32], Step Loss: 1.5518\n",
            "Epoch [47/300], Step [32/32], Step Loss: 1.3220\n",
            "Epoch [47/300], Validation Accuracy: 25.78%\n",
            "Epoch [48/300], Step [16/32], Step Loss: 1.8697\n",
            "Epoch [48/300], Step [32/32], Step Loss: 2.1551\n",
            "Epoch [48/300], Validation Accuracy: 30.10%\n",
            "Epoch [49/300], Step [16/32], Step Loss: 2.0274\n",
            "Epoch [49/300], Step [32/32], Step Loss: 1.8128\n",
            "Epoch [49/300], Validation Accuracy: 29.02%\n",
            "Epoch [50/300], Step [16/32], Step Loss: 1.4490\n",
            "Epoch [50/300], Step [32/32], Step Loss: 1.8053\n",
            "Epoch [50/300], Validation Accuracy: 33.04%\n",
            "Epoch [51/300], Step [16/32], Step Loss: 1.9482\n",
            "Epoch [51/300], Step [32/32], Step Loss: 1.3368\n",
            "Epoch [51/300], Validation Accuracy: 34.02%\n",
            "Epoch [52/300], Step [16/32], Step Loss: 1.3843\n",
            "Epoch [52/300], Step [32/32], Step Loss: 1.9851\n",
            "Epoch [52/300], Validation Accuracy: 30.59%\n",
            "Epoch [53/300], Step [16/32], Step Loss: 1.9397\n",
            "Epoch [53/300], Step [32/32], Step Loss: 1.5131\n",
            "Epoch [53/300], Validation Accuracy: 29.90%\n",
            "Epoch [54/300], Step [16/32], Step Loss: 1.4575\n",
            "Epoch [54/300], Step [32/32], Step Loss: 2.1122\n",
            "Epoch [54/300], Validation Accuracy: 32.45%\n",
            "Epoch [55/300], Step [16/32], Step Loss: 1.3254\n",
            "Epoch [55/300], Step [32/32], Step Loss: 1.6727\n",
            "Epoch [55/300], Validation Accuracy: 30.59%\n",
            "Epoch [56/300], Step [16/32], Step Loss: 1.3899\n",
            "Epoch [56/300], Step [32/32], Step Loss: 1.4002\n",
            "Epoch [56/300], Validation Accuracy: 32.84%\n",
            "Epoch [57/300], Step [16/32], Step Loss: 1.5102\n",
            "Epoch [57/300], Step [32/32], Step Loss: 1.2057\n",
            "Epoch [57/300], Validation Accuracy: 34.61%\n",
            "Epoch [58/300], Step [16/32], Step Loss: 1.4399\n",
            "Epoch [58/300], Step [32/32], Step Loss: 1.3168\n",
            "Epoch [58/300], Validation Accuracy: 34.90%\n",
            "Epoch [59/300], Step [16/32], Step Loss: 0.7186\n",
            "Epoch [59/300], Step [32/32], Step Loss: 1.1706\n",
            "Epoch [59/300], Validation Accuracy: 33.33%\n",
            "Epoch [60/300], Step [16/32], Step Loss: 1.3042\n",
            "Epoch [60/300], Step [32/32], Step Loss: 0.8897\n",
            "Epoch [60/300], Validation Accuracy: 34.22%\n",
            "Epoch [61/300], Step [16/32], Step Loss: 1.4246\n",
            "Epoch [61/300], Step [32/32], Step Loss: 1.6663\n",
            "Epoch [61/300], Validation Accuracy: 33.92%\n",
            "Epoch [62/300], Step [16/32], Step Loss: 1.1766\n",
            "Epoch [62/300], Step [32/32], Step Loss: 1.4272\n",
            "Epoch [62/300], Validation Accuracy: 33.04%\n",
            "Epoch [63/300], Step [16/32], Step Loss: 1.1876\n",
            "Epoch [63/300], Step [32/32], Step Loss: 0.9506\n",
            "Epoch [63/300], Validation Accuracy: 32.84%\n",
            "Epoch [64/300], Step [16/32], Step Loss: 0.9445\n",
            "Epoch [64/300], Step [32/32], Step Loss: 1.1071\n",
            "Epoch [64/300], Validation Accuracy: 35.00%\n",
            "Epoch [65/300], Step [16/32], Step Loss: 1.2153\n",
            "Epoch [65/300], Step [32/32], Step Loss: 0.8487\n",
            "Epoch [65/300], Validation Accuracy: 34.61%\n",
            "Epoch [66/300], Step [16/32], Step Loss: 1.1856\n",
            "Epoch [66/300], Step [32/32], Step Loss: 1.1616\n",
            "Epoch [66/300], Validation Accuracy: 35.39%\n",
            "Epoch [67/300], Step [16/32], Step Loss: 0.7108\n",
            "Epoch [67/300], Step [32/32], Step Loss: 0.7279\n",
            "Epoch [67/300], Validation Accuracy: 35.88%\n",
            "Epoch [68/300], Step [16/32], Step Loss: 0.8466\n",
            "Epoch [68/300], Step [32/32], Step Loss: 1.4076\n",
            "Epoch [68/300], Validation Accuracy: 33.73%\n",
            "Epoch [69/300], Step [16/32], Step Loss: 0.9598\n",
            "Epoch [69/300], Step [32/32], Step Loss: 0.9310\n",
            "Epoch [69/300], Validation Accuracy: 35.88%\n",
            "Epoch [70/300], Step [16/32], Step Loss: 1.0664\n",
            "Epoch [70/300], Step [32/32], Step Loss: 1.1283\n",
            "Epoch [70/300], Validation Accuracy: 37.45%\n",
            "Epoch [71/300], Step [16/32], Step Loss: 1.2240\n",
            "Epoch [71/300], Step [32/32], Step Loss: 0.7669\n",
            "Epoch [71/300], Validation Accuracy: 35.78%\n",
            "Epoch [72/300], Step [16/32], Step Loss: 0.9927\n",
            "Epoch [72/300], Step [32/32], Step Loss: 0.9326\n",
            "Epoch [72/300], Validation Accuracy: 36.76%\n",
            "Epoch [73/300], Step [16/32], Step Loss: 0.8273\n",
            "Epoch [73/300], Step [32/32], Step Loss: 1.1756\n",
            "Epoch [73/300], Validation Accuracy: 37.84%\n",
            "Epoch [74/300], Step [16/32], Step Loss: 0.5709\n",
            "Epoch [74/300], Step [32/32], Step Loss: 1.0199\n",
            "Epoch [74/300], Validation Accuracy: 37.25%\n",
            "Epoch [75/300], Step [16/32], Step Loss: 0.8750\n",
            "Epoch [75/300], Step [32/32], Step Loss: 0.4277\n",
            "Epoch [75/300], Validation Accuracy: 37.06%\n",
            "Epoch [76/300], Step [16/32], Step Loss: 0.9348\n",
            "Epoch [76/300], Step [32/32], Step Loss: 1.0225\n",
            "Epoch [76/300], Validation Accuracy: 36.37%\n",
            "Epoch [77/300], Step [16/32], Step Loss: 0.8806\n",
            "Epoch [77/300], Step [32/32], Step Loss: 1.0069\n",
            "Epoch [77/300], Validation Accuracy: 34.80%\n",
            "Epoch [78/300], Step [16/32], Step Loss: 0.6075\n",
            "Epoch [78/300], Step [32/32], Step Loss: 0.7685\n",
            "Epoch [78/300], Validation Accuracy: 37.84%\n",
            "Epoch [79/300], Step [16/32], Step Loss: 0.9911\n",
            "Epoch [79/300], Step [32/32], Step Loss: 0.6306\n",
            "Epoch [79/300], Validation Accuracy: 37.45%\n",
            "Epoch [80/300], Step [16/32], Step Loss: 0.8587\n",
            "Epoch [80/300], Step [32/32], Step Loss: 1.1380\n",
            "Epoch [80/300], Validation Accuracy: 36.47%\n",
            "Epoch [81/300], Step [16/32], Step Loss: 1.0564\n",
            "Epoch [81/300], Step [32/32], Step Loss: 0.4410\n",
            "Epoch [81/300], Validation Accuracy: 35.59%\n",
            "Epoch [82/300], Step [16/32], Step Loss: 0.7447\n",
            "Epoch [82/300], Step [32/32], Step Loss: 0.5309\n",
            "Epoch [82/300], Validation Accuracy: 38.43%\n",
            "Epoch [83/300], Step [16/32], Step Loss: 0.5357\n",
            "Epoch [83/300], Step [32/32], Step Loss: 0.7080\n",
            "Epoch [83/300], Validation Accuracy: 36.76%\n",
            "Epoch [84/300], Step [16/32], Step Loss: 0.9200\n",
            "Epoch [84/300], Step [32/32], Step Loss: 0.7864\n",
            "Epoch [84/300], Validation Accuracy: 36.86%\n",
            "Epoch [85/300], Step [16/32], Step Loss: 0.7698\n",
            "Epoch [85/300], Step [32/32], Step Loss: 0.9799\n",
            "Epoch [85/300], Validation Accuracy: 37.25%\n",
            "Epoch [86/300], Step [16/32], Step Loss: 0.9004\n",
            "Epoch [86/300], Step [32/32], Step Loss: 0.8277\n",
            "Epoch [86/300], Validation Accuracy: 38.82%\n",
            "Epoch [87/300], Step [16/32], Step Loss: 0.9894\n",
            "Epoch [87/300], Step [32/32], Step Loss: 0.3340\n",
            "Epoch [87/300], Validation Accuracy: 37.94%\n",
            "Epoch [88/300], Step [16/32], Step Loss: 0.4230\n",
            "Epoch [88/300], Step [32/32], Step Loss: 0.8953\n",
            "Epoch [88/300], Validation Accuracy: 38.63%\n",
            "Epoch [89/300], Step [16/32], Step Loss: 0.4881\n",
            "Epoch [89/300], Step [32/32], Step Loss: 0.9747\n",
            "Epoch [89/300], Validation Accuracy: 38.53%\n",
            "Epoch [90/300], Step [16/32], Step Loss: 0.6431\n",
            "Epoch [90/300], Step [32/32], Step Loss: 0.9009\n",
            "Epoch [90/300], Validation Accuracy: 38.43%\n",
            "Epoch [91/300], Step [16/32], Step Loss: 0.7237\n",
            "Epoch [91/300], Step [32/32], Step Loss: 0.9797\n",
            "Epoch [91/300], Validation Accuracy: 38.33%\n",
            "Epoch [92/300], Step [16/32], Step Loss: 0.4489\n",
            "Epoch [92/300], Step [32/32], Step Loss: 0.7117\n",
            "Epoch [92/300], Validation Accuracy: 38.63%\n",
            "Epoch [93/300], Step [16/32], Step Loss: 0.8115\n",
            "Epoch [93/300], Step [32/32], Step Loss: 0.3640\n",
            "Epoch [93/300], Validation Accuracy: 35.78%\n",
            "Epoch [94/300], Step [16/32], Step Loss: 0.3893\n",
            "Epoch [94/300], Step [32/32], Step Loss: 0.3473\n",
            "Epoch [94/300], Validation Accuracy: 38.92%\n",
            "Epoch [95/300], Step [16/32], Step Loss: 0.4719\n",
            "Epoch [95/300], Step [32/32], Step Loss: 0.5139\n",
            "Epoch [95/300], Validation Accuracy: 39.22%\n",
            "Epoch [96/300], Step [16/32], Step Loss: 0.6013\n",
            "Epoch [96/300], Step [32/32], Step Loss: 0.4257\n",
            "Epoch [96/300], Validation Accuracy: 37.94%\n",
            "Epoch [97/300], Step [16/32], Step Loss: 0.6519\n",
            "Epoch [97/300], Step [32/32], Step Loss: 0.7498\n",
            "Epoch [97/300], Validation Accuracy: 38.14%\n",
            "Epoch [98/300], Step [16/32], Step Loss: 0.4462\n",
            "Epoch [98/300], Step [32/32], Step Loss: 0.6569\n",
            "Epoch [98/300], Validation Accuracy: 37.75%\n",
            "Epoch [99/300], Step [16/32], Step Loss: 0.4294\n",
            "Epoch [99/300], Step [32/32], Step Loss: 0.6119\n",
            "Epoch [99/300], Validation Accuracy: 37.94%\n",
            "Epoch [100/300], Step [16/32], Step Loss: 0.6066\n",
            "Epoch [100/300], Step [32/32], Step Loss: 0.3703\n",
            "Epoch [100/300], Validation Accuracy: 38.53%\n",
            "Epoch [101/300], Step [16/32], Step Loss: 0.7602\n",
            "Epoch [101/300], Step [32/32], Step Loss: 0.5928\n",
            "Epoch [101/300], Validation Accuracy: 36.76%\n",
            "Epoch [102/300], Step [16/32], Step Loss: 0.4561\n",
            "Epoch [102/300], Step [32/32], Step Loss: 0.5243\n",
            "Epoch [102/300], Validation Accuracy: 39.12%\n",
            "Epoch [103/300], Step [16/32], Step Loss: 0.4576\n",
            "Epoch [103/300], Step [32/32], Step Loss: 0.2225\n",
            "Epoch [103/300], Validation Accuracy: 40.20%\n",
            "Epoch [104/300], Step [16/32], Step Loss: 0.6122\n",
            "Epoch [104/300], Step [32/32], Step Loss: 0.5154\n",
            "Epoch [104/300], Validation Accuracy: 37.25%\n",
            "Epoch [105/300], Step [16/32], Step Loss: 0.4850\n",
            "Epoch [105/300], Step [32/32], Step Loss: 0.8183\n",
            "Epoch [105/300], Validation Accuracy: 41.27%\n",
            "Epoch [106/300], Step [16/32], Step Loss: 0.2186\n",
            "Epoch [106/300], Step [32/32], Step Loss: 0.4336\n",
            "Epoch [106/300], Validation Accuracy: 39.71%\n",
            "Epoch [107/300], Step [16/32], Step Loss: 0.3576\n",
            "Epoch [107/300], Step [32/32], Step Loss: 0.3515\n",
            "Epoch [107/300], Validation Accuracy: 38.73%\n",
            "Epoch [108/300], Step [16/32], Step Loss: 0.6725\n",
            "Epoch [108/300], Step [32/32], Step Loss: 0.4455\n",
            "Epoch [108/300], Validation Accuracy: 39.61%\n",
            "Epoch [109/300], Step [16/32], Step Loss: 0.4280\n",
            "Epoch [109/300], Step [32/32], Step Loss: 0.1999\n",
            "Epoch [109/300], Validation Accuracy: 39.61%\n",
            "Epoch [110/300], Step [16/32], Step Loss: 0.2651\n",
            "Epoch [110/300], Step [32/32], Step Loss: 0.5257\n",
            "Epoch [110/300], Validation Accuracy: 39.12%\n",
            "Epoch [111/300], Step [16/32], Step Loss: 0.3195\n",
            "Epoch [111/300], Step [32/32], Step Loss: 0.5004\n",
            "Epoch [111/300], Validation Accuracy: 40.29%\n",
            "Epoch [112/300], Step [16/32], Step Loss: 0.5125\n",
            "Epoch [112/300], Step [32/32], Step Loss: 0.2058\n",
            "Epoch [112/300], Validation Accuracy: 39.22%\n",
            "Epoch [113/300], Step [16/32], Step Loss: 0.6830\n",
            "Epoch [113/300], Step [32/32], Step Loss: 0.2088\n",
            "Epoch [113/300], Validation Accuracy: 41.67%\n",
            "Epoch [114/300], Step [16/32], Step Loss: 0.6546\n",
            "Epoch [114/300], Step [32/32], Step Loss: 0.4580\n",
            "Epoch [114/300], Validation Accuracy: 39.90%\n",
            "Epoch [115/300], Step [16/32], Step Loss: 0.1669\n",
            "Epoch [115/300], Step [32/32], Step Loss: 0.2634\n",
            "Epoch [115/300], Validation Accuracy: 38.33%\n",
            "Epoch [116/300], Step [16/32], Step Loss: 0.4270\n",
            "Epoch [116/300], Step [32/32], Step Loss: 0.5669\n",
            "Epoch [116/300], Validation Accuracy: 40.69%\n",
            "Epoch [117/300], Step [16/32], Step Loss: 0.6014\n",
            "Epoch [117/300], Step [32/32], Step Loss: 0.3987\n",
            "Epoch [117/300], Validation Accuracy: 40.10%\n",
            "Epoch [118/300], Step [16/32], Step Loss: 0.4573\n",
            "Epoch [118/300], Step [32/32], Step Loss: 0.2300\n",
            "Epoch [118/300], Validation Accuracy: 40.88%\n",
            "Epoch [119/300], Step [16/32], Step Loss: 0.9668\n",
            "Epoch [119/300], Step [32/32], Step Loss: 0.2759\n",
            "Epoch [119/300], Validation Accuracy: 39.90%\n",
            "Epoch [120/300], Step [16/32], Step Loss: 0.4121\n",
            "Epoch [120/300], Step [32/32], Step Loss: 0.1956\n",
            "Epoch [120/300], Validation Accuracy: 41.37%\n",
            "Epoch [121/300], Step [16/32], Step Loss: 0.4279\n",
            "Epoch [121/300], Step [32/32], Step Loss: 0.6190\n",
            "Epoch [121/300], Validation Accuracy: 40.29%\n",
            "Epoch [122/300], Step [16/32], Step Loss: 0.4909\n",
            "Epoch [122/300], Step [32/32], Step Loss: 0.0937\n",
            "Epoch [122/300], Validation Accuracy: 41.96%\n",
            "Epoch [123/300], Step [16/32], Step Loss: 0.1591\n",
            "Epoch [123/300], Step [32/32], Step Loss: 0.4133\n",
            "Epoch [123/300], Validation Accuracy: 42.75%\n",
            "Epoch [124/300], Step [16/32], Step Loss: 0.4007\n",
            "Epoch [124/300], Step [32/32], Step Loss: 0.4699\n",
            "Epoch [124/300], Validation Accuracy: 42.75%\n",
            "Epoch [125/300], Step [16/32], Step Loss: 0.3806\n",
            "Epoch [125/300], Step [32/32], Step Loss: 0.3437\n",
            "Epoch [125/300], Validation Accuracy: 41.57%\n",
            "Epoch [126/300], Step [16/32], Step Loss: 0.1220\n",
            "Epoch [126/300], Step [32/32], Step Loss: 0.2858\n",
            "Epoch [126/300], Validation Accuracy: 41.27%\n",
            "Epoch [127/300], Step [16/32], Step Loss: 0.1136\n",
            "Epoch [127/300], Step [32/32], Step Loss: 0.4365\n",
            "Epoch [127/300], Validation Accuracy: 40.59%\n",
            "Epoch [128/300], Step [16/32], Step Loss: 0.4061\n",
            "Epoch [128/300], Step [32/32], Step Loss: 0.3296\n",
            "Epoch [128/300], Validation Accuracy: 40.29%\n",
            "Epoch [129/300], Step [16/32], Step Loss: 0.3707\n",
            "Epoch [129/300], Step [32/32], Step Loss: 0.5125\n",
            "Epoch [129/300], Validation Accuracy: 40.49%\n",
            "Epoch [130/300], Step [16/32], Step Loss: 0.1343\n",
            "Epoch [130/300], Step [32/32], Step Loss: 0.1161\n",
            "Epoch [130/300], Validation Accuracy: 40.39%\n",
            "Epoch [131/300], Step [16/32], Step Loss: 0.3547\n",
            "Epoch [131/300], Step [32/32], Step Loss: 0.1535\n",
            "Epoch [131/300], Validation Accuracy: 44.02%\n",
            "Epoch [132/300], Step [16/32], Step Loss: 0.3705\n",
            "Epoch [132/300], Step [32/32], Step Loss: 0.1920\n",
            "Epoch [132/300], Validation Accuracy: 42.16%\n",
            "Epoch [133/300], Step [16/32], Step Loss: 0.3250\n",
            "Epoch [133/300], Step [32/32], Step Loss: 0.1910\n",
            "Epoch [133/300], Validation Accuracy: 43.33%\n",
            "Epoch [134/300], Step [16/32], Step Loss: 0.2550\n",
            "Epoch [134/300], Step [32/32], Step Loss: 0.1054\n",
            "Epoch [134/300], Validation Accuracy: 43.63%\n",
            "Epoch [135/300], Step [16/32], Step Loss: 0.6305\n",
            "Epoch [135/300], Step [32/32], Step Loss: 0.1133\n",
            "Epoch [135/300], Validation Accuracy: 41.27%\n",
            "Epoch [136/300], Step [16/32], Step Loss: 0.2417\n",
            "Epoch [136/300], Step [32/32], Step Loss: 0.5636\n",
            "Epoch [136/300], Validation Accuracy: 39.80%\n",
            "Epoch [137/300], Step [16/32], Step Loss: 0.3416\n",
            "Epoch [137/300], Step [32/32], Step Loss: 0.3827\n",
            "Epoch [137/300], Validation Accuracy: 40.39%\n",
            "Epoch [138/300], Step [16/32], Step Loss: 0.1058\n",
            "Epoch [138/300], Step [32/32], Step Loss: 0.5801\n",
            "Epoch [138/300], Validation Accuracy: 40.98%\n",
            "Epoch [139/300], Step [16/32], Step Loss: 0.5079\n",
            "Epoch [139/300], Step [32/32], Step Loss: 0.3528\n",
            "Epoch [139/300], Validation Accuracy: 37.25%\n",
            "Epoch [140/300], Step [16/32], Step Loss: 0.2481\n",
            "Epoch [140/300], Step [32/32], Step Loss: 0.0340\n",
            "Epoch [140/300], Validation Accuracy: 42.65%\n",
            "Epoch [141/300], Step [16/32], Step Loss: 0.2336\n",
            "Epoch [141/300], Step [32/32], Step Loss: 0.1037\n",
            "Epoch [141/300], Validation Accuracy: 42.06%\n",
            "Epoch [142/300], Step [16/32], Step Loss: 0.3018\n",
            "Epoch [142/300], Step [32/32], Step Loss: 0.3610\n",
            "Epoch [142/300], Validation Accuracy: 42.65%\n",
            "Epoch [143/300], Step [16/32], Step Loss: 0.5496\n",
            "Epoch [143/300], Step [32/32], Step Loss: 0.1171\n",
            "Epoch [143/300], Validation Accuracy: 39.22%\n",
            "Epoch [144/300], Step [16/32], Step Loss: 0.1461\n",
            "Epoch [144/300], Step [32/32], Step Loss: 0.3784\n",
            "Epoch [144/300], Validation Accuracy: 41.18%\n",
            "Epoch [145/300], Step [16/32], Step Loss: 0.4177\n",
            "Epoch [145/300], Step [32/32], Step Loss: 0.1736\n",
            "Epoch [145/300], Validation Accuracy: 41.08%\n",
            "Epoch [146/300], Step [16/32], Step Loss: 0.4540\n",
            "Epoch [146/300], Step [32/32], Step Loss: 0.1986\n",
            "Epoch [146/300], Validation Accuracy: 42.55%\n",
            "Epoch [147/300], Step [16/32], Step Loss: 0.3075\n",
            "Epoch [147/300], Step [32/32], Step Loss: 0.0811\n",
            "Epoch [147/300], Validation Accuracy: 41.27%\n",
            "Epoch [148/300], Step [16/32], Step Loss: 0.1361\n",
            "Epoch [148/300], Step [32/32], Step Loss: 0.5734\n",
            "Epoch [148/300], Validation Accuracy: 43.14%\n",
            "Epoch [149/300], Step [16/32], Step Loss: 0.1873\n",
            "Epoch [149/300], Step [32/32], Step Loss: 0.1451\n",
            "Epoch [149/300], Validation Accuracy: 43.92%\n",
            "Epoch [150/300], Step [16/32], Step Loss: 0.0656\n",
            "Epoch [150/300], Step [32/32], Step Loss: 0.2646\n",
            "Epoch [150/300], Validation Accuracy: 39.80%\n",
            "Epoch [151/300], Step [16/32], Step Loss: 0.1427\n",
            "Epoch [151/300], Step [32/32], Step Loss: 0.1844\n",
            "Epoch [151/300], Validation Accuracy: 44.71%\n",
            "Epoch [152/300], Step [16/32], Step Loss: 0.2233\n",
            "Epoch [152/300], Step [32/32], Step Loss: 0.0993\n",
            "Epoch [152/300], Validation Accuracy: 40.59%\n",
            "Epoch [153/300], Step [16/32], Step Loss: 0.1894\n",
            "Epoch [153/300], Step [32/32], Step Loss: 0.0570\n",
            "Epoch [153/300], Validation Accuracy: 41.57%\n",
            "Epoch [154/300], Step [16/32], Step Loss: 0.5029\n",
            "Epoch [154/300], Step [32/32], Step Loss: 0.0582\n",
            "Epoch [154/300], Validation Accuracy: 41.86%\n",
            "Epoch [155/300], Step [16/32], Step Loss: 0.4149\n",
            "Epoch [155/300], Step [32/32], Step Loss: 0.0953\n",
            "Epoch [155/300], Validation Accuracy: 42.16%\n",
            "Epoch [156/300], Step [16/32], Step Loss: 0.2412\n",
            "Epoch [156/300], Step [32/32], Step Loss: 0.2799\n",
            "Epoch [156/300], Validation Accuracy: 44.61%\n",
            "Epoch [157/300], Step [16/32], Step Loss: 0.1364\n",
            "Epoch [157/300], Step [32/32], Step Loss: 0.6750\n",
            "Epoch [157/300], Validation Accuracy: 42.94%\n",
            "Epoch [158/300], Step [16/32], Step Loss: 0.4507\n",
            "Epoch [158/300], Step [32/32], Step Loss: 0.4267\n",
            "Epoch [158/300], Validation Accuracy: 43.24%\n",
            "Epoch [159/300], Step [16/32], Step Loss: 0.3748\n",
            "Epoch [159/300], Step [32/32], Step Loss: 0.3399\n",
            "Epoch [159/300], Validation Accuracy: 40.88%\n",
            "Epoch [160/300], Step [16/32], Step Loss: 0.1248\n",
            "Epoch [160/300], Step [32/32], Step Loss: 0.2963\n",
            "Epoch [160/300], Validation Accuracy: 41.37%\n",
            "Epoch [161/300], Step [16/32], Step Loss: 0.4253\n",
            "Epoch [161/300], Step [32/32], Step Loss: 0.1835\n",
            "Epoch [161/300], Validation Accuracy: 42.45%\n",
            "Epoch [162/300], Step [16/32], Step Loss: 0.2099\n",
            "Epoch [162/300], Step [32/32], Step Loss: 0.0635\n",
            "Epoch [162/300], Validation Accuracy: 45.20%\n",
            "Epoch [163/300], Step [16/32], Step Loss: 0.0534\n",
            "Epoch [163/300], Step [32/32], Step Loss: 0.0864\n",
            "Epoch [163/300], Validation Accuracy: 44.61%\n",
            "Epoch [164/300], Step [16/32], Step Loss: 0.2271\n",
            "Epoch [164/300], Step [32/32], Step Loss: 0.3573\n",
            "Epoch [164/300], Validation Accuracy: 45.69%\n",
            "Epoch [165/300], Step [16/32], Step Loss: 0.1674\n",
            "Epoch [165/300], Step [32/32], Step Loss: 0.0413\n",
            "Epoch [165/300], Validation Accuracy: 44.41%\n",
            "Epoch [166/300], Step [16/32], Step Loss: 0.1563\n",
            "Epoch [166/300], Step [32/32], Step Loss: 0.2708\n",
            "Epoch [166/300], Validation Accuracy: 42.35%\n",
            "Epoch [167/300], Step [16/32], Step Loss: 0.2800\n",
            "Epoch [167/300], Step [32/32], Step Loss: 0.1957\n",
            "Epoch [167/300], Validation Accuracy: 41.47%\n",
            "Epoch [168/300], Step [16/32], Step Loss: 0.2225\n",
            "Epoch [168/300], Step [32/32], Step Loss: 0.1474\n",
            "Epoch [168/300], Validation Accuracy: 39.80%\n",
            "Epoch [169/300], Step [16/32], Step Loss: 0.4283\n",
            "Epoch [169/300], Step [32/32], Step Loss: 0.1640\n",
            "Epoch [169/300], Validation Accuracy: 43.63%\n",
            "Epoch [170/300], Step [16/32], Step Loss: 0.2025\n",
            "Epoch [170/300], Step [32/32], Step Loss: 0.0723\n",
            "Epoch [170/300], Validation Accuracy: 40.88%\n",
            "Epoch [171/300], Step [16/32], Step Loss: 0.1612\n",
            "Epoch [171/300], Step [32/32], Step Loss: 0.1777\n",
            "Epoch [171/300], Validation Accuracy: 40.98%\n",
            "Epoch [172/300], Step [16/32], Step Loss: 0.1338\n",
            "Epoch [172/300], Step [32/32], Step Loss: 0.1308\n",
            "Epoch [172/300], Validation Accuracy: 43.53%\n",
            "Epoch [173/300], Step [16/32], Step Loss: 0.3176\n",
            "Epoch [173/300], Step [32/32], Step Loss: 0.1147\n",
            "Epoch [173/300], Validation Accuracy: 43.24%\n",
            "Epoch [174/300], Step [16/32], Step Loss: 0.1766\n",
            "Epoch [174/300], Step [32/32], Step Loss: 0.1658\n",
            "Epoch [174/300], Validation Accuracy: 43.33%\n",
            "Epoch [175/300], Step [16/32], Step Loss: 0.1800\n",
            "Epoch [175/300], Step [32/32], Step Loss: 0.3790\n",
            "Epoch [175/300], Validation Accuracy: 44.41%\n",
            "Epoch [176/300], Step [16/32], Step Loss: 0.0837\n",
            "Epoch [176/300], Step [32/32], Step Loss: 0.0507\n",
            "Epoch [176/300], Validation Accuracy: 43.24%\n",
            "Epoch [177/300], Step [16/32], Step Loss: 0.3076\n",
            "Epoch [177/300], Step [32/32], Step Loss: 0.1159\n",
            "Epoch [177/300], Validation Accuracy: 42.16%\n",
            "Epoch [178/300], Step [16/32], Step Loss: 0.1859\n",
            "Epoch [178/300], Step [32/32], Step Loss: 0.0349\n",
            "Epoch [178/300], Validation Accuracy: 43.24%\n",
            "Epoch [179/300], Step [16/32], Step Loss: 0.1583\n",
            "Epoch [179/300], Step [32/32], Step Loss: 0.2859\n",
            "Epoch [179/300], Validation Accuracy: 43.14%\n",
            "Epoch [180/300], Step [16/32], Step Loss: 0.1478\n",
            "Epoch [180/300], Step [32/32], Step Loss: 0.0930\n",
            "Epoch [180/300], Validation Accuracy: 43.33%\n",
            "Epoch [181/300], Step [16/32], Step Loss: 0.0060\n",
            "Epoch [181/300], Step [32/32], Step Loss: 0.2028\n",
            "Epoch [181/300], Validation Accuracy: 42.06%\n",
            "Epoch [182/300], Step [16/32], Step Loss: 0.2333\n",
            "Epoch [182/300], Step [32/32], Step Loss: 0.1730\n",
            "Epoch [182/300], Validation Accuracy: 42.45%\n",
            "Epoch [183/300], Step [16/32], Step Loss: 0.2854\n",
            "Epoch [183/300], Step [32/32], Step Loss: 0.0947\n",
            "Epoch [183/300], Validation Accuracy: 40.88%\n",
            "Epoch [184/300], Step [16/32], Step Loss: 0.0272\n",
            "Epoch [184/300], Step [32/32], Step Loss: 0.0838\n",
            "Epoch [184/300], Validation Accuracy: 43.73%\n",
            "Epoch [185/300], Step [16/32], Step Loss: 0.1695\n",
            "Epoch [185/300], Step [32/32], Step Loss: 0.0442\n",
            "Epoch [185/300], Validation Accuracy: 41.76%\n",
            "Epoch [186/300], Step [16/32], Step Loss: 0.0751\n",
            "Epoch [186/300], Step [32/32], Step Loss: 0.2952\n",
            "Epoch [186/300], Validation Accuracy: 44.51%\n",
            "Epoch [187/300], Step [16/32], Step Loss: 0.0290\n",
            "Epoch [187/300], Step [32/32], Step Loss: 0.0882\n",
            "Epoch [187/300], Validation Accuracy: 42.65%\n",
            "Epoch [188/300], Step [16/32], Step Loss: 0.1832\n",
            "Epoch [188/300], Step [32/32], Step Loss: 0.3801\n",
            "Epoch [188/300], Validation Accuracy: 43.92%\n",
            "Epoch [189/300], Step [16/32], Step Loss: 0.2176\n",
            "Epoch [189/300], Step [32/32], Step Loss: 0.1294\n",
            "Epoch [189/300], Validation Accuracy: 43.63%\n",
            "Epoch [190/300], Step [16/32], Step Loss: 0.4084\n",
            "Epoch [190/300], Step [32/32], Step Loss: 0.4965\n",
            "Epoch [190/300], Validation Accuracy: 42.55%\n",
            "Epoch [191/300], Step [16/32], Step Loss: 0.1614\n",
            "Epoch [191/300], Step [32/32], Step Loss: 0.0853\n",
            "Epoch [191/300], Validation Accuracy: 42.84%\n",
            "Epoch [192/300], Step [16/32], Step Loss: 0.2702\n",
            "Epoch [192/300], Step [32/32], Step Loss: 0.0726\n",
            "Epoch [192/300], Validation Accuracy: 42.55%\n",
            "Epoch [193/300], Step [16/32], Step Loss: 0.3378\n",
            "Epoch [193/300], Step [32/32], Step Loss: 0.1626\n",
            "Epoch [193/300], Validation Accuracy: 42.55%\n",
            "Epoch [194/300], Step [16/32], Step Loss: 0.0536\n",
            "Epoch [194/300], Step [32/32], Step Loss: 0.1231\n",
            "Epoch [194/300], Validation Accuracy: 43.82%\n",
            "Epoch [195/300], Step [16/32], Step Loss: 0.2904\n",
            "Epoch [195/300], Step [32/32], Step Loss: 0.3039\n",
            "Epoch [195/300], Validation Accuracy: 43.43%\n",
            "Epoch [196/300], Step [16/32], Step Loss: 0.1035\n",
            "Epoch [196/300], Step [32/32], Step Loss: 0.0888\n",
            "Epoch [196/300], Validation Accuracy: 42.84%\n",
            "Epoch [197/300], Step [16/32], Step Loss: 0.0344\n",
            "Epoch [197/300], Step [32/32], Step Loss: 0.4821\n",
            "Epoch [197/300], Validation Accuracy: 45.98%\n",
            "Epoch [198/300], Step [16/32], Step Loss: 0.2902\n",
            "Epoch [198/300], Step [32/32], Step Loss: 0.1112\n",
            "Epoch [198/300], Validation Accuracy: 41.27%\n",
            "Epoch [199/300], Step [16/32], Step Loss: 0.2333\n",
            "Epoch [199/300], Step [32/32], Step Loss: 0.0637\n",
            "Epoch [199/300], Validation Accuracy: 44.31%\n",
            "Epoch [200/300], Step [16/32], Step Loss: 0.0677\n",
            "Epoch [200/300], Step [32/32], Step Loss: 0.1074\n",
            "Epoch [200/300], Validation Accuracy: 43.53%\n",
            "Epoch [201/300], Step [16/32], Step Loss: 0.1711\n",
            "Epoch [201/300], Step [32/32], Step Loss: 0.1820\n",
            "Epoch [201/300], Validation Accuracy: 41.96%\n",
            "Epoch [202/300], Step [16/32], Step Loss: 0.2323\n",
            "Epoch [202/300], Step [32/32], Step Loss: 0.4271\n",
            "Epoch [202/300], Validation Accuracy: 42.94%\n",
            "Epoch [203/300], Step [16/32], Step Loss: 0.4028\n",
            "Epoch [203/300], Step [32/32], Step Loss: 0.2196\n",
            "Epoch [203/300], Validation Accuracy: 43.92%\n",
            "Epoch [204/300], Step [16/32], Step Loss: 0.1925\n",
            "Epoch [204/300], Step [32/32], Step Loss: 0.2962\n",
            "Epoch [204/300], Validation Accuracy: 43.43%\n",
            "Epoch [205/300], Step [16/32], Step Loss: 0.2128\n",
            "Epoch [205/300], Step [32/32], Step Loss: 0.2751\n",
            "Epoch [205/300], Validation Accuracy: 43.33%\n",
            "Epoch [206/300], Step [16/32], Step Loss: 0.1200\n",
            "Epoch [206/300], Step [32/32], Step Loss: 0.0960\n",
            "Epoch [206/300], Validation Accuracy: 44.12%\n",
            "Epoch [207/300], Step [16/32], Step Loss: 0.1221\n",
            "Epoch [207/300], Step [32/32], Step Loss: 0.0648\n",
            "Epoch [207/300], Validation Accuracy: 40.59%\n",
            "Epoch [208/300], Step [16/32], Step Loss: 0.1487\n",
            "Epoch [208/300], Step [32/32], Step Loss: 0.2000\n",
            "Epoch [208/300], Validation Accuracy: 44.61%\n",
            "Epoch [209/300], Step [16/32], Step Loss: 0.1091\n",
            "Epoch [209/300], Step [32/32], Step Loss: 0.1966\n",
            "Epoch [209/300], Validation Accuracy: 42.75%\n",
            "Epoch [210/300], Step [16/32], Step Loss: 0.5659\n",
            "Epoch [210/300], Step [32/32], Step Loss: 0.0706\n",
            "Epoch [210/300], Validation Accuracy: 42.45%\n",
            "Epoch [211/300], Step [16/32], Step Loss: 0.2094\n",
            "Epoch [211/300], Step [32/32], Step Loss: 0.3417\n",
            "Epoch [211/300], Validation Accuracy: 43.33%\n",
            "Epoch [212/300], Step [16/32], Step Loss: 0.0482\n",
            "Epoch [212/300], Step [32/32], Step Loss: 0.1220\n",
            "Epoch [212/300], Validation Accuracy: 45.59%\n",
            "Epoch [213/300], Step [16/32], Step Loss: 0.2098\n",
            "Epoch [213/300], Step [32/32], Step Loss: 0.4411\n",
            "Epoch [213/300], Validation Accuracy: 44.31%\n",
            "Epoch [214/300], Step [16/32], Step Loss: 0.0463\n",
            "Epoch [214/300], Step [32/32], Step Loss: 0.2258\n",
            "Epoch [214/300], Validation Accuracy: 43.63%\n",
            "Epoch [215/300], Step [16/32], Step Loss: 0.1222\n",
            "Epoch [215/300], Step [32/32], Step Loss: 0.0836\n",
            "Epoch [215/300], Validation Accuracy: 43.82%\n",
            "Epoch [216/300], Step [16/32], Step Loss: 0.2277\n",
            "Epoch [216/300], Step [32/32], Step Loss: 0.1615\n",
            "Epoch [216/300], Validation Accuracy: 43.73%\n",
            "Epoch [217/300], Step [16/32], Step Loss: 0.3456\n",
            "Epoch [217/300], Step [32/32], Step Loss: 0.0646\n",
            "Epoch [217/300], Validation Accuracy: 41.96%\n",
            "Epoch [218/300], Step [16/32], Step Loss: 0.2132\n",
            "Epoch [218/300], Step [32/32], Step Loss: 0.3481\n",
            "Epoch [218/300], Validation Accuracy: 43.82%\n",
            "Epoch [219/300], Step [16/32], Step Loss: 0.2348\n",
            "Epoch [219/300], Step [32/32], Step Loss: 0.0955\n",
            "Epoch [219/300], Validation Accuracy: 42.25%\n",
            "Epoch [220/300], Step [16/32], Step Loss: 0.2631\n",
            "Epoch [220/300], Step [32/32], Step Loss: 0.0916\n",
            "Epoch [220/300], Validation Accuracy: 45.00%\n",
            "Epoch [221/300], Step [16/32], Step Loss: 0.1278\n",
            "Epoch [221/300], Step [32/32], Step Loss: 0.1476\n",
            "Epoch [221/300], Validation Accuracy: 43.33%\n",
            "Epoch [222/300], Step [16/32], Step Loss: 0.1463\n",
            "Epoch [222/300], Step [32/32], Step Loss: 0.1117\n",
            "Epoch [222/300], Validation Accuracy: 42.55%\n",
            "Epoch [223/300], Step [16/32], Step Loss: 0.0096\n",
            "Epoch [223/300], Step [32/32], Step Loss: 0.0911\n",
            "Epoch [223/300], Validation Accuracy: 42.75%\n",
            "Epoch [224/300], Step [16/32], Step Loss: 0.4642\n",
            "Epoch [224/300], Step [32/32], Step Loss: 0.0816\n",
            "Epoch [224/300], Validation Accuracy: 43.73%\n",
            "Epoch [225/300], Step [16/32], Step Loss: 0.2178\n",
            "Epoch [225/300], Step [32/32], Step Loss: 0.1583\n",
            "Epoch [225/300], Validation Accuracy: 44.22%\n",
            "Epoch [226/300], Step [16/32], Step Loss: 0.0225\n",
            "Epoch [226/300], Step [32/32], Step Loss: 0.1187\n",
            "Epoch [226/300], Validation Accuracy: 42.94%\n",
            "Epoch [227/300], Step [16/32], Step Loss: 0.1255\n",
            "Epoch [227/300], Step [32/32], Step Loss: 0.1938\n",
            "Epoch [227/300], Validation Accuracy: 43.33%\n",
            "Epoch [228/300], Step [16/32], Step Loss: 0.0612\n",
            "Epoch [228/300], Step [32/32], Step Loss: 0.0785\n",
            "Epoch [228/300], Validation Accuracy: 43.33%\n",
            "Epoch [229/300], Step [16/32], Step Loss: 0.0290\n",
            "Epoch [229/300], Step [32/32], Step Loss: 0.0581\n",
            "Epoch [229/300], Validation Accuracy: 46.27%\n",
            "Epoch [230/300], Step [16/32], Step Loss: 0.0757\n",
            "Epoch [230/300], Step [32/32], Step Loss: 0.0423\n",
            "Epoch [230/300], Validation Accuracy: 45.49%\n",
            "Epoch [231/300], Step [16/32], Step Loss: 0.1635\n",
            "Epoch [231/300], Step [32/32], Step Loss: 0.1332\n",
            "Epoch [231/300], Validation Accuracy: 44.31%\n",
            "Epoch [232/300], Step [16/32], Step Loss: 0.1335\n",
            "Epoch [232/300], Step [32/32], Step Loss: 0.1088\n",
            "Epoch [232/300], Validation Accuracy: 43.43%\n",
            "Epoch [233/300], Step [16/32], Step Loss: 0.0203\n",
            "Epoch [233/300], Step [32/32], Step Loss: 0.1077\n",
            "Epoch [233/300], Validation Accuracy: 43.82%\n",
            "Epoch [234/300], Step [16/32], Step Loss: 0.2355\n",
            "Epoch [234/300], Step [32/32], Step Loss: 0.0462\n",
            "Epoch [234/300], Validation Accuracy: 45.20%\n",
            "Epoch [235/300], Step [16/32], Step Loss: 0.1741\n",
            "Epoch [235/300], Step [32/32], Step Loss: 0.0688\n",
            "Epoch [235/300], Validation Accuracy: 44.41%\n",
            "Epoch [236/300], Step [16/32], Step Loss: 0.1001\n",
            "Epoch [236/300], Step [32/32], Step Loss: 0.0562\n",
            "Epoch [236/300], Validation Accuracy: 43.14%\n",
            "Epoch [237/300], Step [16/32], Step Loss: 0.1641\n",
            "Epoch [237/300], Step [32/32], Step Loss: 0.0652\n",
            "Epoch [237/300], Validation Accuracy: 41.18%\n",
            "Epoch [238/300], Step [16/32], Step Loss: 0.3639\n",
            "Epoch [238/300], Step [32/32], Step Loss: 0.1393\n",
            "Epoch [238/300], Validation Accuracy: 43.24%\n",
            "Epoch [239/300], Step [16/32], Step Loss: 0.0590\n",
            "Epoch [239/300], Step [32/32], Step Loss: 0.0633\n",
            "Epoch [239/300], Validation Accuracy: 42.65%\n",
            "Epoch [240/300], Step [16/32], Step Loss: 0.1134\n",
            "Epoch [240/300], Step [32/32], Step Loss: 0.1946\n",
            "Epoch [240/300], Validation Accuracy: 44.80%\n",
            "Epoch [241/300], Step [16/32], Step Loss: 0.1030\n",
            "Epoch [241/300], Step [32/32], Step Loss: 0.0792\n",
            "Epoch [241/300], Validation Accuracy: 44.02%\n",
            "Epoch [242/300], Step [16/32], Step Loss: 0.1377\n",
            "Epoch [242/300], Step [32/32], Step Loss: 0.1730\n",
            "Epoch [242/300], Validation Accuracy: 46.18%\n",
            "Epoch [243/300], Step [16/32], Step Loss: 0.1998\n",
            "Epoch [243/300], Step [32/32], Step Loss: 0.1850\n",
            "Epoch [243/300], Validation Accuracy: 45.39%\n",
            "Epoch [244/300], Step [16/32], Step Loss: 0.3555\n",
            "Epoch [244/300], Step [32/32], Step Loss: 0.2018\n",
            "Epoch [244/300], Validation Accuracy: 46.76%\n",
            "Epoch [245/300], Step [16/32], Step Loss: 0.0936\n",
            "Epoch [245/300], Step [32/32], Step Loss: 0.1855\n",
            "Epoch [245/300], Validation Accuracy: 46.08%\n",
            "Epoch [246/300], Step [16/32], Step Loss: 0.1461\n",
            "Epoch [246/300], Step [32/32], Step Loss: 0.1419\n",
            "Epoch [246/300], Validation Accuracy: 42.35%\n",
            "Epoch [247/300], Step [16/32], Step Loss: 0.0174\n",
            "Epoch [247/300], Step [32/32], Step Loss: 0.1009\n",
            "Epoch [247/300], Validation Accuracy: 47.06%\n",
            "Epoch [248/300], Step [16/32], Step Loss: 0.0672\n",
            "Epoch [248/300], Step [32/32], Step Loss: 0.0221\n",
            "Epoch [248/300], Validation Accuracy: 44.02%\n",
            "Epoch [249/300], Step [16/32], Step Loss: 0.0744\n",
            "Epoch [249/300], Step [32/32], Step Loss: 0.1711\n",
            "Epoch [249/300], Validation Accuracy: 45.59%\n",
            "Epoch [250/300], Step [16/32], Step Loss: 0.0434\n",
            "Epoch [250/300], Step [32/32], Step Loss: 0.3683\n",
            "Epoch [250/300], Validation Accuracy: 41.18%\n",
            "Epoch [251/300], Step [16/32], Step Loss: 0.1195\n",
            "Epoch [251/300], Step [32/32], Step Loss: 0.1845\n",
            "Epoch [251/300], Validation Accuracy: 43.92%\n",
            "Epoch [252/300], Step [16/32], Step Loss: 0.1386\n",
            "Epoch [252/300], Step [32/32], Step Loss: 0.0895\n",
            "Epoch [252/300], Validation Accuracy: 43.73%\n",
            "Epoch [253/300], Step [16/32], Step Loss: 0.2408\n",
            "Epoch [253/300], Step [32/32], Step Loss: 0.1189\n",
            "Epoch [253/300], Validation Accuracy: 45.00%\n",
            "Epoch [254/300], Step [16/32], Step Loss: 0.0802\n",
            "Epoch [254/300], Step [32/32], Step Loss: 0.1030\n",
            "Epoch [254/300], Validation Accuracy: 43.63%\n",
            "Epoch [255/300], Step [16/32], Step Loss: 0.2264\n",
            "Epoch [255/300], Step [32/32], Step Loss: 0.1534\n",
            "Epoch [255/300], Validation Accuracy: 46.18%\n",
            "Epoch [256/300], Step [16/32], Step Loss: 0.0845\n",
            "Epoch [256/300], Step [32/32], Step Loss: 0.0310\n",
            "Epoch [256/300], Validation Accuracy: 45.00%\n",
            "Epoch [257/300], Step [16/32], Step Loss: 0.0579\n",
            "Epoch [257/300], Step [32/32], Step Loss: 0.1284\n",
            "Epoch [257/300], Validation Accuracy: 46.47%\n",
            "Epoch [258/300], Step [16/32], Step Loss: 0.0422\n",
            "Epoch [258/300], Step [32/32], Step Loss: 0.0245\n",
            "Epoch [258/300], Validation Accuracy: 45.20%\n",
            "Epoch [259/300], Step [16/32], Step Loss: 0.1554\n",
            "Epoch [259/300], Step [32/32], Step Loss: 0.0723\n",
            "Epoch [259/300], Validation Accuracy: 47.25%\n",
            "Epoch [260/300], Step [16/32], Step Loss: 0.0764\n",
            "Epoch [260/300], Step [32/32], Step Loss: 0.1511\n",
            "Epoch [260/300], Validation Accuracy: 44.31%\n",
            "Epoch [261/300], Step [16/32], Step Loss: 0.0269\n",
            "Epoch [261/300], Step [32/32], Step Loss: 0.3215\n",
            "Epoch [261/300], Validation Accuracy: 45.20%\n",
            "Epoch [262/300], Step [16/32], Step Loss: 0.0442\n",
            "Epoch [262/300], Step [32/32], Step Loss: 0.0369\n",
            "Epoch [262/300], Validation Accuracy: 46.47%\n",
            "Epoch [263/300], Step [16/32], Step Loss: 0.0305\n",
            "Epoch [263/300], Step [32/32], Step Loss: 0.1800\n",
            "Epoch [263/300], Validation Accuracy: 45.88%\n",
            "Epoch [264/300], Step [16/32], Step Loss: 0.2184\n",
            "Epoch [264/300], Step [32/32], Step Loss: 0.0207\n",
            "Epoch [264/300], Validation Accuracy: 42.45%\n",
            "Epoch [265/300], Step [16/32], Step Loss: 0.0206\n",
            "Epoch [265/300], Step [32/32], Step Loss: 0.0358\n",
            "Epoch [265/300], Validation Accuracy: 43.73%\n",
            "Epoch [266/300], Step [16/32], Step Loss: 0.0418\n",
            "Epoch [266/300], Step [32/32], Step Loss: 0.3635\n",
            "Epoch [266/300], Validation Accuracy: 42.84%\n",
            "Epoch [267/300], Step [16/32], Step Loss: 0.1230\n",
            "Epoch [267/300], Step [32/32], Step Loss: 0.0774\n",
            "Epoch [267/300], Validation Accuracy: 43.53%\n",
            "Epoch [268/300], Step [16/32], Step Loss: 0.1187\n",
            "Epoch [268/300], Step [32/32], Step Loss: 0.4281\n",
            "Epoch [268/300], Validation Accuracy: 44.31%\n",
            "Epoch [269/300], Step [16/32], Step Loss: 0.0589\n",
            "Epoch [269/300], Step [32/32], Step Loss: 0.3620\n",
            "Epoch [269/300], Validation Accuracy: 45.10%\n",
            "Epoch [270/300], Step [16/32], Step Loss: 0.0220\n",
            "Epoch [270/300], Step [32/32], Step Loss: 0.0121\n",
            "Epoch [270/300], Validation Accuracy: 43.92%\n",
            "Epoch [271/300], Step [16/32], Step Loss: 0.0438\n",
            "Epoch [271/300], Step [32/32], Step Loss: 0.0311\n",
            "Epoch [271/300], Validation Accuracy: 44.12%\n",
            "Epoch [272/300], Step [16/32], Step Loss: 0.0247\n",
            "Epoch [272/300], Step [32/32], Step Loss: 0.2227\n",
            "Epoch [272/300], Validation Accuracy: 48.53%\n",
            "Epoch [273/300], Step [16/32], Step Loss: 0.0036\n",
            "Epoch [273/300], Step [32/32], Step Loss: 0.1316\n",
            "Epoch [273/300], Validation Accuracy: 44.61%\n",
            "Epoch [274/300], Step [16/32], Step Loss: 0.0845\n",
            "Epoch [274/300], Step [32/32], Step Loss: 0.3774\n",
            "Epoch [274/300], Validation Accuracy: 44.61%\n",
            "Epoch [275/300], Step [16/32], Step Loss: 0.0223\n",
            "Epoch [275/300], Step [32/32], Step Loss: 0.1253\n",
            "Epoch [275/300], Validation Accuracy: 42.45%\n",
            "Epoch [276/300], Step [16/32], Step Loss: 0.0329\n",
            "Epoch [276/300], Step [32/32], Step Loss: 0.1154\n",
            "Epoch [276/300], Validation Accuracy: 46.18%\n",
            "Epoch [277/300], Step [16/32], Step Loss: 0.1376\n",
            "Epoch [277/300], Step [32/32], Step Loss: 0.0859\n",
            "Epoch [277/300], Validation Accuracy: 44.02%\n",
            "Epoch [278/300], Step [16/32], Step Loss: 0.0592\n",
            "Epoch [278/300], Step [32/32], Step Loss: 0.0755\n",
            "Epoch [278/300], Validation Accuracy: 44.71%\n",
            "Epoch [279/300], Step [16/32], Step Loss: 0.2281\n",
            "Epoch [279/300], Step [32/32], Step Loss: 0.0192\n",
            "Epoch [279/300], Validation Accuracy: 45.88%\n",
            "Epoch [280/300], Step [16/32], Step Loss: 0.0172\n",
            "Epoch [280/300], Step [32/32], Step Loss: 0.0214\n",
            "Epoch [280/300], Validation Accuracy: 42.84%\n",
            "Epoch [281/300], Step [16/32], Step Loss: 0.1695\n",
            "Epoch [281/300], Step [32/32], Step Loss: 0.0387\n",
            "Epoch [281/300], Validation Accuracy: 45.39%\n",
            "Epoch [282/300], Step [16/32], Step Loss: 0.0490\n",
            "Epoch [282/300], Step [32/32], Step Loss: 0.0632\n",
            "Epoch [282/300], Validation Accuracy: 44.41%\n",
            "Epoch [283/300], Step [16/32], Step Loss: 0.0157\n",
            "Epoch [283/300], Step [32/32], Step Loss: 0.0229\n",
            "Epoch [283/300], Validation Accuracy: 45.00%\n",
            "Epoch [284/300], Step [16/32], Step Loss: 0.1904\n",
            "Epoch [284/300], Step [32/32], Step Loss: 0.0712\n",
            "Epoch [284/300], Validation Accuracy: 39.80%\n",
            "Epoch [285/300], Step [16/32], Step Loss: 0.1429\n",
            "Epoch [285/300], Step [32/32], Step Loss: 0.2541\n",
            "Epoch [285/300], Validation Accuracy: 44.02%\n",
            "Epoch [286/300], Step [16/32], Step Loss: 0.2684\n",
            "Epoch [286/300], Step [32/32], Step Loss: 0.4287\n",
            "Epoch [286/300], Validation Accuracy: 45.69%\n",
            "Epoch [287/300], Step [16/32], Step Loss: 0.0417\n",
            "Epoch [287/300], Step [32/32], Step Loss: 0.2249\n",
            "Epoch [287/300], Validation Accuracy: 43.24%\n",
            "Epoch [288/300], Step [16/32], Step Loss: 0.0278\n",
            "Epoch [288/300], Step [32/32], Step Loss: 0.0142\n",
            "Epoch [288/300], Validation Accuracy: 44.90%\n",
            "Epoch [289/300], Step [16/32], Step Loss: 0.1130\n",
            "Epoch [289/300], Step [32/32], Step Loss: 0.0092\n",
            "Epoch [289/300], Validation Accuracy: 42.94%\n",
            "Epoch [290/300], Step [16/32], Step Loss: 0.1091\n",
            "Epoch [290/300], Step [32/32], Step Loss: 0.0127\n",
            "Epoch [290/300], Validation Accuracy: 46.76%\n",
            "Epoch [291/300], Step [16/32], Step Loss: 0.0245\n",
            "Epoch [291/300], Step [32/32], Step Loss: 0.0742\n",
            "Epoch [291/300], Validation Accuracy: 46.08%\n",
            "Epoch [292/300], Step [16/32], Step Loss: 0.3158\n",
            "Epoch [292/300], Step [32/32], Step Loss: 0.0746\n",
            "Epoch [292/300], Validation Accuracy: 45.69%\n",
            "Epoch [293/300], Step [16/32], Step Loss: 0.0516\n",
            "Epoch [293/300], Step [32/32], Step Loss: 0.0860\n",
            "Epoch [293/300], Validation Accuracy: 44.90%\n",
            "Epoch [294/300], Step [16/32], Step Loss: 0.0302\n",
            "Epoch [294/300], Step [32/32], Step Loss: 0.0282\n",
            "Epoch [294/300], Validation Accuracy: 45.49%\n",
            "Epoch [295/300], Step [16/32], Step Loss: 0.0787\n",
            "Epoch [295/300], Step [32/32], Step Loss: 0.0355\n",
            "Epoch [295/300], Validation Accuracy: 45.49%\n",
            "Epoch [296/300], Step [16/32], Step Loss: 0.1786\n",
            "Epoch [296/300], Step [32/32], Step Loss: 0.2614\n",
            "Epoch [296/300], Validation Accuracy: 46.27%\n",
            "Epoch [297/300], Step [16/32], Step Loss: 0.0711\n",
            "Epoch [297/300], Step [32/32], Step Loss: 0.1672\n",
            "Epoch [297/300], Validation Accuracy: 45.10%\n",
            "Epoch [298/300], Step [16/32], Step Loss: 0.0230\n",
            "Epoch [298/300], Step [32/32], Step Loss: 0.0382\n",
            "Epoch [298/300], Validation Accuracy: 42.94%\n",
            "Epoch [299/300], Step [16/32], Step Loss: 0.0189\n",
            "Epoch [299/300], Step [32/32], Step Loss: 0.0897\n",
            "Epoch [299/300], Validation Accuracy: 46.08%\n",
            "Epoch [300/300], Step [16/32], Step Loss: 0.0162\n",
            "Epoch [300/300], Step [32/32], Step Loss: 0.0265\n",
            "Epoch [300/300], Validation Accuracy: 44.22%\n",
            "Training Complete in: 03h 06m 24s\n"
          ]
        }
      ],
      "source": [
        "import torch, time, gc\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as grid\n",
        "\n",
        "# Setup device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "SAVE_PATH = \"./neural_net.pth\"\n",
        "\n",
        "# Training variables\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 300\n",
        "LEARNING_RATE = 0.00005\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256, antialias=True),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
        "    transforms.RandomGrayscale(p=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the train and test datasets\n",
        "train_dataset = datasets.Flowers102(root=\"./data\", split=\"train\", transform=transform, download=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "test_dataset = datasets.Flowers102(root=\"./data\", split=\"test\", transform=transform, download=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "val_dataset = datasets.Flowers102(root=\"./data\", split=\"val\", transform=transform, download=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "val_accuracies = []\n",
        "\n",
        "\n",
        "# Define the CNN architecture\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(64),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2)) # 224 -> 112\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(128),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.Dropout(p=0.1),\n",
        "                                   nn.MaxPool2d(2, 2)) # 112 -> 56\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(128),\n",
        "                                   nn.ReLU())\n",
        "        self.conv4 = nn.Sequential(nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(128),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2)) # 56 -> 28\n",
        "        self.conv5 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(256),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.Dropout(p=0.1))\n",
        "        self.conv6 = nn.Sequential(nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(256),\n",
        "                                   nn.ReLU())\n",
        "        self.conv7 = nn.Sequential(nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(256),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2)) # 28 -> 14\n",
        "        self.conv8 = nn.Sequential(nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(512),\n",
        "                                   nn.ReLU())\n",
        "        self.conv9 = nn.Sequential(nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(512),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2)) # 14 -> 7\n",
        "        self.fc1 = nn.Sequential(nn.Linear(7 * 7 * 512, 4096),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Dropout(0.5))\n",
        "        self.fc2 = nn.Sequential(nn.Linear(4096, 4096),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Dropout(0.5))\n",
        "        self.fc3 = nn.Sequential(nn.Linear(4096, 102))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.conv6(x)\n",
        "        x = self.conv7(x)\n",
        "        x = self.conv8(x)\n",
        "        x = self.conv9(x)\n",
        "        x = x.view(-1, 7 * 7 * 512)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Clear cuda cache\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Create an instance of the CNN and move it to the device\n",
        "cnn = CNN().to(device)\n",
        "print(cnn)\n",
        "\n",
        "# Define the loss function and the optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cnn.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Setup timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the CNN\n",
        "for epoch in range(EPOCHS):\n",
        "    cnn.train()\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        labels = torch.eye(102)[labels] # one hot encode\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = cnn(images) # train\n",
        "        labels = torch.argmax(labels, dim=1) # one hot decode\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 16 == 0:\n",
        "            print(f\"Epoch [{epoch + 1}/{EPOCHS}], Step [{i + 1}/{len(train_loader)}], Step Loss: {loss.item():.4f}\")\n",
        "\n",
        "    # Evaluate model after each training epoch\n",
        "    cnn.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = cnn(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f'Epoch [{epoch+1}/{EPOCHS}], Validation Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "    # save accuracy\n",
        "    val_accuracies.append(accuracy)\n",
        "\n",
        "# Output time taken to train\n",
        "end_time = time.time()\n",
        "print(\"Training Complete in: \" + time.strftime(\"%Hh %Mm %Ss\", time.gmtime(end_time - start_time)))"
      ]
    }
  ]
}