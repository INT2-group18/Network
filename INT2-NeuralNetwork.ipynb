{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObGYlK241kqwc63/NLtpku",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/INT2-group18/Network/blob/main/INT2-NeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tH3QdrT0wjst"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0ZhlsjKQklxP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import ConcatDataset\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "img_size = (300, 300)\n",
        "transform = transforms.Compose([transforms.Resize(img_size), ToTensor()])\n",
        "transform2 =  transforms.Compose([transforms.Resize(img_size), transforms.RandomRotation(90), transforms.RandomHorizontalFlip(), transforms.ColorJitter(hue=.05, saturation=.05), ToTensor()])\n",
        "transform3 = transforms.Compose([transforms.Resize(img_size), ToTensor(), transforms.ColorJitter(hue=.02, saturation=.02), transforms.RandomHorizontalFlip(), transforms.RandomRotation(20), transforms.Grayscale(num_output_channels=3)])\n",
        "training_data1 = datasets.Flowers102(root=\"../flowerData\", split=\"train\", download=True, transform=transform)\n",
        "training_data2 = datasets.Flowers102(root=\"../flowerData\", split=\"train\", download=True, transform=transform2)\n",
        "training_data3 = datasets.Flowers102(root=\"../flowerData\", split=\"train\", download=True, transform=transform2)\n",
        "training_data4 = datasets.Flowers102(root=\"../flowerData\", split=\"train\", download=True, transform=transform2)\n",
        "training_data = ConcatDataset([training_data1, training_data2, training_data3, training_data4])\n",
        "test_data1 = datasets.Flowers102(root=\"../flowerData\", split=\"test\", download=True, transform=transform)\n",
        "test_data = ConcatDataset([test_data1])\n",
        "training_data_full = ConcatDataset([training_data1, training_data2, training_data3, training_data4])\n",
        "\n",
        "\n",
        "\n",
        "# Split the training data into train and validation sets with an 80/20 ratio\n",
        "train_size = int(0.8 * len(training_data_full))\n",
        "val_size = len(training_data_full) - train_size\n",
        "training_data, validation_data = random_split(training_data_full, [train_size, val_size])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OfViLkJmOLl",
        "outputId": "4b0094d6-0c47-436c-84e4-b0ff4a8315aa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to ../flowerData/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 344862509/344862509 [00:30<00:00, 11319833.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../flowerData/flowers-102/102flowers.tgz to ../flowerData/flowers-102\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to ../flowerData/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 502/502 [00:00<00:00, 535624.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to ../flowerData/flowers-102/setid.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14989/14989 [00:00<00:00, 15119870.77it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XdR2ZkcHg0HF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2ce650a-28dd-4b2e-d430-d05129ecc668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu1): ReLU()\n",
            "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu2): ReLU()\n",
            "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu3): ReLU()\n",
            "  (pool3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu4): ReLU()\n",
            "  (pool4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv5): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu5): ReLU()\n",
            "  (pool5): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc1): Linear(in_features=41472, out_features=1024, bias=True)\n",
            "  (dropout1): Dropout(p=0.5, inplace=False)\n",
            "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (dropout2): Dropout(p=0.5, inplace=False)\n",
            "  (fc3): Linear(in_features=1024, out_features=102, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=(3,3), stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3,3), stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=(3,3), stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=(2, 2))\n",
        "        \n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=(3,3), stride=1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=(2, 2))\n",
        "        \n",
        "        self.conv5 = nn.Conv2d(256, 512, kernel_size=(3,3), stride=1, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(512)\n",
        "        self.relu5 = nn.ReLU()\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size=(2, 2))\n",
        "        \n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(512 * 9 * 9, 1024)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(1024, 1024)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc3 = nn.Linear(1024, 102)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.pool3(x)\n",
        "        \n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.relu4(x)\n",
        "        x = self.pool4(x)\n",
        "        \n",
        "        x = self.conv5(x)\n",
        "        x = self.bn5(x)\n",
        "        x = self.relu5(x)\n",
        "        x = self.pool5(x)\n",
        "        \n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout2(x)\n",
        "        logits = self.fc3(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YWsmZ7BUg0HF"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimiser):\n",
        "    size = len(dataloader.dataset)\n",
        "    total_loss = 0\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "        \n",
        "        # Backpropagation\n",
        "        optimiser.zero_grad()\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        #if batch % 200 == 0:\n",
        "            #loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            #print(f\"loss: {loss:>7f}    [{current:>5d}/{size:>5d}]\")\n",
        "    print(f\"Avg train loss: {(total_loss/len(dataloader)):>8f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Wn3Xbr0qg0HG"
      },
      "outputs": [],
      "source": [
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            \n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "    \n",
        "learning_rate = 0.0005\n",
        "batch_size = 64\n",
        "epochs = 100\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimiser = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.1, weight_decay=0)\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxTy8o6Ig0HG",
        "outputId": "8a58fac6-e1dd-4a66-9e71-109a3f5fa1df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "Avg train loss: 4.669604\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 1.3%, Avg loss: 4.620359 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Avg train loss: 4.553140\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 2.8%, Avg loss: 4.544501 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Avg train loss: 4.452853\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 4.8%, Avg loss: 4.426299 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Avg train loss: 4.368044\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 6.1%, Avg loss: 4.368923 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Avg train loss: 4.265355\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 7.2%, Avg loss: 4.285997 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Avg train loss: 4.163451\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 7.7%, Avg loss: 4.192699 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Avg train loss: 4.074706\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 9.9%, Avg loss: 4.102925 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Avg train loss: 3.986083\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 9.6%, Avg loss: 4.041917 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Avg train loss: 3.896734\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 12.0%, Avg loss: 3.953640 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Avg train loss: 3.819703\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 13.0%, Avg loss: 3.879618 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Avg train loss: 3.747334\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 14.6%, Avg loss: 3.809194 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Avg train loss: 3.671207\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 16.3%, Avg loss: 3.700368 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Avg train loss: 3.610153\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 12.0%, Avg loss: 3.728109 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Avg train loss: 3.534622\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 15.8%, Avg loss: 3.639458 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Avg train loss: 3.456908\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 16.7%, Avg loss: 3.574107 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Avg train loss: 3.422820\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 16.2%, Avg loss: 3.529503 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Avg train loss: 3.363375\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 19.2%, Avg loss: 3.475614 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Avg train loss: 3.320551\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 19.7%, Avg loss: 3.453604 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Avg train loss: 3.255284\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 21.9%, Avg loss: 3.379648 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Avg train loss: 3.198924\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 19.5%, Avg loss: 3.356544 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Avg train loss: 3.172057\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 21.8%, Avg loss: 3.317272 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Avg train loss: 3.108302\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 21.6%, Avg loss: 3.243496 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Avg train loss: 3.067621\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 22.1%, Avg loss: 3.223241 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Avg train loss: 3.018136\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 24.5%, Avg loss: 3.169505 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Avg train loss: 2.996871\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 24.6%, Avg loss: 3.141164 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Avg train loss: 2.930957\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 22.1%, Avg loss: 3.142426 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Avg train loss: 2.874180\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 23.9%, Avg loss: 3.092602 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Avg train loss: 2.853771\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 24.6%, Avg loss: 3.103747 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Avg train loss: 2.826979\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 26.1%, Avg loss: 3.010771 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "Avg train loss: 2.790178\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 26.1%, Avg loss: 2.999234 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "Avg train loss: 2.745653\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 27.9%, Avg loss: 2.929987 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "Avg train loss: 2.700532\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 27.5%, Avg loss: 2.916322 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "Avg train loss: 2.647519\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 28.1%, Avg loss: 2.925504 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "Avg train loss: 2.649271\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 30.5%, Avg loss: 2.857477 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "Avg train loss: 2.620183\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 32.2%, Avg loss: 2.838963 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "Avg train loss: 2.595920\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 31.2%, Avg loss: 2.773908 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "Avg train loss: 2.557481\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 33.6%, Avg loss: 2.787759 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "Avg train loss: 2.515752\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 32.8%, Avg loss: 2.760139 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "Avg train loss: 2.472783\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 34.1%, Avg loss: 2.740200 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "Avg train loss: 2.434197\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 31.5%, Avg loss: 2.725967 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "Avg train loss: 2.432347\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 32.4%, Avg loss: 2.736623 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "Avg train loss: 2.398406\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 33.2%, Avg loss: 2.649588 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "Avg train loss: 2.352105\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 33.6%, Avg loss: 2.612062 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "Avg train loss: 2.347894\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 33.8%, Avg loss: 2.623625 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "Avg train loss: 2.285630\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 37.6%, Avg loss: 2.542320 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "Avg train loss: 2.269034\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 38.0%, Avg loss: 2.557161 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "Avg train loss: 2.267906\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 38.0%, Avg loss: 2.500568 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "Avg train loss: 2.243932\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 39.8%, Avg loss: 2.474148 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "Avg train loss: 2.214222\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 37.5%, Avg loss: 2.482910 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "Avg train loss: 2.187155\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 37.7%, Avg loss: 2.467219 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "Avg train loss: 2.168833\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 39.5%, Avg loss: 2.434513 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "Avg train loss: 2.117105\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 39.8%, Avg loss: 2.405317 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "Avg train loss: 2.093518\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 41.7%, Avg loss: 2.376196 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "Avg train loss: 2.065327\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 38.6%, Avg loss: 2.391707 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "Avg train loss: 2.051943\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 39.5%, Avg loss: 2.395791 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "Avg train loss: 2.035577\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 41.3%, Avg loss: 2.305683 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "Avg train loss: 2.023606\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 43.5%, Avg loss: 2.273015 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "Avg train loss: 1.974417\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 44.7%, Avg loss: 2.234436 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "Avg train loss: 1.971446\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 43.3%, Avg loss: 2.220536 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "Avg train loss: 1.961898\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 43.1%, Avg loss: 2.288845 \n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "Avg train loss: 1.936278\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 40.3%, Avg loss: 2.297939 \n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "Avg train loss: 1.911734\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 42.3%, Avg loss: 2.209014 \n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "Avg train loss: 1.888815\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 43.6%, Avg loss: 2.155143 \n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "Avg train loss: 1.872928\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 44.4%, Avg loss: 2.152458 \n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "Avg train loss: 1.849346\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 46.4%, Avg loss: 2.161524 \n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "Avg train loss: 1.818259\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 45.6%, Avg loss: 2.155491 \n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "Avg train loss: 1.805494\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 43.5%, Avg loss: 2.115673 \n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "Avg train loss: 1.795754\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 46.8%, Avg loss: 2.116439 \n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "Avg train loss: 1.781959\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 46.7%, Avg loss: 2.078587 \n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "Avg train loss: 1.763967\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 47.4%, Avg loss: 2.031659 \n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "Avg train loss: 1.725402\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 47.4%, Avg loss: 2.034069 \n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "Avg train loss: 1.712781\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 47.8%, Avg loss: 2.014868 \n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "Avg train loss: 1.696024\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 50.0%, Avg loss: 2.009490 \n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "Avg train loss: 1.668661\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 49.4%, Avg loss: 2.000839 \n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "Avg train loss: 1.662535\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 50.7%, Avg loss: 1.951659 \n",
            "\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "Avg train loss: 1.634311\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 49.4%, Avg loss: 1.999741 \n",
            "\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "Avg train loss: 1.620080\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 49.1%, Avg loss: 2.016873 \n",
            "\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "Avg train loss: 1.607654\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 49.9%, Avg loss: 1.959699 \n",
            "\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "Avg train loss: 1.602657\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 48.5%, Avg loss: 1.915869 \n",
            "\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "Avg train loss: 1.576704\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 51.7%, Avg loss: 1.889528 \n",
            "\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "Avg train loss: 1.560711\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 51.2%, Avg loss: 1.886565 \n",
            "\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "Avg train loss: 1.555858\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 50.6%, Avg loss: 1.870898 \n",
            "\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "Avg train loss: 1.529950\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 53.2%, Avg loss: 1.832469 \n",
            "\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "Avg train loss: 1.501790\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 53.2%, Avg loss: 1.791659 \n",
            "\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "Avg train loss: 1.525386\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 51.7%, Avg loss: 1.841855 \n",
            "\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "Avg train loss: 1.478959\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 53.8%, Avg loss: 1.843124 \n",
            "\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "Avg train loss: 1.459182\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 56.0%, Avg loss: 1.798171 \n",
            "\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "Avg train loss: 1.447513\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 54.5%, Avg loss: 1.782825 \n",
            "\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "Avg train loss: 1.437109\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 51.1%, Avg loss: 1.814245 \n",
            "\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "Avg train loss: 1.410098\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 54.4%, Avg loss: 1.780842 \n",
            "\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "Avg train loss: 1.419169\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 54.8%, Avg loss: 1.785925 \n",
            "\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "Avg train loss: 1.371402\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 55.9%, Avg loss: 1.750649 \n",
            "\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "Avg train loss: 1.383640\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 57.1%, Avg loss: 1.740681 \n",
            "\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "Avg train loss: 1.374817\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 55.0%, Avg loss: 1.731176 \n",
            "\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "Avg train loss: 1.356715\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 55.3%, Avg loss: 1.716651 \n",
            "\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "Avg train loss: 1.345101\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 55.5%, Avg loss: 1.696436 \n",
            "\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "Avg train loss: 1.339014\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 54.4%, Avg loss: 1.738621 \n",
            "\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "Avg train loss: 1.324685\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 59.1%, Avg loss: 1.634789 \n",
            "\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "Avg train loss: 1.305250\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 58.8%, Avg loss: 1.610053 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "Avg train loss: 1.313764\n",
            "Validation performance:\n",
            "Test Error: \n",
            " Accuracy: 58.9%, Avg loss: 1.655079 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "validation_dataloader = DataLoader(validation_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimiser)\n",
        "    print(\"Validation performance:\")\n",
        "    test_loop(validation_dataloader, model, loss_fn)\n",
        "\n",
        "print(\"Done!\")"
      ]
    }
  ]
}