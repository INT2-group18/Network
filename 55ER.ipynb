{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iABXs37PYLuP",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using {torch.cuda.get_device_name(0)}')"
      ],
      "metadata": {
        "id": "VHdEPmVXbC_g",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "623dfc1b-6b40-4591-fdd7-c41067584e60"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.15.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.31)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.22.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imfTPkppJp0E",
        "outputId": "6bb90c8c-9ad1-49c1-c622-6c7c20281738"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialise training variables and datasets, split into train, validation and test sets."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "agrX3EK6Jp0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training variables\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 150\n",
        "LEARNING_RATE = 0.0001"
      ],
      "metadata": {
        "id": "WZi6DrrfbEkT",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformations for the train, validation, and test datasets\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(256, antialias=True),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256), antialias=True),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "augment_transform = transforms.Compose([\n",
        "    train_transform,\n",
        "    transforms.RandomApply(\n",
        "        [transforms.RandomApply([transforms.RandomAffine(degrees=359, translate=(0.2, 0.2), shear=(20, 20, 20, 20)),\n",
        "                                 transforms.RandomHorizontalFlip(1), transforms.RandomVerticalFlip(1)], p=0.7),\n",
        "         transforms.ColorJitter(brightness=(0.75, 1.25), contrast=(0.75, 1.25), hue=(-0.15, 0.15),\n",
        "                                saturation=(0.75, 1.25))\n",
        "         ]\n",
        "    )\n",
        "])\n",
        "\n",
        "# Load the train, validation, and test datasets\n",
        "train_dataset = datasets.Flowers102(root=\"./data\", split=\"train\", transform=train_transform, download=True)\n",
        "all_train_data = [train_dataset]\n",
        "for i in range(1):  # augmented train dataset, concatenated with normal train dataset\n",
        "    all_train_data.append(\n",
        "        datasets.Flowers102(root=\"./data\", split=\"train\", transform=augment_transform, download=False))\n",
        "train_dataset_extra = torch.utils.data.ConcatDataset(all_train_data)\n",
        "\n",
        "train_loader = DataLoader(train_dataset_extra, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_dataset = datasets.Flowers102(root=\"./data\", split=\"val\", transform=val_test_transform, download=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "test_dataset = datasets.Flowers102(root=\"./data\", split=\"test\", transform=val_test_transform, download=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "WLXBzxwbbO_w",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "outputs": [],
      "source": [
        "# Data for plots\n",
        "val_accuracies, val_losses, train_accuracies, train_losses = [], [], [], []\n",
        "plt.rcParams['axes.grid'] = True  # grid on all plots"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jB_uO6DpJp0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define CNN model."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "f5C3LZJgJp0K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(16),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2))  # 224 -> 112\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(32),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2))  # 112 -> 56\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(64),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2))  # 56 -> 28\n",
        "        self.conv4 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(128),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2))  # 28 -> 14\n",
        "        self.conv5 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(256),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2))  # 14 -> 7\n",
        "        self.conv6 = nn.Sequential(nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(512),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2))  # 7 -> 3\n",
        "        self.conv7 = nn.Sequential(nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(1024),\n",
        "                                   nn.MaxPool2d(2, 2))  # 3 -> 1\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Sequential(nn.Linear(1024, 512),\n",
        "                                 nn.ReLU())\n",
        "        self.fc2 = nn.Sequential(nn.Linear(512, 256),\n",
        "                                 nn.ReLU())\n",
        "\n",
        "        self.fc3 = nn.Sequential(nn.Linear(256, 102))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.conv6(x)\n",
        "        x = self.conv7(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "yeq6L8fBJp0N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to save the model with the best validation accuracy."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "WlIjCVIIJp0P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "outputs": [],
      "source": [
        "def save_network(network, epoch_label):\n",
        "    save_filename = 'net_%s.pth' % epoch_label\n",
        "    save_path = os.path.join('./savedModels', save_filename)\n",
        "    torch.save(network.cpu().state_dict(), save_path)\n",
        "    if torch.cuda.is_available():\n",
        "       network.cuda()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "FxVSWofuJp0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialise CNN instance and train."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "KjMpRpm7Jp0Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230508_174249-ogsm4k5d</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/faran-team/final-tests/runs/ogsm4k5d' target=\"_blank\">0.0001</a></strong> to <a href='https://wandb.ai/faran-team/final-tests' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/faran-team/final-tests' target=\"_blank\">https://wandb.ai/faran-team/final-tests</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/faran-team/final-tests/runs/ogsm4k5d' target=\"_blank\">https://wandb.ai/faran-team/final-tests/runs/ogsm4k5d</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/faran-team/final-tests/runs/ogsm4k5d?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f26548a5c30>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "wandb.init(\n",
        "    name=str(LEARNING_RATE),\n",
        "    project=\"final-tests\",\n",
        "    config={\n",
        "        \"learning_rate\": LEARNING_RATE,\n",
        "        \"architecture\": \"CNN-256L\",\n",
        "        \"dataset\": \"Flowers102\",\n",
        "        \"epochs\": EPOCHS,\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "N3AUt4HhJp0R",
        "outputId": "0b0f72d0-39aa-4ae9-d6ca-111239a82f57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear CUDA cache\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# Create an instance of the CNN and move it to the device\n",
        "cnn = CNN().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Set weight decay\n",
        "WEIGHT_DECAY = 0.03\n",
        "\n",
        "# Create the optimizer and add weight decay\n",
        "optimizer = optim.Adam(cnn.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "# lr scheduler\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.1, verbose=True)"
      ],
      "metadata": {
        "id": "c3L6lRUEbjFp",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "yhGoXwwnQiQu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "31d005ac-f3e9-4872-d7df-d72652e56dce",
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training with learning rate 0.0001000\n",
            "--------- Epoch 1 ----------\n",
            "Epoch [1/150], Step [32/64], Step Loss: 4.4615\n",
            "Epoch [1/150], Step [64/64], Step Loss: 4.2972\n",
            "Epoch [1/150], Training Loss: 4.4891, Training Accuracy: 4.22%\n",
            "Epoch [1/150], Validation Loss: 4.2246, Validation Accuracy: 8.43%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 2 ----------\n",
            "Epoch [2/150], Step [32/64], Step Loss: 3.8773\n",
            "Epoch [2/150], Step [64/64], Step Loss: 4.0517\n",
            "Epoch [2/150], Training Loss: 4.0002, Training Accuracy: 9.51%\n",
            "Epoch [2/150], Validation Loss: 3.7132, Validation Accuracy: 14.12%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 3 ----------\n",
            "Epoch [3/150], Step [32/64], Step Loss: 3.7270\n",
            "Epoch [3/150], Step [64/64], Step Loss: 3.6400\n",
            "Epoch [3/150], Training Loss: 3.5940, Training Accuracy: 15.05%\n",
            "Epoch [3/150], Validation Loss: 3.2971, Validation Accuracy: 17.55%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 4 ----------\n",
            "Epoch [4/150], Step [32/64], Step Loss: 3.3336\n",
            "Epoch [4/150], Step [64/64], Step Loss: 3.8170\n",
            "Epoch [4/150], Training Loss: 3.2963, Training Accuracy: 19.22%\n",
            "Epoch [4/150], Validation Loss: 3.3040, Validation Accuracy: 17.55%\n",
            "--------- Epoch 5 ----------\n",
            "Epoch [5/150], Step [32/64], Step Loss: 3.0611\n",
            "Epoch [5/150], Step [64/64], Step Loss: 3.2760\n",
            "Epoch [5/150], Training Loss: 3.0703, Training Accuracy: 23.82%\n",
            "Epoch [5/150], Validation Loss: 3.0093, Validation Accuracy: 21.76%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 6 ----------\n",
            "Epoch [6/150], Step [32/64], Step Loss: 3.1506\n",
            "Epoch [6/150], Step [64/64], Step Loss: 3.0910\n",
            "Epoch [6/150], Training Loss: 2.9059, Training Accuracy: 27.65%\n",
            "Epoch [6/150], Validation Loss: 2.8600, Validation Accuracy: 25.98%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 7 ----------\n",
            "Epoch [7/150], Step [32/64], Step Loss: 2.3698\n",
            "Epoch [7/150], Step [64/64], Step Loss: 2.4487\n",
            "Epoch [7/150], Training Loss: 2.7181, Training Accuracy: 32.30%\n",
            "Epoch [7/150], Validation Loss: 2.8014, Validation Accuracy: 29.41%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 8 ----------\n",
            "Epoch [8/150], Step [32/64], Step Loss: 2.8881\n",
            "Epoch [8/150], Step [64/64], Step Loss: 2.8352\n",
            "Epoch [8/150], Training Loss: 2.5750, Training Accuracy: 35.83%\n",
            "Epoch [8/150], Validation Loss: 2.8875, Validation Accuracy: 28.24%\n",
            "--------- Epoch 9 ----------\n",
            "Epoch [9/150], Step [32/64], Step Loss: 2.5666\n",
            "Epoch [9/150], Step [64/64], Step Loss: 2.7578\n",
            "Epoch [9/150], Training Loss: 2.4129, Training Accuracy: 39.90%\n",
            "Epoch [9/150], Validation Loss: 2.6697, Validation Accuracy: 32.45%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 10 ----------\n",
            "Epoch [10/150], Step [32/64], Step Loss: 2.4807\n",
            "Epoch [10/150], Step [64/64], Step Loss: 2.8029\n",
            "Epoch [10/150], Training Loss: 2.3303, Training Accuracy: 42.11%\n",
            "Epoch [10/150], Validation Loss: 2.6836, Validation Accuracy: 31.57%\n",
            "--------- Epoch 11 ----------\n",
            "Epoch [11/150], Step [32/64], Step Loss: 2.1483\n",
            "Epoch [11/150], Step [64/64], Step Loss: 1.9636\n",
            "Epoch [11/150], Training Loss: 2.1739, Training Accuracy: 45.34%\n",
            "Epoch [11/150], Validation Loss: 2.5232, Validation Accuracy: 37.06%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 12 ----------\n",
            "Epoch [12/150], Step [32/64], Step Loss: 2.0934\n",
            "Epoch [12/150], Step [64/64], Step Loss: 1.7167\n",
            "Epoch [12/150], Training Loss: 2.0575, Training Accuracy: 49.31%\n",
            "Epoch [12/150], Validation Loss: 2.5139, Validation Accuracy: 36.08%\n",
            "--------- Epoch 13 ----------\n",
            "Epoch [13/150], Step [32/64], Step Loss: 2.0070\n",
            "Epoch [13/150], Step [64/64], Step Loss: 1.9966\n",
            "Epoch [13/150], Training Loss: 1.9509, Training Accuracy: 51.62%\n",
            "Epoch [13/150], Validation Loss: 2.4716, Validation Accuracy: 37.16%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 14 ----------\n",
            "Epoch [14/150], Step [32/64], Step Loss: 1.8349\n",
            "Epoch [14/150], Step [64/64], Step Loss: 1.9348\n",
            "Epoch [14/150], Training Loss: 1.8511, Training Accuracy: 55.78%\n",
            "Epoch [14/150], Validation Loss: 2.3665, Validation Accuracy: 39.31%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 15 ----------\n",
            "Epoch [15/150], Step [32/64], Step Loss: 1.9571\n",
            "Epoch [15/150], Step [64/64], Step Loss: 1.6249\n",
            "Epoch [15/150], Training Loss: 1.7620, Training Accuracy: 56.47%\n",
            "Epoch [15/150], Validation Loss: 2.3609, Validation Accuracy: 39.12%\n",
            "--------- Epoch 16 ----------\n",
            "Epoch [16/150], Step [32/64], Step Loss: 1.9519\n",
            "Epoch [16/150], Step [64/64], Step Loss: 1.7346\n",
            "Epoch [16/150], Training Loss: 1.7025, Training Accuracy: 56.96%\n",
            "Epoch [16/150], Validation Loss: 2.3199, Validation Accuracy: 41.08%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 17 ----------\n",
            "Epoch [17/150], Step [32/64], Step Loss: 1.3839\n",
            "Epoch [17/150], Step [64/64], Step Loss: 1.4870\n",
            "Epoch [17/150], Training Loss: 1.5752, Training Accuracy: 60.93%\n",
            "Epoch [17/150], Validation Loss: 2.3254, Validation Accuracy: 42.25%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 18 ----------\n",
            "Epoch [18/150], Step [32/64], Step Loss: 1.6947\n",
            "Epoch [18/150], Step [64/64], Step Loss: 1.8531\n",
            "Epoch [18/150], Training Loss: 1.4905, Training Accuracy: 64.41%\n",
            "Epoch [18/150], Validation Loss: 2.2602, Validation Accuracy: 45.20%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 19 ----------\n",
            "Epoch [19/150], Step [32/64], Step Loss: 1.7178\n",
            "Epoch [19/150], Step [64/64], Step Loss: 1.2854\n",
            "Epoch [19/150], Training Loss: 1.4521, Training Accuracy: 65.15%\n",
            "Epoch [19/150], Validation Loss: 2.2433, Validation Accuracy: 43.53%\n",
            "--------- Epoch 20 ----------\n",
            "Epoch [20/150], Step [32/64], Step Loss: 1.4854\n",
            "Epoch [20/150], Step [64/64], Step Loss: 1.0982\n",
            "Epoch [20/150], Training Loss: 1.3569, Training Accuracy: 67.79%\n",
            "Epoch [20/150], Validation Loss: 2.2771, Validation Accuracy: 43.33%\n",
            "--------- Epoch 21 ----------\n",
            "Epoch [21/150], Step [32/64], Step Loss: 1.3416\n",
            "Epoch [21/150], Step [64/64], Step Loss: 1.7312\n",
            "Epoch [21/150], Training Loss: 1.2986, Training Accuracy: 69.75%\n",
            "Epoch [21/150], Validation Loss: 2.2446, Validation Accuracy: 46.27%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 22 ----------\n",
            "Epoch [22/150], Step [32/64], Step Loss: 1.4091\n",
            "Epoch [22/150], Step [64/64], Step Loss: 1.2469\n",
            "Epoch [22/150], Training Loss: 1.2213, Training Accuracy: 71.13%\n",
            "Epoch [22/150], Validation Loss: 2.2572, Validation Accuracy: 43.53%\n",
            "--------- Epoch 23 ----------\n",
            "Epoch [23/150], Step [32/64], Step Loss: 1.1711\n",
            "Epoch [23/150], Step [64/64], Step Loss: 1.5443\n",
            "Epoch [23/150], Training Loss: 1.2402, Training Accuracy: 71.52%\n",
            "Epoch [23/150], Validation Loss: 2.4150, Validation Accuracy: 40.88%\n",
            "--------- Epoch 24 ----------\n",
            "Epoch [24/150], Step [32/64], Step Loss: 1.1412\n",
            "Epoch [24/150], Step [64/64], Step Loss: 1.3816\n",
            "Epoch [24/150], Training Loss: 1.1614, Training Accuracy: 74.31%\n",
            "Epoch [24/150], Validation Loss: 2.2252, Validation Accuracy: 44.22%\n",
            "--------- Epoch 25 ----------\n",
            "Epoch [25/150], Step [32/64], Step Loss: 1.1233\n",
            "Epoch [25/150], Step [64/64], Step Loss: 0.9094\n",
            "Epoch [25/150], Training Loss: 1.1154, Training Accuracy: 75.54%\n",
            "Epoch [25/150], Validation Loss: 2.1176, Validation Accuracy: 48.24%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 26 ----------\n",
            "Epoch [26/150], Step [32/64], Step Loss: 1.4896\n",
            "Epoch [26/150], Step [64/64], Step Loss: 1.2522\n",
            "Epoch [26/150], Training Loss: 1.0645, Training Accuracy: 76.62%\n",
            "Epoch [26/150], Validation Loss: 2.1955, Validation Accuracy: 46.57%\n",
            "--------- Epoch 27 ----------\n",
            "Epoch [27/150], Step [32/64], Step Loss: 0.8188\n",
            "Epoch [27/150], Step [64/64], Step Loss: 0.7893\n",
            "Epoch [27/150], Training Loss: 1.0486, Training Accuracy: 76.52%\n",
            "Epoch [27/150], Validation Loss: 2.1370, Validation Accuracy: 46.47%\n",
            "--------- Epoch 28 ----------\n",
            "Epoch [28/150], Step [32/64], Step Loss: 1.3437\n",
            "Epoch [28/150], Step [64/64], Step Loss: 1.2736\n",
            "Epoch [28/150], Training Loss: 1.0235, Training Accuracy: 78.24%\n",
            "Epoch [28/150], Validation Loss: 2.1205, Validation Accuracy: 46.86%\n",
            "--------- Epoch 29 ----------\n",
            "Epoch [29/150], Step [32/64], Step Loss: 1.0050\n",
            "Epoch [29/150], Step [64/64], Step Loss: 0.9868\n",
            "Epoch [29/150], Training Loss: 0.9575, Training Accuracy: 79.80%\n",
            "Epoch [29/150], Validation Loss: 2.1759, Validation Accuracy: 45.78%\n",
            "--------- Epoch 30 ----------\n",
            "Epoch [30/150], Step [32/64], Step Loss: 1.3746\n",
            "Epoch [30/150], Step [64/64], Step Loss: 0.9396\n",
            "Epoch [30/150], Training Loss: 0.9969, Training Accuracy: 78.04%\n",
            "Epoch [30/150], Validation Loss: 2.1054, Validation Accuracy: 46.27%\n",
            "--------- Epoch 31 ----------\n",
            "Epoch [31/150], Step [32/64], Step Loss: 0.9893\n",
            "Epoch [31/150], Step [64/64], Step Loss: 0.7310\n",
            "Epoch [31/150], Training Loss: 0.9715, Training Accuracy: 79.12%\n",
            "Epoch [31/150], Validation Loss: 2.1606, Validation Accuracy: 46.47%\n",
            "--------- Epoch 32 ----------\n",
            "Epoch [32/150], Step [32/64], Step Loss: 0.9809\n",
            "Epoch [32/150], Step [64/64], Step Loss: 1.3025\n",
            "Epoch [32/150], Training Loss: 0.9371, Training Accuracy: 79.95%\n",
            "Epoch [32/150], Validation Loss: 2.1967, Validation Accuracy: 46.18%\n",
            "--------- Epoch 33 ----------\n",
            "Epoch [33/150], Step [32/64], Step Loss: 1.1927\n",
            "Epoch [33/150], Step [64/64], Step Loss: 0.6717\n",
            "Epoch [33/150], Training Loss: 0.9031, Training Accuracy: 80.93%\n",
            "Epoch [33/150], Validation Loss: 2.0877, Validation Accuracy: 47.55%\n",
            "--------- Epoch 34 ----------\n",
            "Epoch [34/150], Step [32/64], Step Loss: 1.1310\n",
            "Epoch [34/150], Step [64/64], Step Loss: 0.6285\n",
            "Epoch [34/150], Training Loss: 0.9426, Training Accuracy: 80.25%\n",
            "Epoch [34/150], Validation Loss: 2.1302, Validation Accuracy: 49.41%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 35 ----------\n",
            "Epoch [35/150], Step [32/64], Step Loss: 0.6836\n",
            "Epoch [35/150], Step [64/64], Step Loss: 0.7220\n",
            "Epoch [35/150], Training Loss: 0.8890, Training Accuracy: 81.08%\n",
            "Epoch [35/150], Validation Loss: 2.0448, Validation Accuracy: 50.00%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 36 ----------\n",
            "Epoch [36/150], Step [32/64], Step Loss: 0.8184\n",
            "Epoch [36/150], Step [64/64], Step Loss: 1.0358\n",
            "Epoch [36/150], Training Loss: 0.8581, Training Accuracy: 81.81%\n",
            "Epoch [36/150], Validation Loss: 2.0666, Validation Accuracy: 51.76%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 37 ----------\n",
            "Epoch [37/150], Step [32/64], Step Loss: 0.9473\n",
            "Epoch [37/150], Step [64/64], Step Loss: 0.9666\n",
            "Epoch [37/150], Training Loss: 0.9289, Training Accuracy: 79.90%\n",
            "Epoch [37/150], Validation Loss: 2.0773, Validation Accuracy: 49.02%\n",
            "--------- Epoch 38 ----------\n",
            "Epoch [38/150], Step [32/64], Step Loss: 1.2544\n",
            "Epoch [38/150], Step [64/64], Step Loss: 0.6441\n",
            "Epoch [38/150], Training Loss: 0.8993, Training Accuracy: 80.59%\n",
            "Epoch [38/150], Validation Loss: 2.1956, Validation Accuracy: 48.04%\n",
            "--------- Epoch 39 ----------\n",
            "Epoch [39/150], Step [32/64], Step Loss: 0.7436\n",
            "Epoch [39/150], Step [64/64], Step Loss: 0.9324\n",
            "Epoch [39/150], Training Loss: 0.8361, Training Accuracy: 82.75%\n",
            "Epoch [39/150], Validation Loss: 2.0505, Validation Accuracy: 51.37%\n",
            "--------- Epoch 40 ----------\n",
            "Epoch [40/150], Step [32/64], Step Loss: 0.6110\n",
            "Epoch [40/150], Step [64/64], Step Loss: 0.9140\n",
            "Epoch [40/150], Training Loss: 0.8955, Training Accuracy: 80.15%\n",
            "Epoch [40/150], Validation Loss: 2.1088, Validation Accuracy: 49.41%\n",
            "--------- Epoch 41 ----------\n",
            "Epoch [41/150], Step [32/64], Step Loss: 0.9227\n",
            "Epoch [41/150], Step [64/64], Step Loss: 0.5969\n",
            "Epoch [41/150], Training Loss: 0.8617, Training Accuracy: 81.91%\n",
            "Epoch [41/150], Validation Loss: 1.9799, Validation Accuracy: 51.08%\n",
            "--------- Epoch 42 ----------\n",
            "Epoch [42/150], Step [32/64], Step Loss: 1.0248\n",
            "Epoch [42/150], Step [64/64], Step Loss: 0.9857\n",
            "Epoch [42/150], Training Loss: 0.8645, Training Accuracy: 81.18%\n",
            "Epoch [42/150], Validation Loss: 2.0251, Validation Accuracy: 50.78%\n",
            "--------- Epoch 43 ----------\n",
            "Epoch [43/150], Step [32/64], Step Loss: 0.7416\n",
            "Epoch [43/150], Step [64/64], Step Loss: 1.1240\n",
            "Epoch [43/150], Training Loss: 0.8229, Training Accuracy: 82.16%\n",
            "Epoch [43/150], Validation Loss: 2.0546, Validation Accuracy: 50.69%\n",
            "--------- Epoch 44 ----------\n",
            "Epoch [44/150], Step [32/64], Step Loss: 0.7448\n",
            "Epoch [44/150], Step [64/64], Step Loss: 1.0233\n",
            "Epoch [44/150], Training Loss: 0.8380, Training Accuracy: 81.67%\n",
            "Epoch [44/150], Validation Loss: 1.9872, Validation Accuracy: 51.96%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 45 ----------\n",
            "Epoch [45/150], Step [32/64], Step Loss: 0.8194\n",
            "Epoch [45/150], Step [64/64], Step Loss: 1.0116\n",
            "Epoch [45/150], Training Loss: 0.7730, Training Accuracy: 84.12%\n",
            "Epoch [45/150], Validation Loss: 2.0418, Validation Accuracy: 51.57%\n",
            "--------- Epoch 46 ----------\n",
            "Epoch [46/150], Step [32/64], Step Loss: 0.6548\n",
            "Epoch [46/150], Step [64/64], Step Loss: 0.3973\n",
            "Epoch [46/150], Training Loss: 0.8231, Training Accuracy: 82.35%\n",
            "Epoch [46/150], Validation Loss: 2.0446, Validation Accuracy: 50.20%\n",
            "--------- Epoch 47 ----------\n",
            "Epoch [47/150], Step [32/64], Step Loss: 1.1037\n",
            "Epoch [47/150], Step [64/64], Step Loss: 0.6726\n",
            "Epoch [47/150], Training Loss: 0.8447, Training Accuracy: 81.72%\n",
            "Epoch [47/150], Validation Loss: 2.0090, Validation Accuracy: 51.37%\n",
            "--------- Epoch 48 ----------\n",
            "Epoch [48/150], Step [32/64], Step Loss: 0.5480\n",
            "Epoch [48/150], Step [64/64], Step Loss: 1.1704\n",
            "Epoch [48/150], Training Loss: 0.8370, Training Accuracy: 81.96%\n",
            "Epoch [48/150], Validation Loss: 2.0301, Validation Accuracy: 49.61%\n",
            "--------- Epoch 49 ----------\n",
            "Epoch [49/150], Step [32/64], Step Loss: 1.0425\n",
            "Epoch [49/150], Step [64/64], Step Loss: 0.7165\n",
            "Epoch [49/150], Training Loss: 0.8629, Training Accuracy: 80.59%\n",
            "Epoch [49/150], Validation Loss: 2.0695, Validation Accuracy: 48.82%\n",
            "--------- Epoch 50 ----------\n",
            "Epoch [50/150], Step [32/64], Step Loss: 0.8992\n",
            "Epoch [50/150], Step [64/64], Step Loss: 0.6429\n",
            "Epoch [50/150], Training Loss: 0.7859, Training Accuracy: 82.75%\n",
            "Epoch [50/150], Validation Loss: 2.0966, Validation Accuracy: 49.22%\n",
            "--------- Epoch 51 ----------\n",
            "Epoch [51/150], Step [32/64], Step Loss: 0.7068\n",
            "Epoch [51/150], Step [64/64], Step Loss: 0.6380\n",
            "Epoch [51/150], Training Loss: 0.7947, Training Accuracy: 83.33%\n",
            "Epoch [51/150], Validation Loss: 2.0289, Validation Accuracy: 51.47%\n",
            "--------- Epoch 52 ----------\n",
            "Epoch [52/150], Step [32/64], Step Loss: 1.0869\n",
            "Epoch [52/150], Step [64/64], Step Loss: 0.5197\n",
            "Epoch [52/150], Training Loss: 0.7521, Training Accuracy: 83.87%\n",
            "Epoch [52/150], Validation Loss: 1.9489, Validation Accuracy: 52.55%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 53 ----------\n",
            "Epoch [53/150], Step [32/64], Step Loss: 0.7617\n",
            "Epoch [53/150], Step [64/64], Step Loss: 0.8082\n",
            "Epoch [53/150], Training Loss: 0.7691, Training Accuracy: 83.53%\n",
            "Epoch [53/150], Validation Loss: 1.9750, Validation Accuracy: 51.76%\n",
            "--------- Epoch 54 ----------\n",
            "Epoch [54/150], Step [32/64], Step Loss: 1.4427\n",
            "Epoch [54/150], Step [64/64], Step Loss: 0.7024\n",
            "Epoch [54/150], Training Loss: 0.7761, Training Accuracy: 83.77%\n",
            "Epoch [54/150], Validation Loss: 1.9784, Validation Accuracy: 50.10%\n",
            "--------- Epoch 55 ----------\n",
            "Epoch [55/150], Step [32/64], Step Loss: 1.0683\n",
            "Epoch [55/150], Step [64/64], Step Loss: 0.4501\n",
            "Epoch [55/150], Training Loss: 0.7621, Training Accuracy: 84.22%\n",
            "Epoch [55/150], Validation Loss: 1.9433, Validation Accuracy: 51.08%\n",
            "--------- Epoch 56 ----------\n",
            "Epoch [56/150], Step [32/64], Step Loss: 1.1197\n",
            "Epoch [56/150], Step [64/64], Step Loss: 0.7012\n",
            "Epoch [56/150], Training Loss: 0.8193, Training Accuracy: 83.28%\n",
            "Epoch [56/150], Validation Loss: 1.9922, Validation Accuracy: 50.39%\n",
            "--------- Epoch 57 ----------\n",
            "Epoch [57/150], Step [32/64], Step Loss: 0.9928\n",
            "Epoch [57/150], Step [64/64], Step Loss: 0.7179\n",
            "Epoch [57/150], Training Loss: 0.7841, Training Accuracy: 83.38%\n",
            "Epoch [57/150], Validation Loss: 1.9233, Validation Accuracy: 53.33%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 58 ----------\n",
            "Epoch [58/150], Step [32/64], Step Loss: 0.5828\n",
            "Epoch [58/150], Step [64/64], Step Loss: 1.1251\n",
            "Epoch [58/150], Training Loss: 0.7402, Training Accuracy: 84.36%\n",
            "Epoch [58/150], Validation Loss: 2.0527, Validation Accuracy: 51.37%\n",
            "--------- Epoch 59 ----------\n",
            "Epoch [59/150], Step [32/64], Step Loss: 0.8923\n",
            "Epoch [59/150], Step [64/64], Step Loss: 0.4897\n",
            "Epoch [59/150], Training Loss: 0.8318, Training Accuracy: 81.96%\n",
            "Epoch [59/150], Validation Loss: 1.9606, Validation Accuracy: 50.49%\n",
            "--------- Epoch 60 ----------\n",
            "Epoch [60/150], Step [32/64], Step Loss: 0.8950\n",
            "Epoch [60/150], Step [64/64], Step Loss: 0.8149\n",
            "Epoch [60/150], Training Loss: 0.7643, Training Accuracy: 84.61%\n",
            "Epoch [60/150], Validation Loss: 1.9830, Validation Accuracy: 54.12%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 61 ----------\n",
            "Epoch [61/150], Step [32/64], Step Loss: 0.5550\n",
            "Epoch [61/150], Step [64/64], Step Loss: 0.8865\n",
            "Epoch [61/150], Training Loss: 0.8189, Training Accuracy: 82.50%\n",
            "Epoch [61/150], Validation Loss: 2.0224, Validation Accuracy: 51.18%\n",
            "--------- Epoch 62 ----------\n",
            "Epoch [62/150], Step [32/64], Step Loss: 0.7807\n",
            "Epoch [62/150], Step [64/64], Step Loss: 0.6277\n",
            "Epoch [62/150], Training Loss: 0.7807, Training Accuracy: 84.41%\n",
            "Epoch [62/150], Validation Loss: 1.9458, Validation Accuracy: 53.04%\n",
            "--------- Epoch 63 ----------\n",
            "Epoch [63/150], Step [32/64], Step Loss: 0.9037\n",
            "Epoch [63/150], Step [64/64], Step Loss: 0.3377\n",
            "Epoch [63/150], Training Loss: 0.7146, Training Accuracy: 84.75%\n",
            "Epoch [63/150], Validation Loss: 2.0701, Validation Accuracy: 49.22%\n",
            "--------- Epoch 64 ----------\n",
            "Epoch [64/150], Step [32/64], Step Loss: 0.7274\n",
            "Epoch [64/150], Step [64/64], Step Loss: 1.0513\n",
            "Epoch [64/150], Training Loss: 0.7944, Training Accuracy: 82.50%\n",
            "Epoch [64/150], Validation Loss: 2.0554, Validation Accuracy: 49.51%\n",
            "--------- Epoch 65 ----------\n",
            "Epoch [65/150], Step [32/64], Step Loss: 0.5305\n",
            "Epoch [65/150], Step [64/64], Step Loss: 0.8524\n",
            "Epoch [65/150], Training Loss: 0.7684, Training Accuracy: 83.82%\n",
            "Epoch [65/150], Validation Loss: 2.2906, Validation Accuracy: 47.25%\n",
            "--------- Epoch 66 ----------\n",
            "Epoch [66/150], Step [32/64], Step Loss: 0.5261\n",
            "Epoch [66/150], Step [64/64], Step Loss: 1.2442\n",
            "Epoch [66/150], Training Loss: 0.7573, Training Accuracy: 84.22%\n",
            "Epoch [66/150], Validation Loss: 2.0698, Validation Accuracy: 49.71%\n",
            "--------- Epoch 67 ----------\n",
            "Epoch [67/150], Step [32/64], Step Loss: 0.4833\n",
            "Epoch [67/150], Step [64/64], Step Loss: 0.4670\n",
            "Epoch [67/150], Training Loss: 0.7490, Training Accuracy: 84.46%\n",
            "Epoch [67/150], Validation Loss: 2.0476, Validation Accuracy: 49.12%\n",
            "--------- Epoch 68 ----------\n",
            "Epoch [68/150], Step [32/64], Step Loss: 0.8987\n",
            "Epoch [68/150], Step [64/64], Step Loss: 0.6691\n",
            "Epoch [68/150], Training Loss: 0.7277, Training Accuracy: 85.10%\n",
            "Epoch [68/150], Validation Loss: 1.9846, Validation Accuracy: 49.90%\n",
            "Epoch 00068: reducing learning rate of group 0 to 1.0000e-05.\n",
            "--------- Epoch 69 ----------\n",
            "Epoch [69/150], Step [32/64], Step Loss: 0.4290\n",
            "Epoch [69/150], Step [64/64], Step Loss: 0.7472\n",
            "Epoch [69/150], Training Loss: 0.6252, Training Accuracy: 86.67%\n",
            "Epoch [69/150], Validation Loss: 1.7199, Validation Accuracy: 57.25%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 70 ----------\n",
            "Epoch [70/150], Step [32/64], Step Loss: 0.7150\n",
            "Epoch [70/150], Step [64/64], Step Loss: 0.6210\n",
            "Epoch [70/150], Training Loss: 0.5829, Training Accuracy: 87.30%\n",
            "Epoch [70/150], Validation Loss: 1.6930, Validation Accuracy: 57.65%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 71 ----------\n",
            "Epoch [71/150], Step [32/64], Step Loss: 0.8189\n",
            "Epoch [71/150], Step [64/64], Step Loss: 0.4238\n",
            "Epoch [71/150], Training Loss: 0.5729, Training Accuracy: 87.45%\n",
            "Epoch [71/150], Validation Loss: 1.6692, Validation Accuracy: 58.53%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 72 ----------\n",
            "Epoch [72/150], Step [32/64], Step Loss: 0.6126\n",
            "Epoch [72/150], Step [64/64], Step Loss: 0.4366\n",
            "Epoch [72/150], Training Loss: 0.5508, Training Accuracy: 87.70%\n",
            "Epoch [72/150], Validation Loss: 1.6640, Validation Accuracy: 58.63%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 73 ----------\n",
            "Epoch [73/150], Step [32/64], Step Loss: 0.3930\n",
            "Epoch [73/150], Step [64/64], Step Loss: 0.9475\n",
            "Epoch [73/150], Training Loss: 0.5589, Training Accuracy: 87.94%\n",
            "Epoch [73/150], Validation Loss: 1.6818, Validation Accuracy: 58.53%\n",
            "--------- Epoch 74 ----------\n",
            "Epoch [74/150], Step [32/64], Step Loss: 0.4223\n",
            "Epoch [74/150], Step [64/64], Step Loss: 0.5485\n",
            "Epoch [74/150], Training Loss: 0.5399, Training Accuracy: 88.04%\n",
            "Epoch [74/150], Validation Loss: 1.6769, Validation Accuracy: 58.63%\n",
            "--------- Epoch 75 ----------\n",
            "Epoch [75/150], Step [32/64], Step Loss: 0.3293\n",
            "Epoch [75/150], Step [64/64], Step Loss: 0.6067\n",
            "Epoch [75/150], Training Loss: 0.5268, Training Accuracy: 88.24%\n",
            "Epoch [75/150], Validation Loss: 1.6866, Validation Accuracy: 57.75%\n",
            "--------- Epoch 76 ----------\n",
            "Epoch [76/150], Step [32/64], Step Loss: 0.4741\n",
            "Epoch [76/150], Step [64/64], Step Loss: 0.3068\n",
            "Epoch [76/150], Training Loss: 0.5187, Training Accuracy: 88.58%\n",
            "Epoch [76/150], Validation Loss: 1.6683, Validation Accuracy: 59.12%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 77 ----------\n",
            "Epoch [77/150], Step [32/64], Step Loss: 0.5098\n",
            "Epoch [77/150], Step [64/64], Step Loss: 0.9297\n",
            "Epoch [77/150], Training Loss: 0.5227, Training Accuracy: 88.68%\n",
            "Epoch [77/150], Validation Loss: 1.6793, Validation Accuracy: 58.33%\n",
            "--------- Epoch 78 ----------\n",
            "Epoch [78/150], Step [32/64], Step Loss: 0.8450\n",
            "Epoch [78/150], Step [64/64], Step Loss: 0.6842\n",
            "Epoch [78/150], Training Loss: 0.5135, Training Accuracy: 89.12%\n",
            "Epoch [78/150], Validation Loss: 1.6489, Validation Accuracy: 59.22%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 79 ----------\n",
            "Epoch [79/150], Step [32/64], Step Loss: 0.1923\n",
            "Epoch [79/150], Step [64/64], Step Loss: 0.9806\n",
            "Epoch [79/150], Training Loss: 0.5299, Training Accuracy: 88.38%\n",
            "Epoch [79/150], Validation Loss: 1.6749, Validation Accuracy: 58.63%\n",
            "--------- Epoch 80 ----------\n",
            "Epoch [80/150], Step [32/64], Step Loss: 0.3295\n",
            "Epoch [80/150], Step [64/64], Step Loss: 0.4220\n",
            "Epoch [80/150], Training Loss: 0.4980, Training Accuracy: 89.31%\n",
            "Epoch [80/150], Validation Loss: 1.6679, Validation Accuracy: 58.33%\n",
            "--------- Epoch 81 ----------\n",
            "Epoch [81/150], Step [32/64], Step Loss: 0.3496\n",
            "Epoch [81/150], Step [64/64], Step Loss: 0.4072\n",
            "Epoch [81/150], Training Loss: 0.4751, Training Accuracy: 89.95%\n",
            "Epoch [81/150], Validation Loss: 1.6598, Validation Accuracy: 58.73%\n",
            "--------- Epoch 82 ----------\n",
            "Epoch [82/150], Step [32/64], Step Loss: 0.3626\n",
            "Epoch [82/150], Step [64/64], Step Loss: 0.6097\n",
            "Epoch [82/150], Training Loss: 0.5114, Training Accuracy: 88.92%\n",
            "Epoch [82/150], Validation Loss: 1.6659, Validation Accuracy: 58.92%\n",
            "--------- Epoch 83 ----------\n",
            "Epoch [83/150], Step [32/64], Step Loss: 0.6938\n",
            "Epoch [83/150], Step [64/64], Step Loss: 0.2922\n",
            "Epoch [83/150], Training Loss: 0.5193, Training Accuracy: 88.73%\n",
            "Epoch [83/150], Validation Loss: 1.6550, Validation Accuracy: 59.22%\n",
            "--------- Epoch 84 ----------\n",
            "Epoch [84/150], Step [32/64], Step Loss: 0.1522\n",
            "Epoch [84/150], Step [64/64], Step Loss: 0.7528\n",
            "Epoch [84/150], Training Loss: 0.5080, Training Accuracy: 89.71%\n",
            "Epoch [84/150], Validation Loss: 1.6751, Validation Accuracy: 58.43%\n",
            "--------- Epoch 85 ----------\n",
            "Epoch [85/150], Step [32/64], Step Loss: 0.3712\n",
            "Epoch [85/150], Step [64/64], Step Loss: 0.4128\n",
            "Epoch [85/150], Training Loss: 0.4841, Training Accuracy: 90.29%\n",
            "Epoch [85/150], Validation Loss: 1.6327, Validation Accuracy: 59.02%\n",
            "--------- Epoch 86 ----------\n",
            "Epoch [86/150], Step [32/64], Step Loss: 0.2742\n",
            "Epoch [86/150], Step [64/64], Step Loss: 0.6074\n",
            "Epoch [86/150], Training Loss: 0.4984, Training Accuracy: 88.92%\n",
            "Epoch [86/150], Validation Loss: 1.6635, Validation Accuracy: 58.92%\n",
            "--------- Epoch 87 ----------\n",
            "Epoch [87/150], Step [32/64], Step Loss: 0.3257\n",
            "Epoch [87/150], Step [64/64], Step Loss: 0.8456\n",
            "Epoch [87/150], Training Loss: 0.4962, Training Accuracy: 89.51%\n",
            "Epoch [87/150], Validation Loss: 1.6527, Validation Accuracy: 59.41%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 88 ----------\n",
            "Epoch [88/150], Step [32/64], Step Loss: 0.7074\n",
            "Epoch [88/150], Step [64/64], Step Loss: 0.8255\n",
            "Epoch [88/150], Training Loss: 0.5102, Training Accuracy: 88.77%\n",
            "Epoch [88/150], Validation Loss: 1.6709, Validation Accuracy: 59.02%\n",
            "--------- Epoch 89 ----------\n",
            "Epoch [89/150], Step [32/64], Step Loss: 0.3290\n",
            "Epoch [89/150], Step [64/64], Step Loss: 0.3993\n",
            "Epoch [89/150], Training Loss: 0.4720, Training Accuracy: 90.05%\n",
            "Epoch [89/150], Validation Loss: 1.6487, Validation Accuracy: 59.61%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 90 ----------\n",
            "Epoch [90/150], Step [32/64], Step Loss: 0.3146\n",
            "Epoch [90/150], Step [64/64], Step Loss: 0.6501\n",
            "Epoch [90/150], Training Loss: 0.5169, Training Accuracy: 89.46%\n",
            "Epoch [90/150], Validation Loss: 1.6560, Validation Accuracy: 59.61%\n",
            "--------- Epoch 91 ----------\n",
            "Epoch [91/150], Step [32/64], Step Loss: 0.2549\n",
            "Epoch [91/150], Step [64/64], Step Loss: 0.7310\n",
            "Epoch [91/150], Training Loss: 0.4906, Training Accuracy: 89.85%\n",
            "Epoch [91/150], Validation Loss: 1.6675, Validation Accuracy: 59.22%\n",
            "--------- Epoch 92 ----------\n",
            "Epoch [92/150], Step [32/64], Step Loss: 0.4196\n",
            "Epoch [92/150], Step [64/64], Step Loss: 0.3634\n",
            "Epoch [92/150], Training Loss: 0.5032, Training Accuracy: 89.17%\n",
            "Epoch [92/150], Validation Loss: 1.6599, Validation Accuracy: 59.71%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 93 ----------\n",
            "Epoch [93/150], Step [32/64], Step Loss: 0.3044\n",
            "Epoch [93/150], Step [64/64], Step Loss: 0.2163\n",
            "Epoch [93/150], Training Loss: 0.4958, Training Accuracy: 89.46%\n",
            "Epoch [93/150], Validation Loss: 1.6471, Validation Accuracy: 59.80%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 94 ----------\n",
            "Epoch [94/150], Step [32/64], Step Loss: 0.6187\n",
            "Epoch [94/150], Step [64/64], Step Loss: 0.3770\n",
            "Epoch [94/150], Training Loss: 0.5001, Training Accuracy: 89.56%\n",
            "Epoch [94/150], Validation Loss: 1.6752, Validation Accuracy: 59.61%\n",
            "--------- Epoch 95 ----------\n",
            "Epoch [95/150], Step [32/64], Step Loss: 0.4106\n",
            "Epoch [95/150], Step [64/64], Step Loss: 0.6450\n",
            "Epoch [95/150], Training Loss: 0.4650, Training Accuracy: 90.15%\n",
            "Epoch [95/150], Validation Loss: 1.6420, Validation Accuracy: 59.80%\n",
            "--------- Epoch 96 ----------\n",
            "Epoch [96/150], Step [32/64], Step Loss: 0.2556\n",
            "Epoch [96/150], Step [64/64], Step Loss: 0.6884\n",
            "Epoch [96/150], Training Loss: 0.4916, Training Accuracy: 88.92%\n",
            "Epoch [96/150], Validation Loss: 1.6619, Validation Accuracy: 59.61%\n",
            "Epoch 00096: reducing learning rate of group 0 to 1.0000e-06.\n",
            "--------- Epoch 97 ----------\n",
            "Epoch [97/150], Step [32/64], Step Loss: 0.7185\n",
            "Epoch [97/150], Step [64/64], Step Loss: 0.4986\n",
            "Epoch [97/150], Training Loss: 0.4443, Training Accuracy: 90.64%\n",
            "Epoch [97/150], Validation Loss: 1.6559, Validation Accuracy: 59.71%\n",
            "--------- Epoch 98 ----------\n",
            "Epoch [98/150], Step [32/64], Step Loss: 0.4585\n",
            "Epoch [98/150], Step [64/64], Step Loss: 0.4796\n",
            "Epoch [98/150], Training Loss: 0.4918, Training Accuracy: 89.46%\n",
            "Epoch [98/150], Validation Loss: 1.6597, Validation Accuracy: 59.41%\n",
            "--------- Epoch 99 ----------\n",
            "Epoch [99/150], Step [32/64], Step Loss: 0.6252\n",
            "Epoch [99/150], Step [64/64], Step Loss: 0.7639\n",
            "Epoch [99/150], Training Loss: 0.5061, Training Accuracy: 88.77%\n",
            "Epoch [99/150], Validation Loss: 1.6446, Validation Accuracy: 59.71%\n",
            "--------- Epoch 100 ----------\n",
            "Epoch [100/150], Step [32/64], Step Loss: 0.2850\n",
            "Epoch [100/150], Step [64/64], Step Loss: 0.6951\n",
            "Epoch [100/150], Training Loss: 0.4953, Training Accuracy: 89.31%\n",
            "Epoch [100/150], Validation Loss: 1.6529, Validation Accuracy: 59.41%\n",
            "--------- Epoch 101 ----------\n",
            "Epoch [101/150], Step [32/64], Step Loss: 0.3761\n",
            "Epoch [101/150], Step [64/64], Step Loss: 0.6780\n",
            "Epoch [101/150], Training Loss: 0.4696, Training Accuracy: 90.54%\n",
            "Epoch [101/150], Validation Loss: 1.6566, Validation Accuracy: 59.80%\n",
            "--------- Epoch 102 ----------\n",
            "Epoch [102/150], Step [32/64], Step Loss: 0.5112\n",
            "Epoch [102/150], Step [64/64], Step Loss: 0.4004\n",
            "Epoch [102/150], Training Loss: 0.4604, Training Accuracy: 90.64%\n",
            "Epoch [102/150], Validation Loss: 1.6546, Validation Accuracy: 59.90%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 103 ----------\n",
            "Epoch [103/150], Step [32/64], Step Loss: 0.5088\n",
            "Epoch [103/150], Step [64/64], Step Loss: 0.2525\n",
            "Epoch [103/150], Training Loss: 0.4575, Training Accuracy: 90.93%\n",
            "Epoch [103/150], Validation Loss: 1.6508, Validation Accuracy: 59.90%\n",
            "--------- Epoch 104 ----------\n",
            "Epoch [104/150], Step [32/64], Step Loss: 0.5407\n",
            "Epoch [104/150], Step [64/64], Step Loss: 0.3092\n",
            "Epoch [104/150], Training Loss: 0.4810, Training Accuracy: 89.85%\n",
            "Epoch [104/150], Validation Loss: 1.6435, Validation Accuracy: 59.90%\n",
            "--------- Epoch 105 ----------\n",
            "Epoch [105/150], Step [32/64], Step Loss: 0.2598\n",
            "Epoch [105/150], Step [64/64], Step Loss: 0.3226\n",
            "Epoch [105/150], Training Loss: 0.4662, Training Accuracy: 90.54%\n",
            "Epoch [105/150], Validation Loss: 1.6464, Validation Accuracy: 59.61%\n",
            "--------- Epoch 106 ----------\n",
            "Epoch [106/150], Step [32/64], Step Loss: 0.7138\n",
            "Epoch [106/150], Step [64/64], Step Loss: 0.4846\n",
            "Epoch [106/150], Training Loss: 0.4277, Training Accuracy: 91.18%\n",
            "Epoch [106/150], Validation Loss: 1.6529, Validation Accuracy: 60.59%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 107 ----------\n",
            "Epoch [107/150], Step [32/64], Step Loss: 0.5359\n",
            "Epoch [107/150], Step [64/64], Step Loss: 0.2802\n",
            "Epoch [107/150], Training Loss: 0.4763, Training Accuracy: 89.85%\n",
            "Epoch [107/150], Validation Loss: 1.6458, Validation Accuracy: 60.29%\n",
            "Epoch 00107: reducing learning rate of group 0 to 1.0000e-07.\n",
            "--------- Epoch 108 ----------\n",
            "Epoch [108/150], Step [32/64], Step Loss: 0.2628\n",
            "Epoch [108/150], Step [64/64], Step Loss: 0.4612\n",
            "Epoch [108/150], Training Loss: 0.4796, Training Accuracy: 89.31%\n",
            "Epoch [108/150], Validation Loss: 1.6519, Validation Accuracy: 60.00%\n",
            "--------- Epoch 109 ----------\n",
            "Epoch [109/150], Step [32/64], Step Loss: 0.5890\n",
            "Epoch [109/150], Step [64/64], Step Loss: 0.4007\n",
            "Epoch [109/150], Training Loss: 0.4720, Training Accuracy: 89.95%\n",
            "Epoch [109/150], Validation Loss: 1.6567, Validation Accuracy: 59.41%\n",
            "--------- Epoch 110 ----------\n",
            "Epoch [110/150], Step [32/64], Step Loss: 0.4765\n",
            "Epoch [110/150], Step [64/64], Step Loss: 0.4262\n",
            "Epoch [110/150], Training Loss: 0.4987, Training Accuracy: 89.80%\n",
            "Epoch [110/150], Validation Loss: 1.6462, Validation Accuracy: 60.00%\n",
            "--------- Epoch 111 ----------\n",
            "Epoch [111/150], Step [32/64], Step Loss: 0.4964\n",
            "Epoch [111/150], Step [64/64], Step Loss: 0.2706\n",
            "Epoch [111/150], Training Loss: 0.4896, Training Accuracy: 89.80%\n",
            "Epoch [111/150], Validation Loss: 1.6427, Validation Accuracy: 60.29%\n",
            "--------- Epoch 112 ----------\n",
            "Epoch [112/150], Step [32/64], Step Loss: 0.4862\n",
            "Epoch [112/150], Step [64/64], Step Loss: 0.3614\n",
            "Epoch [112/150], Training Loss: 0.4600, Training Accuracy: 90.69%\n",
            "Epoch [112/150], Validation Loss: 1.6515, Validation Accuracy: 60.20%\n",
            "--------- Epoch 113 ----------\n",
            "Epoch [113/150], Step [32/64], Step Loss: 0.3761\n",
            "Epoch [113/150], Step [64/64], Step Loss: 0.2212\n",
            "Epoch [113/150], Training Loss: 0.4387, Training Accuracy: 90.78%\n",
            "Epoch [113/150], Validation Loss: 1.6509, Validation Accuracy: 60.00%\n",
            "--------- Epoch 114 ----------\n",
            "Epoch [114/150], Step [32/64], Step Loss: 0.3852\n",
            "Epoch [114/150], Step [64/64], Step Loss: 0.9748\n",
            "Epoch [114/150], Training Loss: 0.4927, Training Accuracy: 89.71%\n",
            "Epoch [114/150], Validation Loss: 1.6404, Validation Accuracy: 59.41%\n",
            "--------- Epoch 115 ----------\n",
            "Epoch [115/150], Step [32/64], Step Loss: 0.3249\n",
            "Epoch [115/150], Step [64/64], Step Loss: 0.4751\n",
            "Epoch [115/150], Training Loss: 0.4672, Training Accuracy: 90.44%\n",
            "Epoch [115/150], Validation Loss: 1.6508, Validation Accuracy: 60.20%\n",
            "--------- Epoch 116 ----------\n",
            "Epoch [116/150], Step [32/64], Step Loss: 0.4679\n",
            "Epoch [116/150], Step [64/64], Step Loss: 0.4539\n",
            "Epoch [116/150], Training Loss: 0.4294, Training Accuracy: 90.78%\n",
            "Epoch [116/150], Validation Loss: 1.6589, Validation Accuracy: 59.71%\n",
            "--------- Epoch 117 ----------\n",
            "Epoch [117/150], Step [32/64], Step Loss: 0.3534\n",
            "Epoch [117/150], Step [64/64], Step Loss: 0.3463\n",
            "Epoch [117/150], Training Loss: 0.4751, Training Accuracy: 90.00%\n",
            "Epoch [117/150], Validation Loss: 1.6521, Validation Accuracy: 60.29%\n",
            "--------- Epoch 118 ----------\n",
            "Epoch [118/150], Step [32/64], Step Loss: 0.3220\n",
            "Epoch [118/150], Step [64/64], Step Loss: 0.5334\n",
            "Epoch [118/150], Training Loss: 0.4814, Training Accuracy: 89.51%\n",
            "Epoch [118/150], Validation Loss: 1.6559, Validation Accuracy: 60.29%\n",
            "Epoch 00118: reducing learning rate of group 0 to 1.0000e-08.\n",
            "--------- Epoch 119 ----------\n",
            "Epoch [119/150], Step [32/64], Step Loss: 0.2489\n",
            "Epoch [119/150], Step [64/64], Step Loss: 0.4051\n",
            "Epoch [119/150], Training Loss: 0.4614, Training Accuracy: 90.34%\n",
            "Epoch [119/150], Validation Loss: 1.6497, Validation Accuracy: 60.10%\n",
            "--------- Epoch 120 ----------\n",
            "Epoch [120/150], Step [32/64], Step Loss: 0.3339\n",
            "Epoch [120/150], Step [64/64], Step Loss: 0.3910\n",
            "Epoch [120/150], Training Loss: 0.4595, Training Accuracy: 90.29%\n",
            "Epoch [120/150], Validation Loss: 1.6407, Validation Accuracy: 60.10%\n",
            "--------- Epoch 121 ----------\n",
            "Epoch [121/150], Step [32/64], Step Loss: 0.3867\n",
            "Epoch [121/150], Step [64/64], Step Loss: 0.5936\n",
            "Epoch [121/150], Training Loss: 0.4418, Training Accuracy: 91.13%\n",
            "Epoch [121/150], Validation Loss: 1.6515, Validation Accuracy: 60.39%\n",
            "--------- Epoch 122 ----------\n",
            "Epoch [122/150], Step [32/64], Step Loss: 0.5458\n",
            "Epoch [122/150], Step [64/64], Step Loss: 0.2814\n",
            "Epoch [122/150], Training Loss: 0.4473, Training Accuracy: 90.00%\n",
            "Epoch [122/150], Validation Loss: 1.6415, Validation Accuracy: 59.80%\n",
            "--------- Epoch 123 ----------\n",
            "Epoch [123/150], Step [32/64], Step Loss: 0.4107\n",
            "Epoch [123/150], Step [64/64], Step Loss: 0.3342\n",
            "Epoch [123/150], Training Loss: 0.4428, Training Accuracy: 91.13%\n",
            "Epoch [123/150], Validation Loss: 1.6538, Validation Accuracy: 60.10%\n",
            "--------- Epoch 124 ----------\n",
            "Epoch [124/150], Step [32/64], Step Loss: 0.7623\n",
            "Epoch [124/150], Step [64/64], Step Loss: 0.6637\n",
            "Epoch [124/150], Training Loss: 0.4683, Training Accuracy: 90.64%\n",
            "Epoch [124/150], Validation Loss: 1.6535, Validation Accuracy: 59.71%\n",
            "--------- Epoch 125 ----------\n",
            "Epoch [125/150], Step [32/64], Step Loss: 0.3624\n",
            "Epoch [125/150], Step [64/64], Step Loss: 0.4310\n",
            "Epoch [125/150], Training Loss: 0.4421, Training Accuracy: 91.27%\n",
            "Epoch [125/150], Validation Loss: 1.6485, Validation Accuracy: 60.10%\n",
            "--------- Epoch 126 ----------\n",
            "Epoch [126/150], Step [32/64], Step Loss: 1.0575\n",
            "Epoch [126/150], Step [64/64], Step Loss: 0.4419\n",
            "Epoch [126/150], Training Loss: 0.4786, Training Accuracy: 90.29%\n",
            "Epoch [126/150], Validation Loss: 1.6403, Validation Accuracy: 59.31%\n",
            "--------- Epoch 127 ----------\n",
            "Epoch [127/150], Step [32/64], Step Loss: 0.4901\n",
            "Epoch [127/150], Step [64/64], Step Loss: 0.4024\n",
            "Epoch [127/150], Training Loss: 0.4653, Training Accuracy: 89.85%\n",
            "Epoch [127/150], Validation Loss: 1.6510, Validation Accuracy: 59.80%\n",
            "--------- Epoch 128 ----------\n",
            "Epoch [128/150], Step [32/64], Step Loss: 0.3721\n",
            "Epoch [128/150], Step [64/64], Step Loss: 0.5131\n",
            "Epoch [128/150], Training Loss: 0.4930, Training Accuracy: 89.36%\n",
            "Epoch [128/150], Validation Loss: 1.6504, Validation Accuracy: 60.20%\n",
            "--------- Epoch 129 ----------\n",
            "Epoch [129/150], Step [32/64], Step Loss: 0.4859\n",
            "Epoch [129/150], Step [64/64], Step Loss: 0.1640\n",
            "Epoch [129/150], Training Loss: 0.4457, Training Accuracy: 91.03%\n",
            "Epoch [129/150], Validation Loss: 1.6453, Validation Accuracy: 59.41%\n",
            "--------- Epoch 130 ----------\n",
            "Epoch [130/150], Step [32/64], Step Loss: 0.5041\n",
            "Epoch [130/150], Step [64/64], Step Loss: 0.8995\n",
            "Epoch [130/150], Training Loss: 0.4683, Training Accuracy: 89.41%\n",
            "Epoch [130/150], Validation Loss: 1.6505, Validation Accuracy: 59.61%\n",
            "--------- Epoch 131 ----------\n",
            "Epoch [131/150], Step [32/64], Step Loss: 0.2188\n",
            "Epoch [131/150], Step [64/64], Step Loss: 0.4184\n",
            "Epoch [131/150], Training Loss: 0.4710, Training Accuracy: 90.15%\n",
            "Epoch [131/150], Validation Loss: 1.6517, Validation Accuracy: 59.80%\n",
            "--------- Epoch 132 ----------\n",
            "Epoch [132/150], Step [32/64], Step Loss: 0.7506\n",
            "Epoch [132/150], Step [64/64], Step Loss: 0.2088\n",
            "Epoch [132/150], Training Loss: 0.4870, Training Accuracy: 89.56%\n",
            "Epoch [132/150], Validation Loss: 1.6494, Validation Accuracy: 60.10%\n",
            "--------- Epoch 133 ----------\n",
            "Epoch [133/150], Step [32/64], Step Loss: 0.4261\n",
            "Epoch [133/150], Step [64/64], Step Loss: 0.2904\n",
            "Epoch [133/150], Training Loss: 0.4602, Training Accuracy: 90.74%\n",
            "Epoch [133/150], Validation Loss: 1.6442, Validation Accuracy: 59.80%\n",
            "--------- Epoch 134 ----------\n",
            "Epoch [134/150], Step [32/64], Step Loss: 0.4300\n",
            "Epoch [134/150], Step [64/64], Step Loss: 0.1725\n",
            "Epoch [134/150], Training Loss: 0.4857, Training Accuracy: 90.10%\n",
            "Epoch [134/150], Validation Loss: 1.6427, Validation Accuracy: 60.39%\n",
            "--------- Epoch 135 ----------\n",
            "Epoch [135/150], Step [32/64], Step Loss: 0.6346\n",
            "Epoch [135/150], Step [64/64], Step Loss: 0.4050\n",
            "Epoch [135/150], Training Loss: 0.4536, Training Accuracy: 90.59%\n",
            "Epoch [135/150], Validation Loss: 1.6574, Validation Accuracy: 59.80%\n",
            "--------- Epoch 136 ----------\n",
            "Epoch [136/150], Step [32/64], Step Loss: 0.3491\n",
            "Epoch [136/150], Step [64/64], Step Loss: 0.7800\n",
            "Epoch [136/150], Training Loss: 0.4484, Training Accuracy: 91.03%\n",
            "Epoch [136/150], Validation Loss: 1.6644, Validation Accuracy: 59.61%\n",
            "--------- Epoch 137 ----------\n",
            "Epoch [137/150], Step [32/64], Step Loss: 0.7990\n",
            "Epoch [137/150], Step [64/64], Step Loss: 0.5916\n",
            "Epoch [137/150], Training Loss: 0.4522, Training Accuracy: 90.25%\n",
            "Epoch [137/150], Validation Loss: 1.6418, Validation Accuracy: 59.90%\n",
            "--------- Epoch 138 ----------\n",
            "Epoch [138/150], Step [32/64], Step Loss: 0.3809\n",
            "Epoch [138/150], Step [64/64], Step Loss: 0.5470\n",
            "Epoch [138/150], Training Loss: 0.4577, Training Accuracy: 90.49%\n",
            "Epoch [138/150], Validation Loss: 1.6456, Validation Accuracy: 59.61%\n",
            "--------- Epoch 139 ----------\n",
            "Epoch [139/150], Step [32/64], Step Loss: 0.7172\n",
            "Epoch [139/150], Step [64/64], Step Loss: 0.5993\n",
            "Epoch [139/150], Training Loss: 0.4941, Training Accuracy: 89.31%\n",
            "Epoch [139/150], Validation Loss: 1.6438, Validation Accuracy: 59.61%\n",
            "--------- Epoch 140 ----------\n",
            "Epoch [140/150], Step [32/64], Step Loss: 0.2649\n",
            "Epoch [140/150], Step [64/64], Step Loss: 0.5190\n",
            "Epoch [140/150], Training Loss: 0.4412, Training Accuracy: 90.93%\n",
            "Epoch [140/150], Validation Loss: 1.6586, Validation Accuracy: 59.61%\n",
            "--------- Epoch 141 ----------\n",
            "Epoch [141/150], Step [32/64], Step Loss: 0.8091\n",
            "Epoch [141/150], Step [64/64], Step Loss: 0.1434\n",
            "Epoch [141/150], Training Loss: 0.4838, Training Accuracy: 89.85%\n",
            "Epoch [141/150], Validation Loss: 1.6438, Validation Accuracy: 60.10%\n",
            "--------- Epoch 142 ----------\n",
            "Epoch [142/150], Step [32/64], Step Loss: 0.2736\n",
            "Epoch [142/150], Step [64/64], Step Loss: 0.2608\n",
            "Epoch [142/150], Training Loss: 0.4507, Training Accuracy: 90.49%\n",
            "Epoch [142/150], Validation Loss: 1.6460, Validation Accuracy: 59.02%\n",
            "--------- Epoch 143 ----------\n",
            "Epoch [143/150], Step [32/64], Step Loss: 1.0260\n",
            "Epoch [143/150], Step [64/64], Step Loss: 0.4611\n",
            "Epoch [143/150], Training Loss: 0.4699, Training Accuracy: 90.29%\n",
            "Epoch [143/150], Validation Loss: 1.6519, Validation Accuracy: 59.51%\n",
            "--------- Epoch 144 ----------\n",
            "Epoch [144/150], Step [32/64], Step Loss: 0.5781\n",
            "Epoch [144/150], Step [64/64], Step Loss: 0.6777\n",
            "Epoch [144/150], Training Loss: 0.4695, Training Accuracy: 89.90%\n",
            "Epoch [144/150], Validation Loss: 1.6450, Validation Accuracy: 60.10%\n",
            "--------- Epoch 145 ----------\n",
            "Epoch [145/150], Step [32/64], Step Loss: 0.5651\n",
            "Epoch [145/150], Step [64/64], Step Loss: 0.2875\n",
            "Epoch [145/150], Training Loss: 0.4555, Training Accuracy: 90.44%\n",
            "Epoch [145/150], Validation Loss: 1.6439, Validation Accuracy: 58.73%\n",
            "--------- Epoch 146 ----------\n",
            "Epoch [146/150], Step [32/64], Step Loss: 0.4476\n",
            "Epoch [146/150], Step [64/64], Step Loss: 0.3099\n",
            "Epoch [146/150], Training Loss: 0.4887, Training Accuracy: 90.10%\n",
            "Epoch [146/150], Validation Loss: 1.6424, Validation Accuracy: 60.20%\n",
            "--------- Epoch 147 ----------\n",
            "Epoch [147/150], Step [32/64], Step Loss: 0.4617\n",
            "Epoch [147/150], Step [64/64], Step Loss: 0.3459\n",
            "Epoch [147/150], Training Loss: 0.4802, Training Accuracy: 89.56%\n",
            "Epoch [147/150], Validation Loss: 1.6442, Validation Accuracy: 60.39%\n",
            "--------- Epoch 148 ----------\n",
            "Epoch [148/150], Step [32/64], Step Loss: 0.4354\n",
            "Epoch [148/150], Step [64/64], Step Loss: 0.2501\n",
            "Epoch [148/150], Training Loss: 0.4574, Training Accuracy: 90.39%\n",
            "Epoch [148/150], Validation Loss: 1.6511, Validation Accuracy: 59.41%\n",
            "--------- Epoch 149 ----------\n",
            "Epoch [149/150], Step [32/64], Step Loss: 0.6884\n",
            "Epoch [149/150], Step [64/64], Step Loss: 0.4777\n",
            "Epoch [149/150], Training Loss: 0.4411, Training Accuracy: 90.88%\n",
            "Epoch [149/150], Validation Loss: 1.6584, Validation Accuracy: 60.20%\n",
            "--------- Epoch 150 ----------\n",
            "Epoch [150/150], Step [32/64], Step Loss: 0.3401\n",
            "Epoch [150/150], Step [64/64], Step Loss: 0.2867\n",
            "Epoch [150/150], Training Loss: 0.4322, Training Accuracy: 90.98%\n",
            "Epoch [150/150], Validation Loss: 1.6439, Validation Accuracy: 59.90%\n",
            "Training complete in: 01h 23m 03s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▂▃▄▅▆▇▇▇▇▇▇▇▇▇▇▇▇██████████████████████</td></tr><tr><td>train_loss</td><td>█▇▅▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▃▄▅▅▆▆▆▇▆▇▆▆▆▇▇▆██████████████████████</td></tr><tr><td>val_loss</td><td>█▇▅▄▃▃▃▃▃▂▃▂▂▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>90.98039</td></tr><tr><td>train_loss</td><td>0.4322</td></tr><tr><td>val_acc</td><td>59.90196</td></tr><tr><td>val_loss</td><td>1.64391</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">0.0001</strong> at: <a href='https://wandb.ai/faran-team/final-tests/runs/ogsm4k5d' target=\"_blank\">https://wandb.ai/faran-team/final-tests/runs/ogsm4k5d</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230508_174249-ogsm4k5d/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Timer setup\n",
        "print(f\"Starting training with learning rate {LEARNING_RATE:.7f}\")\n",
        "start_time = time.time()\n",
        "\n",
        "best_acc = 0\n",
        "best_epoch = -1\n",
        "\n",
        "# Train the CNN\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f'--------- Epoch {epoch + 1} ----------')\n",
        "    cnn.train()\n",
        "    train_loss = 0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        labels = torch.eye(102)[labels]  # one hot encode\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = cnn(images)  # train\n",
        "        labels = torch.argmax(labels, dim=1)  # one hot decode\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        train_total += labels.size(0)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        if (i + 1) % 32 == 0:\n",
        "            print(f\"Epoch [{epoch + 1}/{EPOCHS}], Step [{i + 1}/{len(train_loader)}], Step Loss: {loss.item():.4f}\")\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_accuracy = 100 * train_correct / train_total\n",
        "    print(f'Epoch [{epoch + 1}/{EPOCHS}], Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%')\n",
        "\n",
        "    # Evaluate model after each training epoch\n",
        "    cnn.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = cnn(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_accuracy = 100 * correct / total\n",
        "    print(f'Epoch [{epoch + 1}/{EPOCHS}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "\n",
        "    # wandb stuff, REMOVE\n",
        "    wandb.log({\"train_acc\": train_accuracy, \"train_loss\": train_loss, \"val_acc\": val_accuracy, \"val_loss\": val_loss})\n",
        "\n",
        "    # save plot data\n",
        "    val_accuracies.append(val_accuracy)\n",
        "    val_losses.append(val_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # Update the learning rate scheduler\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    if val_accuracy > best_acc:\n",
        "      best_acc = val_accuracy\n",
        "      torch.save(cnn.state_dict(), 'best-model-parameters.pt')\n",
        "      best_epoch = epoch + 1\n",
        "      print(\"  **Better model found. Updated best model.\")\n",
        "\n",
        "# End time\n",
        "end_time = time.time()\n",
        "print(\"Training complete in: \" + time.strftime(\"%Hh %Mm %Ss\", time.gmtime(end_time - start_time)))\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test model."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "i3pOHSKXJp0T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- Best Model Testing ----------\n",
            "  Epoch: 106\n",
            "  Validation accuracy: 60.59%\n"
          ]
        }
      ],
      "source": [
        "# Test the best model on the test set\n",
        "best_model = torch.load(\"best-model-parameters.pt\")\n",
        "cnn.load_state_dict(best_model)\n",
        "print(\"---------- Best Model Testing ----------\")\n",
        "print(f'  Epoch: {best_epoch}')\n",
        "print(f'  Validation accuracy: {best_acc:.2f}%')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d_NGRt-Jp0U",
        "outputId": "5def3dfc-df70-4a83-fdb1-db66de96b768"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 55.39%\n"
          ]
        }
      ],
      "source": [
        "# Test the CNN on the test set\n",
        "cnn.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = cnn(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_accuracy = 100 * correct / total\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}%')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVaYKS7GJp0V",
        "outputId": "a7fa8050-fb02-4f6d-e780-22a39f8cdda1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot training data"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "sFTuTLYZJp0V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot\n",
        "fig, (ax_a, ax_l) = plt.subplots(2, sharex=True)\n",
        "\n",
        "ax_a.set_xlabel(\"Epoch\")\n",
        "ax_a.set_ylabel(\"Accuracy %\")\n",
        "ax_a.plot(val_accuracies, marker=\".\", c=\"forestgreen\")\n",
        "ax_a.plot(train_accuracies, marker=\".\", c=\"royalblue\")\n",
        "\n",
        "ax_l.set_xlabel(\"Epoch\")\n",
        "ax_l.set_ylabel(\"Loss\")\n",
        "ax_l.plot(val_losses, marker=\".\", c=\"forestgreen\")\n",
        "ax_l.plot(train_losses, marker=\".\", c=\"royalblue\")\n",
        "\n",
        "fig.legend(title=\"Data Type\", labels=[\"Training\", \"Validation\"], fontsize=\"small\", loc=3, bbox_to_anchor=(0.925, 0.425))\n",
        "fig.align_labels()\n",
        "plt.show()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "ZwA6bbIkJp0W",
        "outputId": "0ab3f8cc-498f-4ce1-d8b0-ebe0379154c6"
      }
    }
  ]
}