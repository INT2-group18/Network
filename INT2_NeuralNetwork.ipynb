{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/INT2-group18/Network/blob/main/INT2-NeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LWLZiIRvMfzp",
        "outputId": "a5cc43da-07f8-4e47-ce97-a18641d650c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv5): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (conv6): Sequential(\n",
            "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (conv7): Sequential(\n",
            "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv8): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (conv9): Sequential(\n",
            "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc1): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (fc2): Sequential(\n",
            "    (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (fc3): Sequential(\n",
            "    (0): Linear(in_features=4096, out_features=102, bias=True)\n",
            "  )\n",
            ")\n",
            "Epoch [1/300], Step [16/32], Step Loss: 4.6892\n",
            "Epoch [1/300], Step [32/32], Step Loss: 4.6058\n",
            "Training accuracy: 1.67%\n",
            "Epoch [1/300], Validation Accuracy: 1.86%\n",
            "Epoch [2/300], Step [16/32], Step Loss: 4.4703\n",
            "Epoch [2/300], Step [32/32], Step Loss: 4.5283\n",
            "Training accuracy: 4.41%\n",
            "Epoch [2/300], Validation Accuracy: 4.90%\n",
            "Epoch [3/300], Step [16/32], Step Loss: 4.3879\n",
            "Epoch [3/300], Step [32/32], Step Loss: 4.4260\n",
            "Training accuracy: 9.41%\n",
            "Epoch [3/300], Validation Accuracy: 9.80%\n",
            "Epoch [4/300], Step [16/32], Step Loss: 4.2614\n",
            "Epoch [4/300], Step [32/32], Step Loss: 4.2022\n",
            "Training accuracy: 14.90%\n",
            "Epoch [4/300], Validation Accuracy: 12.75%\n",
            "Epoch [5/300], Step [16/32], Step Loss: 4.1591\n",
            "Epoch [5/300], Step [32/32], Step Loss: 4.0838\n",
            "Training accuracy: 18.53%\n",
            "Epoch [5/300], Validation Accuracy: 12.65%\n",
            "Epoch [6/300], Step [16/32], Step Loss: 3.7757\n",
            "Epoch [6/300], Step [32/32], Step Loss: 3.7549\n",
            "Training accuracy: 21.76%\n",
            "Epoch [6/300], Validation Accuracy: 15.59%\n",
            "Epoch [7/300], Step [16/32], Step Loss: 3.6453\n",
            "Epoch [7/300], Step [32/32], Step Loss: 3.5533\n",
            "Training accuracy: 26.57%\n",
            "Epoch [7/300], Validation Accuracy: 18.33%\n",
            "Epoch [8/300], Step [16/32], Step Loss: 3.5014\n",
            "Epoch [8/300], Step [32/32], Step Loss: 3.4894\n",
            "Training accuracy: 32.06%\n",
            "Epoch [8/300], Validation Accuracy: 19.80%\n",
            "Epoch [9/300], Step [16/32], Step Loss: 3.4605\n",
            "Epoch [9/300], Step [32/32], Step Loss: 3.0088\n",
            "Training accuracy: 36.47%\n",
            "Epoch [9/300], Validation Accuracy: 24.31%\n",
            "Epoch [10/300], Step [16/32], Step Loss: 3.1335\n",
            "Epoch [10/300], Step [32/32], Step Loss: 3.1110\n",
            "Training accuracy: 43.24%\n",
            "Epoch [10/300], Validation Accuracy: 25.69%\n",
            "Epoch [11/300], Step [16/32], Step Loss: 3.1289\n",
            "Epoch [11/300], Step [32/32], Step Loss: 2.8976\n",
            "Training accuracy: 45.88%\n",
            "Epoch [11/300], Validation Accuracy: 28.92%\n",
            "Epoch [12/300], Step [16/32], Step Loss: 2.9978\n",
            "Epoch [12/300], Step [32/32], Step Loss: 2.7330\n",
            "Training accuracy: 46.76%\n",
            "Epoch [12/300], Validation Accuracy: 28.92%\n",
            "Epoch [13/300], Step [16/32], Step Loss: 2.5361\n",
            "Epoch [13/300], Step [32/32], Step Loss: 2.5561\n",
            "Training accuracy: 55.98%\n",
            "Epoch [13/300], Validation Accuracy: 28.53%\n",
            "Epoch [14/300], Step [16/32], Step Loss: 2.3990\n",
            "Epoch [14/300], Step [32/32], Step Loss: 2.2373\n",
            "Training accuracy: 58.82%\n",
            "Epoch [14/300], Validation Accuracy: 31.47%\n",
            "Epoch [15/300], Step [16/32], Step Loss: 2.3302\n",
            "Epoch [15/300], Step [32/32], Step Loss: 2.3194\n",
            "Training accuracy: 62.06%\n",
            "Epoch [15/300], Validation Accuracy: 32.65%\n",
            "Epoch [16/300], Step [16/32], Step Loss: 2.1294\n",
            "Epoch [16/300], Step [32/32], Step Loss: 1.9272\n",
            "Training accuracy: 65.59%\n",
            "Epoch [16/300], Validation Accuracy: 33.53%\n",
            "Epoch [17/300], Step [16/32], Step Loss: 2.0531\n",
            "Epoch [17/300], Step [32/32], Step Loss: 1.9579\n",
            "Training accuracy: 69.41%\n",
            "Epoch [17/300], Validation Accuracy: 33.73%\n",
            "Epoch [18/300], Step [16/32], Step Loss: 1.7230\n",
            "Epoch [18/300], Step [32/32], Step Loss: 1.7657\n",
            "Training accuracy: 74.51%\n",
            "Epoch [18/300], Validation Accuracy: 34.22%\n",
            "Epoch [19/300], Step [16/32], Step Loss: 1.6321\n",
            "Epoch [19/300], Step [32/32], Step Loss: 1.7645\n",
            "Training accuracy: 75.88%\n",
            "Epoch [19/300], Validation Accuracy: 34.02%\n",
            "Epoch [20/300], Step [16/32], Step Loss: 1.3760\n",
            "Epoch [20/300], Step [32/32], Step Loss: 1.5775\n",
            "Training accuracy: 81.76%\n",
            "Epoch [20/300], Validation Accuracy: 35.39%\n",
            "Epoch [21/300], Step [16/32], Step Loss: 1.8328\n",
            "Epoch [21/300], Step [32/32], Step Loss: 1.4119\n",
            "Training accuracy: 82.35%\n",
            "Epoch [21/300], Validation Accuracy: 35.88%\n",
            "Epoch [22/300], Step [16/32], Step Loss: 1.2602\n",
            "Epoch [22/300], Step [32/32], Step Loss: 1.2782\n",
            "Training accuracy: 85.10%\n",
            "Epoch [22/300], Validation Accuracy: 36.96%\n",
            "Epoch [23/300], Step [16/32], Step Loss: 1.3765\n",
            "Epoch [23/300], Step [32/32], Step Loss: 1.4515\n",
            "Training accuracy: 85.20%\n",
            "Epoch [23/300], Validation Accuracy: 36.86%\n",
            "Epoch [24/300], Step [16/32], Step Loss: 1.1461\n",
            "Epoch [24/300], Step [32/32], Step Loss: 1.1159\n",
            "Training accuracy: 87.84%\n",
            "Epoch [24/300], Validation Accuracy: 37.16%\n",
            "Epoch [25/300], Step [16/32], Step Loss: 1.0145\n",
            "Epoch [25/300], Step [32/32], Step Loss: 0.9813\n",
            "Training accuracy: 91.37%\n",
            "Epoch [25/300], Validation Accuracy: 39.02%\n",
            "Epoch [26/300], Step [16/32], Step Loss: 0.8578\n",
            "Epoch [26/300], Step [32/32], Step Loss: 0.8974\n",
            "Training accuracy: 92.25%\n",
            "Epoch [26/300], Validation Accuracy: 37.35%\n",
            "Epoch [27/300], Step [16/32], Step Loss: 0.8238\n",
            "Epoch [27/300], Step [32/32], Step Loss: 0.6003\n",
            "Training accuracy: 93.33%\n",
            "Epoch [27/300], Validation Accuracy: 37.94%\n",
            "Epoch [28/300], Step [16/32], Step Loss: 0.7140\n",
            "Epoch [28/300], Step [32/32], Step Loss: 0.6652\n",
            "Training accuracy: 95.00%\n",
            "Epoch [28/300], Validation Accuracy: 39.02%\n",
            "Epoch [29/300], Step [16/32], Step Loss: 0.6346\n",
            "Epoch [29/300], Step [32/32], Step Loss: 0.5991\n",
            "Training accuracy: 94.22%\n",
            "Epoch [29/300], Validation Accuracy: 38.73%\n",
            "Epoch [30/300], Step [16/32], Step Loss: 0.6345\n",
            "Epoch [30/300], Step [32/32], Step Loss: 0.8033\n",
            "Training accuracy: 96.27%\n",
            "Epoch [30/300], Validation Accuracy: 39.22%\n",
            "Epoch [31/300], Step [16/32], Step Loss: 0.6650\n",
            "Epoch [31/300], Step [32/32], Step Loss: 0.5482\n",
            "Training accuracy: 97.06%\n",
            "Epoch [31/300], Validation Accuracy: 39.22%\n",
            "Epoch [32/300], Step [16/32], Step Loss: 0.4435\n",
            "Epoch [32/300], Step [32/32], Step Loss: 0.4314\n",
            "Training accuracy: 97.55%\n",
            "Epoch [32/300], Validation Accuracy: 39.61%\n",
            "Epoch [33/300], Step [16/32], Step Loss: 0.5139\n",
            "Epoch [33/300], Step [32/32], Step Loss: 0.4296\n",
            "Training accuracy: 97.16%\n",
            "Epoch [33/300], Validation Accuracy: 39.90%\n",
            "Epoch [34/300], Step [16/32], Step Loss: 0.8310\n",
            "Epoch [34/300], Step [32/32], Step Loss: 0.3455\n",
            "Training accuracy: 98.43%\n",
            "Epoch [34/300], Validation Accuracy: 40.69%\n",
            "Epoch [35/300], Step [16/32], Step Loss: 0.2711\n",
            "Epoch [35/300], Step [32/32], Step Loss: 0.3421\n",
            "Training accuracy: 98.82%\n",
            "Epoch [35/300], Validation Accuracy: 40.88%\n",
            "Epoch [36/300], Step [16/32], Step Loss: 0.5448\n",
            "Epoch [36/300], Step [32/32], Step Loss: 0.4777\n",
            "Training accuracy: 99.41%\n",
            "Epoch [36/300], Validation Accuracy: 40.29%\n",
            "Epoch [37/300], Step [16/32], Step Loss: 0.2930\n",
            "Epoch [37/300], Step [32/32], Step Loss: 0.3099\n",
            "Training accuracy: 99.80%\n",
            "Epoch [37/300], Validation Accuracy: 40.00%\n",
            "Epoch [38/300], Step [16/32], Step Loss: 0.4182\n",
            "Epoch [38/300], Step [32/32], Step Loss: 0.3427\n",
            "Training accuracy: 98.92%\n",
            "Epoch [38/300], Validation Accuracy: 40.20%\n",
            "Epoch [39/300], Step [16/32], Step Loss: 0.2324\n",
            "Epoch [39/300], Step [32/32], Step Loss: 0.2102\n",
            "Training accuracy: 99.61%\n",
            "Epoch [39/300], Validation Accuracy: 41.18%\n",
            "Epoch [40/300], Step [16/32], Step Loss: 0.2391\n",
            "Epoch [40/300], Step [32/32], Step Loss: 0.3251\n",
            "Training accuracy: 99.71%\n",
            "Epoch [40/300], Validation Accuracy: 40.69%\n",
            "Epoch [41/300], Step [16/32], Step Loss: 0.2261\n",
            "Epoch [41/300], Step [32/32], Step Loss: 0.4695\n",
            "Training accuracy: 99.61%\n",
            "Epoch [41/300], Validation Accuracy: 41.08%\n",
            "Epoch [42/300], Step [16/32], Step Loss: 0.3160\n",
            "Epoch [42/300], Step [32/32], Step Loss: 0.2397\n",
            "Training accuracy: 99.41%\n",
            "Epoch [42/300], Validation Accuracy: 40.00%\n",
            "Epoch [43/300], Step [16/32], Step Loss: 0.1507\n",
            "Epoch [43/300], Step [32/32], Step Loss: 0.2492\n",
            "Training accuracy: 99.90%\n",
            "Epoch [43/300], Validation Accuracy: 39.90%\n",
            "Epoch [44/300], Step [16/32], Step Loss: 0.1776\n",
            "Epoch [44/300], Step [32/32], Step Loss: 0.1534\n",
            "Training accuracy: 99.71%\n",
            "Epoch [44/300], Validation Accuracy: 39.80%\n",
            "Epoch [45/300], Step [16/32], Step Loss: 0.1565\n",
            "Epoch [45/300], Step [32/32], Step Loss: 0.1627\n",
            "Training accuracy: 100.00%\n",
            "Epoch [45/300], Validation Accuracy: 41.57%\n",
            "Epoch [46/300], Step [16/32], Step Loss: 0.2028\n",
            "Epoch [46/300], Step [32/32], Step Loss: 0.1570\n",
            "Training accuracy: 99.90%\n",
            "Epoch [46/300], Validation Accuracy: 41.27%\n",
            "Epoch [47/300], Step [16/32], Step Loss: 0.1706\n",
            "Epoch [47/300], Step [32/32], Step Loss: 0.1488\n",
            "Training accuracy: 100.00%\n",
            "Epoch [47/300], Validation Accuracy: 41.37%\n",
            "Epoch [48/300], Step [16/32], Step Loss: 0.1674\n",
            "Epoch [48/300], Step [32/32], Step Loss: 0.1331\n",
            "Training accuracy: 100.00%\n",
            "Epoch [48/300], Validation Accuracy: 40.78%\n",
            "Epoch [49/300], Step [16/32], Step Loss: 0.1430\n",
            "Epoch [49/300], Step [32/32], Step Loss: 0.1128\n",
            "Training accuracy: 100.00%\n",
            "Epoch [49/300], Validation Accuracy: 41.08%\n",
            "Epoch [50/300], Step [16/32], Step Loss: 0.0961\n",
            "Epoch [50/300], Step [32/32], Step Loss: 0.3267\n",
            "Training accuracy: 100.00%\n",
            "Epoch [50/300], Validation Accuracy: 41.18%\n",
            "Epoch [51/300], Step [16/32], Step Loss: 0.1562\n",
            "Epoch [51/300], Step [32/32], Step Loss: 0.0693\n",
            "Training accuracy: 100.00%\n",
            "Epoch [51/300], Validation Accuracy: 41.86%\n",
            "Epoch [52/300], Step [16/32], Step Loss: 0.0869\n",
            "Epoch [52/300], Step [32/32], Step Loss: 0.0653\n",
            "Training accuracy: 100.00%\n",
            "Epoch [52/300], Validation Accuracy: 42.35%\n",
            "Epoch [53/300], Step [16/32], Step Loss: 0.1106\n",
            "Epoch [53/300], Step [32/32], Step Loss: 0.1485\n",
            "Training accuracy: 100.00%\n",
            "Epoch [53/300], Validation Accuracy: 42.25%\n",
            "Epoch [54/300], Step [16/32], Step Loss: 0.1088\n",
            "Epoch [54/300], Step [32/32], Step Loss: 0.0886\n",
            "Training accuracy: 99.90%\n",
            "Epoch [54/300], Validation Accuracy: 42.06%\n",
            "Epoch [55/300], Step [16/32], Step Loss: 0.0785\n",
            "Epoch [55/300], Step [32/32], Step Loss: 0.1286\n",
            "Training accuracy: 100.00%\n",
            "Epoch [55/300], Validation Accuracy: 41.27%\n",
            "Epoch [56/300], Step [16/32], Step Loss: 0.0708\n",
            "Epoch [56/300], Step [32/32], Step Loss: 0.1044\n",
            "Training accuracy: 100.00%\n",
            "Epoch [56/300], Validation Accuracy: 41.18%\n",
            "Epoch [57/300], Step [16/32], Step Loss: 0.0489\n",
            "Epoch [57/300], Step [32/32], Step Loss: 0.0765\n",
            "Training accuracy: 100.00%\n",
            "Epoch [57/300], Validation Accuracy: 40.98%\n",
            "Epoch [58/300], Step [16/32], Step Loss: 0.0527\n",
            "Epoch [58/300], Step [32/32], Step Loss: 0.0593\n",
            "Training accuracy: 100.00%\n",
            "Epoch [58/300], Validation Accuracy: 40.69%\n",
            "Epoch [59/300], Step [16/32], Step Loss: 0.0722\n",
            "Epoch [59/300], Step [32/32], Step Loss: 0.0929\n",
            "Training accuracy: 100.00%\n",
            "Epoch [59/300], Validation Accuracy: 42.25%\n",
            "Epoch [60/300], Step [16/32], Step Loss: 0.0949\n",
            "Epoch [60/300], Step [32/32], Step Loss: 0.0847\n",
            "Training accuracy: 100.00%\n",
            "Epoch [60/300], Validation Accuracy: 41.76%\n",
            "Epoch [61/300], Step [16/32], Step Loss: 0.0470\n",
            "Epoch [61/300], Step [32/32], Step Loss: 0.0648\n",
            "Training accuracy: 100.00%\n",
            "Epoch [61/300], Validation Accuracy: 41.47%\n",
            "Epoch [62/300], Step [16/32], Step Loss: 0.0745\n",
            "Epoch [62/300], Step [32/32], Step Loss: 0.0689\n",
            "Training accuracy: 100.00%\n",
            "Epoch [62/300], Validation Accuracy: 41.18%\n",
            "Epoch [63/300], Step [16/32], Step Loss: 0.0572\n",
            "Epoch [63/300], Step [32/32], Step Loss: 0.0592\n",
            "Training accuracy: 100.00%\n",
            "Epoch [63/300], Validation Accuracy: 41.37%\n",
            "Epoch [64/300], Step [16/32], Step Loss: 0.0336\n",
            "Epoch [64/300], Step [32/32], Step Loss: 0.1357\n",
            "Training accuracy: 100.00%\n",
            "Epoch [64/300], Validation Accuracy: 40.98%\n",
            "Epoch [65/300], Step [16/32], Step Loss: 0.0819\n",
            "Epoch [65/300], Step [32/32], Step Loss: 0.0663\n",
            "Training accuracy: 100.00%\n",
            "Epoch [65/300], Validation Accuracy: 42.06%\n",
            "Epoch [66/300], Step [16/32], Step Loss: 0.0303\n",
            "Epoch [66/300], Step [32/32], Step Loss: 0.0374\n",
            "Training accuracy: 100.00%\n",
            "Epoch [66/300], Validation Accuracy: 41.67%\n",
            "Epoch [67/300], Step [16/32], Step Loss: 0.0479\n",
            "Epoch [67/300], Step [32/32], Step Loss: 0.0705\n",
            "Training accuracy: 100.00%\n",
            "Epoch [67/300], Validation Accuracy: 41.37%\n",
            "Epoch [68/300], Step [16/32], Step Loss: 0.0503\n",
            "Epoch [68/300], Step [32/32], Step Loss: 0.0786\n",
            "Training accuracy: 100.00%\n",
            "Epoch [68/300], Validation Accuracy: 41.47%\n",
            "Epoch [69/300], Step [16/32], Step Loss: 0.0755\n",
            "Epoch [69/300], Step [32/32], Step Loss: 0.0244\n",
            "Training accuracy: 100.00%\n",
            "Epoch [69/300], Validation Accuracy: 42.16%\n",
            "Epoch [70/300], Step [16/32], Step Loss: 0.0517\n",
            "Epoch [70/300], Step [32/32], Step Loss: 0.0534\n",
            "Training accuracy: 100.00%\n",
            "Epoch [70/300], Validation Accuracy: 41.57%\n",
            "Epoch [71/300], Step [16/32], Step Loss: 0.0504\n",
            "Epoch [71/300], Step [32/32], Step Loss: 0.0644\n",
            "Training accuracy: 100.00%\n",
            "Epoch [71/300], Validation Accuracy: 41.96%\n",
            "Epoch [72/300], Step [16/32], Step Loss: 0.0410\n",
            "Epoch [72/300], Step [32/32], Step Loss: 0.0405\n",
            "Training accuracy: 100.00%\n",
            "Epoch [72/300], Validation Accuracy: 41.76%\n",
            "Epoch [73/300], Step [16/32], Step Loss: 0.0798\n",
            "Epoch [73/300], Step [32/32], Step Loss: 0.0301\n",
            "Training accuracy: 99.80%\n",
            "Epoch [73/300], Validation Accuracy: 42.06%\n",
            "Epoch [74/300], Step [16/32], Step Loss: 0.0294\n",
            "Epoch [74/300], Step [32/32], Step Loss: 0.0254\n",
            "Training accuracy: 100.00%\n",
            "Epoch [74/300], Validation Accuracy: 41.27%\n",
            "Epoch [75/300], Step [16/32], Step Loss: 0.0460\n",
            "Epoch [75/300], Step [32/32], Step Loss: 0.0314\n",
            "Training accuracy: 100.00%\n",
            "Epoch [75/300], Validation Accuracy: 41.47%\n",
            "Epoch [76/300], Step [16/32], Step Loss: 0.0409\n",
            "Epoch [76/300], Step [32/32], Step Loss: 0.0902\n",
            "Training accuracy: 100.00%\n",
            "Epoch [76/300], Validation Accuracy: 41.37%\n",
            "Epoch [77/300], Step [16/32], Step Loss: 0.0349\n",
            "Epoch [77/300], Step [32/32], Step Loss: 0.0316\n",
            "Training accuracy: 100.00%\n",
            "Epoch [77/300], Validation Accuracy: 41.37%\n",
            "Epoch [78/300], Step [16/32], Step Loss: 0.0335\n",
            "Epoch [78/300], Step [32/32], Step Loss: 0.0321\n",
            "Training accuracy: 100.00%\n",
            "Epoch [78/300], Validation Accuracy: 41.96%\n",
            "Epoch [79/300], Step [16/32], Step Loss: 0.0439\n",
            "Epoch [79/300], Step [32/32], Step Loss: 0.0826\n",
            "Training accuracy: 100.00%\n",
            "Epoch [79/300], Validation Accuracy: 41.96%\n",
            "Epoch [80/300], Step [16/32], Step Loss: 0.0346\n",
            "Epoch [80/300], Step [32/32], Step Loss: 0.0274\n",
            "Training accuracy: 100.00%\n",
            "Epoch [80/300], Validation Accuracy: 41.57%\n",
            "Epoch [81/300], Step [16/32], Step Loss: 0.0258\n",
            "Epoch [81/300], Step [32/32], Step Loss: 0.0386\n",
            "Training accuracy: 100.00%\n",
            "Epoch [81/300], Validation Accuracy: 41.67%\n",
            "Epoch [82/300], Step [16/32], Step Loss: 0.0489\n",
            "Epoch [82/300], Step [32/32], Step Loss: 0.0334\n",
            "Training accuracy: 100.00%\n",
            "Epoch [82/300], Validation Accuracy: 41.57%\n",
            "Epoch [83/300], Step [16/32], Step Loss: 0.0515\n",
            "Epoch [83/300], Step [32/32], Step Loss: 0.0432\n",
            "Training accuracy: 100.00%\n",
            "Epoch [83/300], Validation Accuracy: 42.55%\n",
            "Epoch [84/300], Step [16/32], Step Loss: 0.0168\n",
            "Epoch [84/300], Step [32/32], Step Loss: 0.0302\n",
            "Training accuracy: 100.00%\n",
            "Epoch [84/300], Validation Accuracy: 41.67%\n",
            "Epoch [85/300], Step [16/32], Step Loss: 0.0229\n",
            "Epoch [85/300], Step [32/32], Step Loss: 0.0329\n",
            "Training accuracy: 100.00%\n",
            "Epoch [85/300], Validation Accuracy: 42.16%\n",
            "Epoch [86/300], Step [16/32], Step Loss: 0.0149\n",
            "Epoch [86/300], Step [32/32], Step Loss: 0.0225\n",
            "Training accuracy: 100.00%\n",
            "Epoch [86/300], Validation Accuracy: 43.14%\n",
            "Epoch [87/300], Step [16/32], Step Loss: 0.0189\n",
            "Epoch [87/300], Step [32/32], Step Loss: 0.0219\n",
            "Training accuracy: 100.00%\n",
            "Epoch [87/300], Validation Accuracy: 42.06%\n",
            "Epoch [88/300], Step [16/32], Step Loss: 0.0199\n",
            "Epoch [88/300], Step [32/32], Step Loss: 0.0204\n",
            "Training accuracy: 100.00%\n",
            "Epoch [88/300], Validation Accuracy: 42.25%\n",
            "Epoch [89/300], Step [16/32], Step Loss: 0.0333\n",
            "Epoch [89/300], Step [32/32], Step Loss: 0.0828\n",
            "Training accuracy: 100.00%\n",
            "Epoch [89/300], Validation Accuracy: 42.94%\n",
            "Epoch [90/300], Step [16/32], Step Loss: 0.0150\n",
            "Epoch [90/300], Step [32/32], Step Loss: 0.0129\n",
            "Training accuracy: 100.00%\n",
            "Epoch [90/300], Validation Accuracy: 42.25%\n",
            "Epoch [91/300], Step [16/32], Step Loss: 0.0091\n",
            "Epoch [91/300], Step [32/32], Step Loss: 0.0593\n",
            "Training accuracy: 100.00%\n",
            "Epoch [91/300], Validation Accuracy: 41.57%\n",
            "Epoch [92/300], Step [16/32], Step Loss: 0.0193\n",
            "Epoch [92/300], Step [32/32], Step Loss: 0.0170\n",
            "Training accuracy: 100.00%\n",
            "Epoch [92/300], Validation Accuracy: 41.76%\n",
            "Epoch [93/300], Step [16/32], Step Loss: 0.0248\n",
            "Epoch [93/300], Step [32/32], Step Loss: 0.0537\n",
            "Training accuracy: 100.00%\n",
            "Epoch [93/300], Validation Accuracy: 43.43%\n",
            "Epoch [94/300], Step [16/32], Step Loss: 0.0291\n",
            "Epoch [94/300], Step [32/32], Step Loss: 0.0620\n",
            "Training accuracy: 100.00%\n",
            "Epoch [94/300], Validation Accuracy: 41.96%\n",
            "Epoch [95/300], Step [16/32], Step Loss: 0.0153\n",
            "Epoch [95/300], Step [32/32], Step Loss: 0.0171\n",
            "Training accuracy: 100.00%\n",
            "Epoch [95/300], Validation Accuracy: 41.37%\n",
            "Epoch [96/300], Step [16/32], Step Loss: 0.0108\n",
            "Epoch [96/300], Step [32/32], Step Loss: 0.0215\n",
            "Training accuracy: 100.00%\n",
            "Epoch [96/300], Validation Accuracy: 41.86%\n",
            "Epoch [97/300], Step [16/32], Step Loss: 0.0125\n",
            "Epoch [97/300], Step [32/32], Step Loss: 0.0102\n",
            "Training accuracy: 100.00%\n",
            "Epoch [97/300], Validation Accuracy: 41.86%\n",
            "Epoch [98/300], Step [16/32], Step Loss: 0.0131\n",
            "Epoch [98/300], Step [32/32], Step Loss: 0.0119\n",
            "Training accuracy: 100.00%\n",
            "Epoch [98/300], Validation Accuracy: 41.76%\n",
            "Epoch [99/300], Step [16/32], Step Loss: 0.0216\n",
            "Epoch [99/300], Step [32/32], Step Loss: 0.0119\n",
            "Training accuracy: 100.00%\n",
            "Epoch [99/300], Validation Accuracy: 41.86%\n",
            "Epoch [100/300], Step [16/32], Step Loss: 0.0229\n",
            "Epoch [100/300], Step [32/32], Step Loss: 0.0402\n",
            "Training accuracy: 100.00%\n",
            "Epoch [100/300], Validation Accuracy: 41.76%\n",
            "Epoch [101/300], Step [16/32], Step Loss: 0.0205\n",
            "Epoch [101/300], Step [32/32], Step Loss: 0.0112\n",
            "Training accuracy: 100.00%\n",
            "Epoch [101/300], Validation Accuracy: 42.06%\n",
            "Epoch [102/300], Step [16/32], Step Loss: 0.0188\n",
            "Epoch [102/300], Step [32/32], Step Loss: 0.0170\n",
            "Training accuracy: 100.00%\n",
            "Epoch [102/300], Validation Accuracy: 42.06%\n",
            "Epoch [103/300], Step [16/32], Step Loss: 0.0080\n",
            "Epoch [103/300], Step [32/32], Step Loss: 0.0089\n",
            "Training accuracy: 100.00%\n",
            "Epoch [103/300], Validation Accuracy: 41.67%\n",
            "Epoch [104/300], Step [16/32], Step Loss: 0.0165\n",
            "Epoch [104/300], Step [32/32], Step Loss: 0.0122\n",
            "Training accuracy: 100.00%\n",
            "Epoch [104/300], Validation Accuracy: 41.67%\n",
            "Epoch [105/300], Step [16/32], Step Loss: 0.0108\n",
            "Epoch [105/300], Step [32/32], Step Loss: 0.0107\n",
            "Training accuracy: 100.00%\n",
            "Epoch [105/300], Validation Accuracy: 41.37%\n",
            "Epoch [106/300], Step [16/32], Step Loss: 0.0122\n",
            "Epoch [106/300], Step [32/32], Step Loss: 0.0176\n",
            "Training accuracy: 100.00%\n",
            "Epoch [106/300], Validation Accuracy: 42.06%\n",
            "Epoch [107/300], Step [16/32], Step Loss: 0.0099\n",
            "Epoch [107/300], Step [32/32], Step Loss: 0.0146\n",
            "Training accuracy: 100.00%\n",
            "Epoch [107/300], Validation Accuracy: 42.06%\n",
            "Epoch [108/300], Step [16/32], Step Loss: 0.0075\n",
            "Epoch [108/300], Step [32/32], Step Loss: 0.0147\n",
            "Training accuracy: 100.00%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-dd1bfb889cb9>\u001b[0m in \u001b[0;36m<cell line: 113>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch, time, gc\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as grid\n",
        "\n",
        "# Setup device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "SAVE_PATH = \"./neural_net.pth\"\n",
        "\n",
        "# Training variables\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 300\n",
        "LEARNING_RATE = 0.000005\n",
        "\n",
        "# Allowed transformations for test dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256, antialias=True),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the train and test datasets\n",
        "train_dataset = datasets.Flowers102(root=\"./data\", split=\"train\", transform=transform, download=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "test_dataset = datasets.Flowers102(root=\"./data\", split=\"test\", transform=transform, download=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "val_dataset = datasets.Flowers102(root=\"./data\", split=\"val\", transform=transform, download=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "val_accuracies = []\n",
        "\n",
        "# Define the CNN architecture\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(64),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2)) # 224 -> 112\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(128),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2)) # 112 -> 56\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(128),\n",
        "                                   nn.ReLU())\n",
        "        self.conv4 = nn.Sequential(nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(128),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2)) # 56 -> 28\n",
        "        self.conv5 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(256),\n",
        "                                   nn.ReLU())\n",
        "        self.conv6 = nn.Sequential(nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(256),\n",
        "                                   nn.ReLU())\n",
        "        self.conv7 = nn.Sequential(nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(256),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2)) # 28 -> 14\n",
        "        self.conv8 = nn.Sequential(nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(512),\n",
        "                                   nn.ReLU())\n",
        "        self.conv9 = nn.Sequential(nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(512),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2)) # 14 -> 7\n",
        "        self.fc1 = nn.Sequential(nn.Linear(7 * 7 * 512, 4096),\n",
        "                                   nn.ReLU())\n",
        "        self.fc2 = nn.Sequential(nn.Linear(4096, 4096),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.Dropout(p = 0.5))\n",
        "        self.fc3 = nn.Sequential(nn.Linear(4096, 102))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.conv6(x)\n",
        "        x = self.conv7(x)\n",
        "        x = self.conv8(x)\n",
        "        x = self.conv9(x)\n",
        "        x = x.view(-1, 7 * 7 * 512)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Clear cuda cache\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Create an instance of the CNN and move it to the device\n",
        "cnn = CNN().to(device)\n",
        "print(cnn)\n",
        "\n",
        "# Define the loss function and the optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cnn.parameters(), lr=LEARNING_RATE, weight_decay=0.0001)\n",
        "\n",
        "# Setup timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the CNN\n",
        "for epoch in range(EPOCHS):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    cnn.train()\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        labels = torch.eye(102)[labels] # one hot encode\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = cnn(images) # train\n",
        "        labels = torch.argmax(labels, dim=1) # one hot decode\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()  \n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 16 == 0:\n",
        "            print(f\"Epoch [{epoch + 1}/{EPOCHS}], Step [{i + 1}/{len(train_loader)}], Step Loss: {loss.item():.4f}\")\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Training accuracy: {accuracy:.2f}%\")\n",
        "    # Evaluate model after each training epoch\n",
        "    cnn.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = cnn(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f'Epoch [{epoch+1}/{EPOCHS}], Validation Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "    # save accuracy\n",
        "    val_accuracies.append(accuracy)\n",
        "\n",
        "# Output time taken to train\n",
        "end_time = time.time()\n",
        "print(\"Training Complete in: \" + time.strftime(\"%Hh %Mm %Ss\", time.gmtime(end_time - start_time)))"
      ]
    }
  ]
}