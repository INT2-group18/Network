{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "29569cc81afe4070885303dce4d147a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48dc304107ec4d6b9d89f1d995e1f110",
              "IPY_MODEL_a9dd3eba3e4946a8bc7d1475ce361bab"
            ],
            "layout": "IPY_MODEL_ec8c33fdf95b40a9870e741f34c35542"
          }
        },
        "48dc304107ec4d6b9d89f1d995e1f110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75f8a289e68c4eff93fca798ecbedd0c",
            "placeholder": "​",
            "style": "IPY_MODEL_a427db27cd6f47b9b1d2decd2ecb5f55",
            "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "a9dd3eba3e4946a8bc7d1475ce361bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_651bab8f4fed440a8aa66a900260fbfb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c362606894c44b3abfe634deeda8e46a",
            "value": 1
          }
        },
        "ec8c33fdf95b40a9870e741f34c35542": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75f8a289e68c4eff93fca798ecbedd0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a427db27cd6f47b9b1d2decd2ecb5f55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "651bab8f4fed440a8aa66a900260fbfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c362606894c44b3abfe634deeda8e46a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iABXs37PYLuP",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using {torch.cuda.get_device_name(0)}')"
      ],
      "metadata": {
        "id": "VHdEPmVXbC_g",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bd5c312-e406-4a85-f887-2be0482f7049"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.15.2)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.31)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.22.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpoppyfynes11\u001b[0m (\u001b[33mfartffart\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imfTPkppJp0E",
        "outputId": "271c9adc-4b97-417e-e4df-d664b8cc631b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialise training variables and datasets, split into train, validation and test sets."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "agrX3EK6Jp0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training variables\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 150\n",
        "LEARNING_RATE = 0.0001"
      ],
      "metadata": {
        "id": "WZi6DrrfbEkT",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformations for the train, validation, and test datasets\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(224,224, antialias=True),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224), antialias=True),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "augment_transform = transforms.Compose([\n",
        "    train_transform,\n",
        "    transforms.RandomApply(\n",
        "        [transforms.RandomApply([transforms.RandomAffine(degrees=359, translate=(0.2, 0.2), shear=(20, 20, 20, 20)),\n",
        "                                 transforms.RandomHorizontalFlip(1), transforms.RandomVerticalFlip(1)], p=0.7),\n",
        "         transforms.ColorJitter(brightness=(0.75, 1.25), contrast=(0.75, 1.25), hue=(-0.15, 0.15),\n",
        "                                saturation=(0.75, 1.25))\n",
        "         ]\n",
        "    )\n",
        "])\n",
        "\n",
        "# Load the train, validation, and test datasets\n",
        "train_dataset = datasets.Flowers102(root=\"./data\", split=\"train\", transform=train_transform, download=True)\n",
        "all_train_data = [train_dataset]\n",
        "for i in range(1):  # augmented train dataset, concatenated with normal train dataset\n",
        "    all_train_data.append(\n",
        "        datasets.Flowers102(root=\"./data\", split=\"train\", transform=augment_transform, download=False))\n",
        "train_dataset_extra = torch.utils.data.ConcatDataset(all_train_data)\n",
        "\n",
        "train_loader = DataLoader(train_dataset_extra, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_dataset = datasets.Flowers102(root=\"./data\", split=\"val\", transform=val_test_transform, download=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "test_dataset = datasets.Flowers102(root=\"./data\", split=\"test\", transform=val_test_transform, download=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "WLXBzxwbbO_w",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b598cc3-cbc5-49b1-e7bd-3eb81fc0c653"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 344862509/344862509 [00:16<00:00, 21165917.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 502/502 [00:00<00:00, 571846.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14989/14989 [00:00<00:00, 22712580.44it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "source": [
        "# Data for plots\n",
        "val_accuracies, val_losses, train_accuracies, train_losses = [], [], [], []\n",
        "plt.rcParams['axes.grid'] = True  # grid on all plots"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jB_uO6DpJp0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define CNN model."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "f5C3LZJgJp0K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(16),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2))  # 224 -> 112\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(32),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2))  # 112 -> 56\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(64),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2))  # 56 -> 28\n",
        "        self.conv4 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(128),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2))  # 28 -> 14\n",
        "        self.conv5 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(256),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2))  # 14 -> 7\n",
        "        self.conv6 = nn.Sequential(nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(512),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.MaxPool2d(2, 2))  # 7 -> 3\n",
        "        self.conv7 = nn.Sequential(nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1),\n",
        "                                   nn.BatchNorm2d(1024),\n",
        "                                   nn.MaxPool2d(2, 2))  # 3 -> 1\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Sequential(nn.Linear(1024, 512),\n",
        "                                 nn.ReLU())\n",
        "        self.fc2 = nn.Sequential(nn.Linear(512, 256),\n",
        "                                 nn.ReLU())\n",
        "\n",
        "        self.fc3 = nn.Sequential(nn.Linear(256, 102))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.conv6(x)\n",
        "        x = self.conv7(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "yeq6L8fBJp0N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to save the model with the best validation accuracy."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "WlIjCVIIJp0P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [],
      "source": [
        "def save_network(network, epoch_label):\n",
        "    save_filename = 'net_%s.pth' % epoch_label\n",
        "    save_path = os.path.join('./savedModels', save_filename)\n",
        "    torch.save(network.cpu().state_dict(), save_path)\n",
        "    if torch.cuda.is_available():\n",
        "       network.cuda()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "FxVSWofuJp0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialise CNN instance and train."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "KjMpRpm7Jp0Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230509_124855-s114eadu</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/fartffart/final-tests/runs/s114eadu' target=\"_blank\">0.0001</a></strong> to <a href='https://wandb.ai/fartffart/final-tests' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/fartffart/final-tests' target=\"_blank\">https://wandb.ai/fartffart/final-tests</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/fartffart/final-tests/runs/s114eadu' target=\"_blank\">https://wandb.ai/fartffart/final-tests/runs/s114eadu</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/fartffart/final-tests/runs/s114eadu?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f0f50e42fb0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "wandb.init(\n",
        "    name=str(LEARNING_RATE),\n",
        "    project=\"final-tests\",\n",
        "    config={\n",
        "        \"learning_rate\": LEARNING_RATE,\n",
        "        \"architecture\": \"CNN-256L\",\n",
        "        \"dataset\": \"Flowers102\",\n",
        "        \"epochs\": EPOCHS,\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "N3AUt4HhJp0R",
        "outputId": "949ac44b-6d27-4d13-99a2-bc8406ec3d76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear CUDA cache\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# Create an instance of the CNN and move it to the device\n",
        "cnn = CNN().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Set weight decay\n",
        "WEIGHT_DECAY = 0.03\n",
        "\n",
        "# Create the optimizer and add weight decay\n",
        "optimizer = optim.Adam(cnn.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "# lr scheduler\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.1, verbose=True)"
      ],
      "metadata": {
        "id": "c3L6lRUEbjFp",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "yhGoXwwnQiQu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "29569cc81afe4070885303dce4d147a1",
            "48dc304107ec4d6b9d89f1d995e1f110",
            "a9dd3eba3e4946a8bc7d1475ce361bab",
            "ec8c33fdf95b40a9870e741f34c35542",
            "75f8a289e68c4eff93fca798ecbedd0c",
            "a427db27cd6f47b9b1d2decd2ecb5f55",
            "651bab8f4fed440a8aa66a900260fbfb",
            "c362606894c44b3abfe634deeda8e46a"
          ]
        },
        "outputId": "b8b056a4-c738-42ae-906d-c460cb33b652",
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training with learning rate 0.0001000\n",
            "--------- Epoch 1 ----------\n",
            "Epoch [1/150], Step [32/64], Step Loss: 4.5317\n",
            "Epoch [1/150], Step [64/64], Step Loss: 4.3406\n",
            "Epoch [1/150], Training Loss: 4.5044, Training Accuracy: 3.33%\n",
            "Epoch [1/150], Validation Loss: 4.2226, Validation Accuracy: 9.12%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 2 ----------\n",
            "Epoch [2/150], Step [32/64], Step Loss: 4.1879\n",
            "Epoch [2/150], Step [64/64], Step Loss: 3.8310\n",
            "Epoch [2/150], Training Loss: 4.0678, Training Accuracy: 8.73%\n",
            "Epoch [2/150], Validation Loss: 3.8843, Validation Accuracy: 11.08%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 3 ----------\n",
            "Epoch [3/150], Step [32/64], Step Loss: 3.5624\n",
            "Epoch [3/150], Step [64/64], Step Loss: 3.2464\n",
            "Epoch [3/150], Training Loss: 3.6310, Training Accuracy: 13.97%\n",
            "Epoch [3/150], Validation Loss: 3.4726, Validation Accuracy: 18.43%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 4 ----------\n",
            "Epoch [4/150], Step [32/64], Step Loss: 3.2248\n",
            "Epoch [4/150], Step [64/64], Step Loss: 3.0905\n",
            "Epoch [4/150], Training Loss: 3.2954, Training Accuracy: 19.36%\n",
            "Epoch [4/150], Validation Loss: 3.2803, Validation Accuracy: 19.22%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 5 ----------\n",
            "Epoch [5/150], Step [32/64], Step Loss: 2.9783\n",
            "Epoch [5/150], Step [64/64], Step Loss: 3.0987\n",
            "Epoch [5/150], Training Loss: 3.1068, Training Accuracy: 23.38%\n",
            "Epoch [5/150], Validation Loss: 3.0241, Validation Accuracy: 23.43%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 6 ----------\n",
            "Epoch [6/150], Step [32/64], Step Loss: 2.8029\n",
            "Epoch [6/150], Step [64/64], Step Loss: 2.8374\n",
            "Epoch [6/150], Training Loss: 2.8648, Training Accuracy: 29.12%\n",
            "Epoch [6/150], Validation Loss: 2.8247, Validation Accuracy: 28.92%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 7 ----------\n",
            "Epoch [7/150], Step [32/64], Step Loss: 2.7453\n",
            "Epoch [7/150], Step [64/64], Step Loss: 2.6622\n",
            "Epoch [7/150], Training Loss: 2.7004, Training Accuracy: 32.06%\n",
            "Epoch [7/150], Validation Loss: 2.8551, Validation Accuracy: 28.82%\n",
            "--------- Epoch 8 ----------\n",
            "Epoch [8/150], Step [32/64], Step Loss: 2.8819\n",
            "Epoch [8/150], Step [64/64], Step Loss: 2.5283\n",
            "Epoch [8/150], Training Loss: 2.5308, Training Accuracy: 36.47%\n",
            "Epoch [8/150], Validation Loss: 2.8345, Validation Accuracy: 30.49%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 9 ----------\n",
            "Epoch [9/150], Step [32/64], Step Loss: 2.4519\n",
            "Epoch [9/150], Step [64/64], Step Loss: 2.8436\n",
            "Epoch [9/150], Training Loss: 2.3640, Training Accuracy: 40.83%\n",
            "Epoch [9/150], Validation Loss: 2.5497, Validation Accuracy: 33.73%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 10 ----------\n",
            "Epoch [10/150], Step [32/64], Step Loss: 2.2077\n",
            "Epoch [10/150], Step [64/64], Step Loss: 2.0157\n",
            "Epoch [10/150], Training Loss: 2.2456, Training Accuracy: 43.53%\n",
            "Epoch [10/150], Validation Loss: 2.6609, Validation Accuracy: 32.84%\n",
            "--------- Epoch 11 ----------\n",
            "Epoch [11/150], Step [32/64], Step Loss: 1.7907\n",
            "Epoch [11/150], Step [64/64], Step Loss: 2.1976\n",
            "Epoch [11/150], Training Loss: 2.1213, Training Accuracy: 45.64%\n",
            "Epoch [11/150], Validation Loss: 2.7279, Validation Accuracy: 31.67%\n",
            "--------- Epoch 12 ----------\n",
            "Epoch [12/150], Step [32/64], Step Loss: 2.0171\n",
            "Epoch [12/150], Step [64/64], Step Loss: 2.2665\n",
            "Epoch [12/150], Training Loss: 1.9481, Training Accuracy: 51.72%\n",
            "Epoch [12/150], Validation Loss: 2.5324, Validation Accuracy: 37.25%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 13 ----------\n",
            "Epoch [13/150], Step [32/64], Step Loss: 1.9135\n",
            "Epoch [13/150], Step [64/64], Step Loss: 1.8881\n",
            "Epoch [13/150], Training Loss: 1.9104, Training Accuracy: 52.79%\n",
            "Epoch [13/150], Validation Loss: 2.4880, Validation Accuracy: 36.76%\n",
            "--------- Epoch 14 ----------\n",
            "Epoch [14/150], Step [32/64], Step Loss: 2.0337\n",
            "Epoch [14/150], Step [64/64], Step Loss: 1.9946\n",
            "Epoch [14/150], Training Loss: 1.8277, Training Accuracy: 52.84%\n",
            "Epoch [14/150], Validation Loss: 2.3798, Validation Accuracy: 39.31%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 15 ----------\n",
            "Epoch [15/150], Step [32/64], Step Loss: 1.3287\n",
            "Epoch [15/150], Step [64/64], Step Loss: 1.7661\n",
            "Epoch [15/150], Training Loss: 1.6566, Training Accuracy: 59.41%\n",
            "Epoch [15/150], Validation Loss: 2.3999, Validation Accuracy: 37.84%\n",
            "--------- Epoch 16 ----------\n",
            "Epoch [16/150], Step [32/64], Step Loss: 1.4183\n",
            "Epoch [16/150], Step [64/64], Step Loss: 1.9009\n",
            "Epoch [16/150], Training Loss: 1.5365, Training Accuracy: 63.58%\n",
            "Epoch [16/150], Validation Loss: 2.2535, Validation Accuracy: 42.55%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 17 ----------\n",
            "Epoch [17/150], Step [32/64], Step Loss: 1.6333\n",
            "Epoch [17/150], Step [64/64], Step Loss: 1.8048\n",
            "Epoch [17/150], Training Loss: 1.5101, Training Accuracy: 63.97%\n",
            "Epoch [17/150], Validation Loss: 2.1793, Validation Accuracy: 46.57%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 18 ----------\n",
            "Epoch [18/150], Step [32/64], Step Loss: 1.6428\n",
            "Epoch [18/150], Step [64/64], Step Loss: 1.4968\n",
            "Epoch [18/150], Training Loss: 1.4634, Training Accuracy: 65.98%\n",
            "Epoch [18/150], Validation Loss: 2.2531, Validation Accuracy: 44.22%\n",
            "--------- Epoch 19 ----------\n",
            "Epoch [19/150], Step [32/64], Step Loss: 1.6306\n",
            "Epoch [19/150], Step [64/64], Step Loss: 1.0583\n",
            "Epoch [19/150], Training Loss: 1.3575, Training Accuracy: 68.28%\n",
            "Epoch [19/150], Validation Loss: 2.1996, Validation Accuracy: 44.71%\n",
            "--------- Epoch 20 ----------\n",
            "Epoch [20/150], Step [32/64], Step Loss: 1.2170\n",
            "Epoch [20/150], Step [64/64], Step Loss: 1.7446\n",
            "Epoch [20/150], Training Loss: 1.3555, Training Accuracy: 67.06%\n",
            "Epoch [20/150], Validation Loss: 2.3687, Validation Accuracy: 43.82%\n",
            "--------- Epoch 21 ----------\n",
            "Epoch [21/150], Step [32/64], Step Loss: 1.1509\n",
            "Epoch [21/150], Step [64/64], Step Loss: 1.2706\n",
            "Epoch [21/150], Training Loss: 1.2423, Training Accuracy: 70.83%\n",
            "Epoch [21/150], Validation Loss: 2.2160, Validation Accuracy: 44.90%\n",
            "--------- Epoch 22 ----------\n",
            "Epoch [22/150], Step [32/64], Step Loss: 1.3418\n",
            "Epoch [22/150], Step [64/64], Step Loss: 1.7448\n",
            "Epoch [22/150], Training Loss: 1.2565, Training Accuracy: 71.18%\n",
            "Epoch [22/150], Validation Loss: 2.1322, Validation Accuracy: 45.78%\n",
            "--------- Epoch 23 ----------\n",
            "Epoch [23/150], Step [32/64], Step Loss: 0.8910\n",
            "Epoch [23/150], Step [64/64], Step Loss: 1.7152\n",
            "Epoch [23/150], Training Loss: 1.1779, Training Accuracy: 73.73%\n",
            "Epoch [23/150], Validation Loss: 2.5016, Validation Accuracy: 39.51%\n",
            "--------- Epoch 24 ----------\n",
            "Epoch [24/150], Step [32/64], Step Loss: 1.4575\n",
            "Epoch [24/150], Step [64/64], Step Loss: 1.2030\n",
            "Epoch [24/150], Training Loss: 1.1118, Training Accuracy: 74.26%\n",
            "Epoch [24/150], Validation Loss: 2.8704, Validation Accuracy: 37.06%\n",
            "--------- Epoch 25 ----------\n",
            "Epoch [25/150], Step [32/64], Step Loss: 0.7495\n",
            "Epoch [25/150], Step [64/64], Step Loss: 1.1529\n",
            "Epoch [25/150], Training Loss: 1.1086, Training Accuracy: 75.54%\n",
            "Epoch [25/150], Validation Loss: 2.3252, Validation Accuracy: 45.20%\n",
            "--------- Epoch 26 ----------\n",
            "Epoch [26/150], Step [32/64], Step Loss: 1.0358\n",
            "Epoch [26/150], Step [64/64], Step Loss: 0.7094\n",
            "Epoch [26/150], Training Loss: 1.0084, Training Accuracy: 78.14%\n",
            "Epoch [26/150], Validation Loss: 2.2139, Validation Accuracy: 47.35%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 27 ----------\n",
            "Epoch [27/150], Step [32/64], Step Loss: 1.0390\n",
            "Epoch [27/150], Step [64/64], Step Loss: 0.9777\n",
            "Epoch [27/150], Training Loss: 1.0343, Training Accuracy: 77.35%\n",
            "Epoch [27/150], Validation Loss: 2.1170, Validation Accuracy: 46.76%\n",
            "--------- Epoch 28 ----------\n",
            "Epoch [28/150], Step [32/64], Step Loss: 1.0633\n",
            "Epoch [28/150], Step [64/64], Step Loss: 0.9255\n",
            "Epoch [28/150], Training Loss: 1.0267, Training Accuracy: 78.09%\n",
            "Epoch [28/150], Validation Loss: 2.1557, Validation Accuracy: 48.63%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 29 ----------\n",
            "Epoch [29/150], Step [32/64], Step Loss: 1.3043\n",
            "Epoch [29/150], Step [64/64], Step Loss: 0.7964\n",
            "Epoch [29/150], Training Loss: 0.9629, Training Accuracy: 78.97%\n",
            "Epoch [29/150], Validation Loss: 1.9944, Validation Accuracy: 50.69%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 30 ----------\n",
            "Epoch [30/150], Step [32/64], Step Loss: 1.0090\n",
            "Epoch [30/150], Step [64/64], Step Loss: 0.8514\n",
            "Epoch [30/150], Training Loss: 1.0293, Training Accuracy: 77.21%\n",
            "Epoch [30/150], Validation Loss: 2.1945, Validation Accuracy: 46.76%\n",
            "--------- Epoch 31 ----------\n",
            "Epoch [31/150], Step [32/64], Step Loss: 0.7259\n",
            "Epoch [31/150], Step [64/64], Step Loss: 0.7183\n",
            "Epoch [31/150], Training Loss: 0.9758, Training Accuracy: 77.75%\n",
            "Epoch [31/150], Validation Loss: 2.1596, Validation Accuracy: 48.33%\n",
            "--------- Epoch 32 ----------\n",
            "Epoch [32/150], Step [32/64], Step Loss: 1.0295\n",
            "Epoch [32/150], Step [64/64], Step Loss: 0.7230\n",
            "Epoch [32/150], Training Loss: 1.0258, Training Accuracy: 77.79%\n",
            "Epoch [32/150], Validation Loss: 2.1642, Validation Accuracy: 47.25%\n",
            "--------- Epoch 33 ----------\n",
            "Epoch [33/150], Step [32/64], Step Loss: 0.8718\n",
            "Epoch [33/150], Step [64/64], Step Loss: 1.1211\n",
            "Epoch [33/150], Training Loss: 0.8978, Training Accuracy: 80.93%\n",
            "Epoch [33/150], Validation Loss: 2.2441, Validation Accuracy: 46.67%\n",
            "--------- Epoch 34 ----------\n",
            "Epoch [34/150], Step [32/64], Step Loss: 0.9852\n",
            "Epoch [34/150], Step [64/64], Step Loss: 1.3390\n",
            "Epoch [34/150], Training Loss: 0.9264, Training Accuracy: 79.46%\n",
            "Epoch [34/150], Validation Loss: 2.0936, Validation Accuracy: 49.41%\n",
            "--------- Epoch 35 ----------\n",
            "Epoch [35/150], Step [32/64], Step Loss: 0.7287\n",
            "Epoch [35/150], Step [64/64], Step Loss: 0.9909\n",
            "Epoch [35/150], Training Loss: 0.9309, Training Accuracy: 80.64%\n",
            "Epoch [35/150], Validation Loss: 1.9861, Validation Accuracy: 49.51%\n",
            "--------- Epoch 36 ----------\n",
            "Epoch [36/150], Step [32/64], Step Loss: 0.6162\n",
            "Epoch [36/150], Step [64/64], Step Loss: 0.8724\n",
            "Epoch [36/150], Training Loss: 0.8994, Training Accuracy: 80.49%\n",
            "Epoch [36/150], Validation Loss: 2.0218, Validation Accuracy: 49.90%\n",
            "--------- Epoch 37 ----------\n",
            "Epoch [37/150], Step [32/64], Step Loss: 0.4649\n",
            "Epoch [37/150], Step [64/64], Step Loss: 0.9489\n",
            "Epoch [37/150], Training Loss: 0.8609, Training Accuracy: 82.94%\n",
            "Epoch [37/150], Validation Loss: 2.1035, Validation Accuracy: 50.49%\n",
            "--------- Epoch 38 ----------\n",
            "Epoch [38/150], Step [32/64], Step Loss: 0.7673\n",
            "Epoch [38/150], Step [64/64], Step Loss: 1.1199\n",
            "Epoch [38/150], Training Loss: 0.8678, Training Accuracy: 81.18%\n",
            "Epoch [38/150], Validation Loss: 2.0527, Validation Accuracy: 50.49%\n",
            "--------- Epoch 39 ----------\n",
            "Epoch [39/150], Step [32/64], Step Loss: 0.7465\n",
            "Epoch [39/150], Step [64/64], Step Loss: 0.5208\n",
            "Epoch [39/150], Training Loss: 0.8589, Training Accuracy: 82.21%\n",
            "Epoch [39/150], Validation Loss: 2.0569, Validation Accuracy: 51.27%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 40 ----------\n",
            "Epoch [40/150], Step [32/64], Step Loss: 0.6294\n",
            "Epoch [40/150], Step [64/64], Step Loss: 1.1074\n",
            "Epoch [40/150], Training Loss: 0.8418, Training Accuracy: 82.35%\n",
            "Epoch [40/150], Validation Loss: 1.9938, Validation Accuracy: 49.41%\n",
            "--------- Epoch 41 ----------\n",
            "Epoch [41/150], Step [32/64], Step Loss: 0.5010\n",
            "Epoch [41/150], Step [64/64], Step Loss: 0.9278\n",
            "Epoch [41/150], Training Loss: 0.8795, Training Accuracy: 81.08%\n",
            "Epoch [41/150], Validation Loss: 2.0093, Validation Accuracy: 52.35%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 42 ----------\n",
            "Epoch [42/150], Step [32/64], Step Loss: 1.1001\n",
            "Epoch [42/150], Step [64/64], Step Loss: 0.8773\n",
            "Epoch [42/150], Training Loss: 0.8249, Training Accuracy: 82.30%\n",
            "Epoch [42/150], Validation Loss: 2.3037, Validation Accuracy: 44.31%\n",
            "--------- Epoch 43 ----------\n",
            "Epoch [43/150], Step [32/64], Step Loss: 0.8567\n",
            "Epoch [43/150], Step [64/64], Step Loss: 0.5782\n",
            "Epoch [43/150], Training Loss: 0.8278, Training Accuracy: 81.96%\n",
            "Epoch [43/150], Validation Loss: 1.9101, Validation Accuracy: 52.94%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 44 ----------\n",
            "Epoch [44/150], Step [32/64], Step Loss: 0.6851\n",
            "Epoch [44/150], Step [64/64], Step Loss: 0.6488\n",
            "Epoch [44/150], Training Loss: 0.7575, Training Accuracy: 83.68%\n",
            "Epoch [44/150], Validation Loss: 1.9710, Validation Accuracy: 50.20%\n",
            "--------- Epoch 45 ----------\n",
            "Epoch [45/150], Step [32/64], Step Loss: 1.1533\n",
            "Epoch [45/150], Step [64/64], Step Loss: 0.9693\n",
            "Epoch [45/150], Training Loss: 0.8227, Training Accuracy: 81.27%\n",
            "Epoch [45/150], Validation Loss: 2.1132, Validation Accuracy: 49.90%\n",
            "--------- Epoch 46 ----------\n",
            "Epoch [46/150], Step [32/64], Step Loss: 0.8667\n",
            "Epoch [46/150], Step [64/64], Step Loss: 1.0685\n",
            "Epoch [46/150], Training Loss: 0.8611, Training Accuracy: 81.96%\n",
            "Epoch [46/150], Validation Loss: 2.1156, Validation Accuracy: 47.94%\n",
            "--------- Epoch 47 ----------\n",
            "Epoch [47/150], Step [32/64], Step Loss: 0.8651\n",
            "Epoch [47/150], Step [64/64], Step Loss: 1.2292\n",
            "Epoch [47/150], Training Loss: 0.8184, Training Accuracy: 81.96%\n",
            "Epoch [47/150], Validation Loss: 2.0667, Validation Accuracy: 51.18%\n",
            "--------- Epoch 48 ----------\n",
            "Epoch [48/150], Step [32/64], Step Loss: 0.9831\n",
            "Epoch [48/150], Step [64/64], Step Loss: 0.8102\n",
            "Epoch [48/150], Training Loss: 0.8816, Training Accuracy: 81.32%\n",
            "Epoch [48/150], Validation Loss: 2.0545, Validation Accuracy: 50.69%\n",
            "--------- Epoch 49 ----------\n",
            "Epoch [49/150], Step [32/64], Step Loss: 0.7674\n",
            "Epoch [49/150], Step [64/64], Step Loss: 0.7094\n",
            "Epoch [49/150], Training Loss: 0.8683, Training Accuracy: 80.29%\n",
            "Epoch [49/150], Validation Loss: 1.8520, Validation Accuracy: 55.69%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 50 ----------\n",
            "Epoch [50/150], Step [32/64], Step Loss: 0.6134\n",
            "Epoch [50/150], Step [64/64], Step Loss: 0.6213\n",
            "Epoch [50/150], Training Loss: 0.8293, Training Accuracy: 82.89%\n",
            "Epoch [50/150], Validation Loss: 1.9243, Validation Accuracy: 52.84%\n",
            "--------- Epoch 51 ----------\n",
            "Epoch [51/150], Step [32/64], Step Loss: 0.8794\n",
            "Epoch [51/150], Step [64/64], Step Loss: 0.9422\n",
            "Epoch [51/150], Training Loss: 0.8219, Training Accuracy: 82.94%\n",
            "Epoch [51/150], Validation Loss: 1.9726, Validation Accuracy: 52.16%\n",
            "--------- Epoch 52 ----------\n",
            "Epoch [52/150], Step [32/64], Step Loss: 0.9848\n",
            "Epoch [52/150], Step [64/64], Step Loss: 0.5997\n",
            "Epoch [52/150], Training Loss: 0.7859, Training Accuracy: 82.79%\n",
            "Epoch [52/150], Validation Loss: 1.9411, Validation Accuracy: 52.94%\n",
            "--------- Epoch 53 ----------\n",
            "Epoch [53/150], Step [32/64], Step Loss: 0.8675\n",
            "Epoch [53/150], Step [64/64], Step Loss: 0.6102\n",
            "Epoch [53/150], Training Loss: 0.7797, Training Accuracy: 83.77%\n",
            "Epoch [53/150], Validation Loss: 1.8625, Validation Accuracy: 53.24%\n",
            "--------- Epoch 54 ----------\n",
            "Epoch [54/150], Step [32/64], Step Loss: 0.7060\n",
            "Epoch [54/150], Step [64/64], Step Loss: 0.8979\n",
            "Epoch [54/150], Training Loss: 0.7587, Training Accuracy: 84.31%\n",
            "Epoch [54/150], Validation Loss: 2.0540, Validation Accuracy: 49.41%\n",
            "--------- Epoch 55 ----------\n",
            "Epoch [55/150], Step [32/64], Step Loss: 0.7262\n",
            "Epoch [55/150], Step [64/64], Step Loss: 0.7300\n",
            "Epoch [55/150], Training Loss: 0.7687, Training Accuracy: 83.77%\n",
            "Epoch [55/150], Validation Loss: 1.9829, Validation Accuracy: 52.25%\n",
            "--------- Epoch 56 ----------\n",
            "Epoch [56/150], Step [32/64], Step Loss: 0.6593\n",
            "Epoch [56/150], Step [64/64], Step Loss: 1.0568\n",
            "Epoch [56/150], Training Loss: 0.8028, Training Accuracy: 82.35%\n",
            "Epoch [56/150], Validation Loss: 2.0130, Validation Accuracy: 49.22%\n",
            "--------- Epoch 57 ----------\n",
            "Epoch [57/150], Step [32/64], Step Loss: 0.5969\n",
            "Epoch [57/150], Step [64/64], Step Loss: 0.7062\n",
            "Epoch [57/150], Training Loss: 0.7653, Training Accuracy: 84.02%\n",
            "Epoch [57/150], Validation Loss: 1.8767, Validation Accuracy: 52.35%\n",
            "--------- Epoch 58 ----------\n",
            "Epoch [58/150], Step [32/64], Step Loss: 0.7415\n",
            "Epoch [58/150], Step [64/64], Step Loss: 0.8285\n",
            "Epoch [58/150], Training Loss: 0.7989, Training Accuracy: 83.28%\n",
            "Epoch [58/150], Validation Loss: 1.9427, Validation Accuracy: 51.47%\n",
            "--------- Epoch 59 ----------\n",
            "Epoch [59/150], Step [32/64], Step Loss: 0.8011\n",
            "Epoch [59/150], Step [64/64], Step Loss: 0.6453\n",
            "Epoch [59/150], Training Loss: 0.8385, Training Accuracy: 82.45%\n",
            "Epoch [59/150], Validation Loss: 1.9182, Validation Accuracy: 52.94%\n",
            "--------- Epoch 60 ----------\n",
            "Epoch [60/150], Step [32/64], Step Loss: 0.8346\n",
            "Epoch [60/150], Step [64/64], Step Loss: 0.7155\n",
            "Epoch [60/150], Training Loss: 0.7465, Training Accuracy: 84.17%\n",
            "Epoch [60/150], Validation Loss: 1.9632, Validation Accuracy: 51.86%\n",
            "Epoch 00060: reducing learning rate of group 0 to 1.0000e-05.\n",
            "--------- Epoch 61 ----------\n",
            "Epoch [61/150], Step [32/64], Step Loss: 0.6589\n",
            "Epoch [61/150], Step [64/64], Step Loss: 0.4654\n",
            "Epoch [61/150], Training Loss: 0.6634, Training Accuracy: 85.05%\n",
            "Epoch [61/150], Validation Loss: 1.6287, Validation Accuracy: 59.22%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 62 ----------\n",
            "Epoch [62/150], Step [32/64], Step Loss: 0.5646\n",
            "Epoch [62/150], Step [64/64], Step Loss: 1.0155\n",
            "Epoch [62/150], Training Loss: 0.6123, Training Accuracy: 86.57%\n",
            "Epoch [62/150], Validation Loss: 1.6068, Validation Accuracy: 59.90%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 63 ----------\n",
            "Epoch [63/150], Step [32/64], Step Loss: 0.3841\n",
            "Epoch [63/150], Step [64/64], Step Loss: 0.4982\n",
            "Epoch [63/150], Training Loss: 0.5554, Training Accuracy: 88.48%\n",
            "Epoch [63/150], Validation Loss: 1.5974, Validation Accuracy: 60.29%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 64 ----------\n",
            "Epoch [64/150], Step [32/64], Step Loss: 0.5318\n",
            "Epoch [64/150], Step [64/64], Step Loss: 0.4037\n",
            "Epoch [64/150], Training Loss: 0.5477, Training Accuracy: 87.75%\n",
            "Epoch [64/150], Validation Loss: 1.6265, Validation Accuracy: 58.43%\n",
            "--------- Epoch 65 ----------\n",
            "Epoch [65/150], Step [32/64], Step Loss: 0.6168\n",
            "Epoch [65/150], Step [64/64], Step Loss: 0.5205\n",
            "Epoch [65/150], Training Loss: 0.5440, Training Accuracy: 88.24%\n",
            "Epoch [65/150], Validation Loss: 1.6016, Validation Accuracy: 60.59%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 66 ----------\n",
            "Epoch [66/150], Step [32/64], Step Loss: 0.3718\n",
            "Epoch [66/150], Step [64/64], Step Loss: 0.4163\n",
            "Epoch [66/150], Training Loss: 0.5497, Training Accuracy: 88.19%\n",
            "Epoch [66/150], Validation Loss: 1.5954, Validation Accuracy: 61.47%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 67 ----------\n",
            "Epoch [67/150], Step [32/64], Step Loss: 0.3507\n",
            "Epoch [67/150], Step [64/64], Step Loss: 0.4971\n",
            "Epoch [67/150], Training Loss: 0.5385, Training Accuracy: 88.19%\n",
            "Epoch [67/150], Validation Loss: 1.5981, Validation Accuracy: 60.98%\n",
            "--------- Epoch 68 ----------\n",
            "Epoch [68/150], Step [32/64], Step Loss: 0.2196\n",
            "Epoch [68/150], Step [64/64], Step Loss: 0.4959\n",
            "Epoch [68/150], Training Loss: 0.5218, Training Accuracy: 88.77%\n",
            "Epoch [68/150], Validation Loss: 1.6105, Validation Accuracy: 61.27%\n",
            "--------- Epoch 69 ----------\n",
            "Epoch [69/150], Step [32/64], Step Loss: 0.3649\n",
            "Epoch [69/150], Step [64/64], Step Loss: 0.4264\n",
            "Epoch [69/150], Training Loss: 0.5530, Training Accuracy: 88.43%\n",
            "Epoch [69/150], Validation Loss: 1.6000, Validation Accuracy: 60.49%\n",
            "--------- Epoch 70 ----------\n",
            "Epoch [70/150], Step [32/64], Step Loss: 0.4795\n",
            "Epoch [70/150], Step [64/64], Step Loss: 0.6141\n",
            "Epoch [70/150], Training Loss: 0.4981, Training Accuracy: 89.75%\n",
            "Epoch [70/150], Validation Loss: 1.5952, Validation Accuracy: 60.29%\n",
            "--------- Epoch 71 ----------\n",
            "Epoch [71/150], Step [32/64], Step Loss: 0.3194\n",
            "Epoch [71/150], Step [64/64], Step Loss: 0.8502\n",
            "Epoch [71/150], Training Loss: 0.5724, Training Accuracy: 87.30%\n",
            "Epoch [71/150], Validation Loss: 1.6111, Validation Accuracy: 60.59%\n",
            "--------- Epoch 72 ----------\n",
            "Epoch [72/150], Step [32/64], Step Loss: 0.2905\n",
            "Epoch [72/150], Step [64/64], Step Loss: 0.3515\n",
            "Epoch [72/150], Training Loss: 0.5258, Training Accuracy: 88.19%\n",
            "Epoch [72/150], Validation Loss: 1.5991, Validation Accuracy: 61.18%\n",
            "--------- Epoch 73 ----------\n",
            "Epoch [73/150], Step [32/64], Step Loss: 0.3911\n",
            "Epoch [73/150], Step [64/64], Step Loss: 0.4438\n",
            "Epoch [73/150], Training Loss: 0.5480, Training Accuracy: 88.14%\n",
            "Epoch [73/150], Validation Loss: 1.5984, Validation Accuracy: 60.10%\n",
            "--------- Epoch 74 ----------\n",
            "Epoch [74/150], Step [32/64], Step Loss: 0.1333\n",
            "Epoch [74/150], Step [64/64], Step Loss: 0.9521\n",
            "Epoch [74/150], Training Loss: 0.5352, Training Accuracy: 87.79%\n",
            "Epoch [74/150], Validation Loss: 1.5901, Validation Accuracy: 60.88%\n",
            "--------- Epoch 75 ----------\n",
            "Epoch [75/150], Step [32/64], Step Loss: 0.4669\n",
            "Epoch [75/150], Step [64/64], Step Loss: 0.4463\n",
            "Epoch [75/150], Training Loss: 0.5191, Training Accuracy: 88.33%\n",
            "Epoch [75/150], Validation Loss: 1.6158, Validation Accuracy: 59.71%\n",
            "--------- Epoch 76 ----------\n",
            "Epoch [76/150], Step [32/64], Step Loss: 0.7841\n",
            "Epoch [76/150], Step [64/64], Step Loss: 0.3064\n",
            "Epoch [76/150], Training Loss: 0.5195, Training Accuracy: 88.09%\n",
            "Epoch [76/150], Validation Loss: 1.6083, Validation Accuracy: 59.71%\n",
            "--------- Epoch 77 ----------\n",
            "Epoch [77/150], Step [32/64], Step Loss: 0.4129\n",
            "Epoch [77/150], Step [64/64], Step Loss: 0.5614\n",
            "Epoch [77/150], Training Loss: 0.5172, Training Accuracy: 89.26%\n",
            "Epoch [77/150], Validation Loss: 1.6010, Validation Accuracy: 61.57%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 78 ----------\n",
            "Epoch [78/150], Step [32/64], Step Loss: 0.3127\n",
            "Epoch [78/150], Step [64/64], Step Loss: 0.4228\n",
            "Epoch [78/150], Training Loss: 0.5241, Training Accuracy: 88.58%\n",
            "Epoch [78/150], Validation Loss: 1.6147, Validation Accuracy: 60.78%\n",
            "--------- Epoch 79 ----------\n",
            "Epoch [79/150], Step [32/64], Step Loss: 0.7575\n",
            "Epoch [79/150], Step [64/64], Step Loss: 0.7242\n",
            "Epoch [79/150], Training Loss: 0.5370, Training Accuracy: 88.38%\n",
            "Epoch [79/150], Validation Loss: 1.5993, Validation Accuracy: 61.57%\n",
            "--------- Epoch 80 ----------\n",
            "Epoch [80/150], Step [32/64], Step Loss: 0.4323\n",
            "Epoch [80/150], Step [64/64], Step Loss: 0.7241\n",
            "Epoch [80/150], Training Loss: 0.4852, Training Accuracy: 88.73%\n",
            "Epoch [80/150], Validation Loss: 1.6028, Validation Accuracy: 60.88%\n",
            "--------- Epoch 81 ----------\n",
            "Epoch [81/150], Step [32/64], Step Loss: 0.7067\n",
            "Epoch [81/150], Step [64/64], Step Loss: 0.3196\n",
            "Epoch [81/150], Training Loss: 0.5089, Training Accuracy: 89.02%\n",
            "Epoch [81/150], Validation Loss: 1.6195, Validation Accuracy: 60.59%\n",
            "--------- Epoch 82 ----------\n",
            "Epoch [82/150], Step [32/64], Step Loss: 0.7124\n",
            "Epoch [82/150], Step [64/64], Step Loss: 0.4943\n",
            "Epoch [82/150], Training Loss: 0.5041, Training Accuracy: 88.92%\n",
            "Epoch [82/150], Validation Loss: 1.6090, Validation Accuracy: 60.29%\n",
            "--------- Epoch 83 ----------\n",
            "Epoch [83/150], Step [32/64], Step Loss: 0.2808\n",
            "Epoch [83/150], Step [64/64], Step Loss: 0.5580\n",
            "Epoch [83/150], Training Loss: 0.5222, Training Accuracy: 89.51%\n",
            "Epoch [83/150], Validation Loss: 1.6217, Validation Accuracy: 60.10%\n",
            "--------- Epoch 84 ----------\n",
            "Epoch [84/150], Step [32/64], Step Loss: 0.4608\n",
            "Epoch [84/150], Step [64/64], Step Loss: 0.6784\n",
            "Epoch [84/150], Training Loss: 0.4725, Training Accuracy: 89.95%\n",
            "Epoch [84/150], Validation Loss: 1.6071, Validation Accuracy: 59.90%\n",
            "--------- Epoch 85 ----------\n",
            "Epoch [85/150], Step [32/64], Step Loss: 0.8458\n",
            "Epoch [85/150], Step [64/64], Step Loss: 0.7563\n",
            "Epoch [85/150], Training Loss: 0.5127, Training Accuracy: 89.17%\n",
            "Epoch [85/150], Validation Loss: 1.6044, Validation Accuracy: 60.39%\n",
            "Epoch 00085: reducing learning rate of group 0 to 1.0000e-06.\n",
            "--------- Epoch 86 ----------\n",
            "Epoch [86/150], Step [32/64], Step Loss: 0.3684\n",
            "Epoch [86/150], Step [64/64], Step Loss: 0.2608\n",
            "Epoch [86/150], Training Loss: 0.4530, Training Accuracy: 90.69%\n",
            "Epoch [86/150], Validation Loss: 1.5920, Validation Accuracy: 60.49%\n",
            "--------- Epoch 87 ----------\n",
            "Epoch [87/150], Step [32/64], Step Loss: 0.4543\n",
            "Epoch [87/150], Step [64/64], Step Loss: 0.4101\n",
            "Epoch [87/150], Training Loss: 0.5113, Training Accuracy: 88.68%\n",
            "Epoch [87/150], Validation Loss: 1.5960, Validation Accuracy: 61.67%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 88 ----------\n",
            "Epoch [88/150], Step [32/64], Step Loss: 0.6961\n",
            "Epoch [88/150], Step [64/64], Step Loss: 0.9760\n",
            "Epoch [88/150], Training Loss: 0.5016, Training Accuracy: 89.41%\n",
            "Epoch [88/150], Validation Loss: 1.5853, Validation Accuracy: 61.08%\n",
            "--------- Epoch 89 ----------\n",
            "Epoch [89/150], Step [32/64], Step Loss: 0.4507\n",
            "Epoch [89/150], Step [64/64], Step Loss: 0.7137\n",
            "Epoch [89/150], Training Loss: 0.5055, Training Accuracy: 89.12%\n",
            "Epoch [89/150], Validation Loss: 1.5879, Validation Accuracy: 61.08%\n",
            "--------- Epoch 90 ----------\n",
            "Epoch [90/150], Step [32/64], Step Loss: 0.4977\n",
            "Epoch [90/150], Step [64/64], Step Loss: 0.5595\n",
            "Epoch [90/150], Training Loss: 0.4920, Training Accuracy: 89.12%\n",
            "Epoch [90/150], Validation Loss: 1.5957, Validation Accuracy: 60.39%\n",
            "--------- Epoch 91 ----------\n",
            "Epoch [91/150], Step [32/64], Step Loss: 0.7614\n",
            "Epoch [91/150], Step [64/64], Step Loss: 0.9036\n",
            "Epoch [91/150], Training Loss: 0.5122, Training Accuracy: 88.43%\n",
            "Epoch [91/150], Validation Loss: 1.5905, Validation Accuracy: 61.18%\n",
            "--------- Epoch 92 ----------\n",
            "Epoch [92/150], Step [32/64], Step Loss: 0.3385\n",
            "Epoch [92/150], Step [64/64], Step Loss: 0.3948\n",
            "Epoch [92/150], Training Loss: 0.4265, Training Accuracy: 91.27%\n",
            "Epoch [92/150], Validation Loss: 1.5941, Validation Accuracy: 60.88%\n",
            "--------- Epoch 93 ----------\n",
            "Epoch [93/150], Step [32/64], Step Loss: 0.1890\n",
            "Epoch [93/150], Step [64/64], Step Loss: 0.4780\n",
            "Epoch [93/150], Training Loss: 0.4900, Training Accuracy: 89.51%\n",
            "Epoch [93/150], Validation Loss: 1.5849, Validation Accuracy: 60.49%\n",
            "--------- Epoch 94 ----------\n",
            "Epoch [94/150], Step [32/64], Step Loss: 0.4649\n",
            "Epoch [94/150], Step [64/64], Step Loss: 0.6486\n",
            "Epoch [94/150], Training Loss: 0.4814, Training Accuracy: 90.10%\n",
            "Epoch [94/150], Validation Loss: 1.5844, Validation Accuracy: 60.78%\n",
            "--------- Epoch 95 ----------\n",
            "Epoch [95/150], Step [32/64], Step Loss: 0.3312\n",
            "Epoch [95/150], Step [64/64], Step Loss: 0.4682\n",
            "Epoch [95/150], Training Loss: 0.4917, Training Accuracy: 89.75%\n",
            "Epoch [95/150], Validation Loss: 1.5942, Validation Accuracy: 60.49%\n",
            "--------- Epoch 96 ----------\n",
            "Epoch [96/150], Step [32/64], Step Loss: 0.6116\n",
            "Epoch [96/150], Step [64/64], Step Loss: 0.4946\n",
            "Epoch [96/150], Training Loss: 0.4965, Training Accuracy: 89.31%\n",
            "Epoch [96/150], Validation Loss: 1.5946, Validation Accuracy: 60.78%\n",
            "--------- Epoch 97 ----------\n",
            "Epoch [97/150], Step [32/64], Step Loss: 0.3052\n",
            "Epoch [97/150], Step [64/64], Step Loss: 0.2722\n",
            "Epoch [97/150], Training Loss: 0.4903, Training Accuracy: 89.85%\n",
            "Epoch [97/150], Validation Loss: 1.5875, Validation Accuracy: 60.78%\n",
            "--------- Epoch 98 ----------\n",
            "Epoch [98/150], Step [32/64], Step Loss: 0.7013\n",
            "Epoch [98/150], Step [64/64], Step Loss: 0.3672\n",
            "Epoch [98/150], Training Loss: 0.4829, Training Accuracy: 89.51%\n",
            "Epoch [98/150], Validation Loss: 1.5951, Validation Accuracy: 60.39%\n",
            "--------- Epoch 99 ----------\n",
            "Epoch [99/150], Step [32/64], Step Loss: 0.4195\n",
            "Epoch [99/150], Step [64/64], Step Loss: 0.8911\n",
            "Epoch [99/150], Training Loss: 0.4935, Training Accuracy: 88.58%\n",
            "Epoch [99/150], Validation Loss: 1.6029, Validation Accuracy: 60.98%\n",
            "--------- Epoch 100 ----------\n",
            "Epoch [100/150], Step [32/64], Step Loss: 0.4703\n",
            "Epoch [100/150], Step [64/64], Step Loss: 0.3205\n",
            "Epoch [100/150], Training Loss: 0.4690, Training Accuracy: 89.56%\n",
            "Epoch [100/150], Validation Loss: 1.5984, Validation Accuracy: 60.88%\n",
            "--------- Epoch 101 ----------\n",
            "Epoch [101/150], Step [32/64], Step Loss: 0.6100\n",
            "Epoch [101/150], Step [64/64], Step Loss: 0.1888\n",
            "Epoch [101/150], Training Loss: 0.4823, Training Accuracy: 89.90%\n",
            "Epoch [101/150], Validation Loss: 1.5900, Validation Accuracy: 60.69%\n",
            "--------- Epoch 102 ----------\n",
            "Epoch [102/150], Step [32/64], Step Loss: 0.6508\n",
            "Epoch [102/150], Step [64/64], Step Loss: 0.7574\n",
            "Epoch [102/150], Training Loss: 0.4673, Training Accuracy: 89.71%\n",
            "Epoch [102/150], Validation Loss: 1.5860, Validation Accuracy: 60.78%\n",
            "--------- Epoch 103 ----------\n",
            "Epoch [103/150], Step [32/64], Step Loss: 0.5898\n",
            "Epoch [103/150], Step [64/64], Step Loss: 0.6179\n",
            "Epoch [103/150], Training Loss: 0.4880, Training Accuracy: 89.31%\n",
            "Epoch [103/150], Validation Loss: 1.5849, Validation Accuracy: 60.98%\n",
            "--------- Epoch 104 ----------\n",
            "Epoch [104/150], Step [32/64], Step Loss: 0.3222\n",
            "Epoch [104/150], Step [64/64], Step Loss: 0.7895\n",
            "Epoch [104/150], Training Loss: 0.4895, Training Accuracy: 89.41%\n",
            "Epoch [104/150], Validation Loss: 1.5838, Validation Accuracy: 60.39%\n",
            "--------- Epoch 105 ----------\n",
            "Epoch [105/150], Step [32/64], Step Loss: 0.4872\n",
            "Epoch [105/150], Step [64/64], Step Loss: 0.5334\n",
            "Epoch [105/150], Training Loss: 0.4984, Training Accuracy: 88.58%\n",
            "Epoch [105/150], Validation Loss: 1.5892, Validation Accuracy: 60.78%\n",
            "--------- Epoch 106 ----------\n",
            "Epoch [106/150], Step [32/64], Step Loss: 0.6435\n",
            "Epoch [106/150], Step [64/64], Step Loss: 0.7503\n",
            "Epoch [106/150], Training Loss: 0.4566, Training Accuracy: 90.39%\n",
            "Epoch [106/150], Validation Loss: 1.5902, Validation Accuracy: 60.59%\n",
            "--------- Epoch 107 ----------\n",
            "Epoch [107/150], Step [32/64], Step Loss: 0.6214\n",
            "Epoch [107/150], Step [64/64], Step Loss: 0.5661\n",
            "Epoch [107/150], Training Loss: 0.4560, Training Accuracy: 90.64%\n",
            "Epoch [107/150], Validation Loss: 1.5934, Validation Accuracy: 61.08%\n",
            "--------- Epoch 108 ----------\n",
            "Epoch [108/150], Step [32/64], Step Loss: 0.3372\n",
            "Epoch [108/150], Step [64/64], Step Loss: 0.3217\n",
            "Epoch [108/150], Training Loss: 0.4844, Training Accuracy: 90.15%\n",
            "Epoch [108/150], Validation Loss: 1.5919, Validation Accuracy: 60.20%\n",
            "--------- Epoch 109 ----------\n",
            "Epoch [109/150], Step [32/64], Step Loss: 0.4236\n",
            "Epoch [109/150], Step [64/64], Step Loss: 0.5317\n",
            "Epoch [109/150], Training Loss: 0.4537, Training Accuracy: 90.29%\n",
            "Epoch [109/150], Validation Loss: 1.5916, Validation Accuracy: 60.78%\n",
            "--------- Epoch 110 ----------\n",
            "Epoch [110/150], Step [32/64], Step Loss: 0.4396\n",
            "Epoch [110/150], Step [64/64], Step Loss: 0.6960\n",
            "Epoch [110/150], Training Loss: 0.4870, Training Accuracy: 88.87%\n",
            "Epoch [110/150], Validation Loss: 1.5802, Validation Accuracy: 60.49%\n",
            "--------- Epoch 111 ----------\n",
            "Epoch [111/150], Step [32/64], Step Loss: 0.5682\n",
            "Epoch [111/150], Step [64/64], Step Loss: 0.6887\n",
            "Epoch [111/150], Training Loss: 0.4677, Training Accuracy: 90.10%\n",
            "Epoch [111/150], Validation Loss: 1.5785, Validation Accuracy: 60.29%\n",
            "--------- Epoch 112 ----------\n",
            "Epoch [112/150], Step [32/64], Step Loss: 0.7335\n",
            "Epoch [112/150], Step [64/64], Step Loss: 0.7654\n",
            "Epoch [112/150], Training Loss: 0.4851, Training Accuracy: 89.90%\n",
            "Epoch [112/150], Validation Loss: 1.5854, Validation Accuracy: 61.08%\n",
            "--------- Epoch 113 ----------\n",
            "Epoch [113/150], Step [32/64], Step Loss: 0.8547\n",
            "Epoch [113/150], Step [64/64], Step Loss: 0.2280\n",
            "Epoch [113/150], Training Loss: 0.4702, Training Accuracy: 89.66%\n",
            "Epoch [113/150], Validation Loss: 1.5878, Validation Accuracy: 61.08%\n",
            "--------- Epoch 114 ----------\n",
            "Epoch [114/150], Step [32/64], Step Loss: 0.4424\n",
            "Epoch [114/150], Step [64/64], Step Loss: 0.3579\n",
            "Epoch [114/150], Training Loss: 0.4696, Training Accuracy: 90.25%\n",
            "Epoch [114/150], Validation Loss: 1.5857, Validation Accuracy: 60.39%\n",
            "--------- Epoch 115 ----------\n",
            "Epoch [115/150], Step [32/64], Step Loss: 0.4165\n",
            "Epoch [115/150], Step [64/64], Step Loss: 0.5831\n",
            "Epoch [115/150], Training Loss: 0.4900, Training Accuracy: 89.02%\n",
            "Epoch [115/150], Validation Loss: 1.5846, Validation Accuracy: 61.47%\n",
            "--------- Epoch 116 ----------\n",
            "Epoch [116/150], Step [32/64], Step Loss: 0.6860\n",
            "Epoch [116/150], Step [64/64], Step Loss: 0.1485\n",
            "Epoch [116/150], Training Loss: 0.4781, Training Accuracy: 90.00%\n",
            "Epoch [116/150], Validation Loss: 1.5766, Validation Accuracy: 61.08%\n",
            "--------- Epoch 117 ----------\n",
            "Epoch [117/150], Step [32/64], Step Loss: 0.7833\n",
            "Epoch [117/150], Step [64/64], Step Loss: 0.5258\n",
            "Epoch [117/150], Training Loss: 0.4598, Training Accuracy: 91.08%\n",
            "Epoch [117/150], Validation Loss: 1.5875, Validation Accuracy: 61.47%\n",
            "--------- Epoch 118 ----------\n",
            "Epoch [118/150], Step [32/64], Step Loss: 0.4034\n",
            "Epoch [118/150], Step [64/64], Step Loss: 0.6721\n",
            "Epoch [118/150], Training Loss: 0.4952, Training Accuracy: 89.12%\n",
            "Epoch [118/150], Validation Loss: 1.6037, Validation Accuracy: 60.88%\n",
            "--------- Epoch 119 ----------\n",
            "Epoch [119/150], Step [32/64], Step Loss: 0.1997\n",
            "Epoch [119/150], Step [64/64], Step Loss: 0.5977\n",
            "Epoch [119/150], Training Loss: 0.4747, Training Accuracy: 90.15%\n",
            "Epoch [119/150], Validation Loss: 1.5687, Validation Accuracy: 61.86%\n",
            "  **Better model found. Updated best model.\n",
            "--------- Epoch 120 ----------\n",
            "Epoch [120/150], Step [32/64], Step Loss: 0.6731\n",
            "Epoch [120/150], Step [64/64], Step Loss: 0.4419\n",
            "Epoch [120/150], Training Loss: 0.4784, Training Accuracy: 89.46%\n",
            "Epoch [120/150], Validation Loss: 1.5981, Validation Accuracy: 61.08%\n",
            "--------- Epoch 121 ----------\n",
            "Epoch [121/150], Step [32/64], Step Loss: 0.4472\n",
            "Epoch [121/150], Step [64/64], Step Loss: 0.9669\n",
            "Epoch [121/150], Training Loss: 0.4876, Training Accuracy: 89.36%\n",
            "Epoch [121/150], Validation Loss: 1.5951, Validation Accuracy: 61.27%\n",
            "--------- Epoch 122 ----------\n",
            "Epoch [122/150], Step [32/64], Step Loss: 0.5990\n",
            "Epoch [122/150], Step [64/64], Step Loss: 0.6072\n",
            "Epoch [122/150], Training Loss: 0.4603, Training Accuracy: 90.25%\n",
            "Epoch [122/150], Validation Loss: 1.5805, Validation Accuracy: 61.37%\n",
            "--------- Epoch 123 ----------\n",
            "Epoch [123/150], Step [32/64], Step Loss: 0.3387\n",
            "Epoch [123/150], Step [64/64], Step Loss: 0.7992\n",
            "Epoch [123/150], Training Loss: 0.4576, Training Accuracy: 90.39%\n",
            "Epoch [123/150], Validation Loss: 1.5923, Validation Accuracy: 60.69%\n",
            "--------- Epoch 124 ----------\n",
            "Epoch [124/150], Step [32/64], Step Loss: 0.5187\n",
            "Epoch [124/150], Step [64/64], Step Loss: 0.3959\n",
            "Epoch [124/150], Training Loss: 0.4766, Training Accuracy: 90.05%\n",
            "Epoch [124/150], Validation Loss: 1.5943, Validation Accuracy: 60.88%\n",
            "--------- Epoch 125 ----------\n",
            "Epoch [125/150], Step [32/64], Step Loss: 0.3969\n",
            "Epoch [125/150], Step [64/64], Step Loss: 0.4991\n",
            "Epoch [125/150], Training Loss: 0.4790, Training Accuracy: 89.66%\n",
            "Epoch [125/150], Validation Loss: 1.5870, Validation Accuracy: 60.98%\n",
            "--------- Epoch 126 ----------\n",
            "Epoch [126/150], Step [32/64], Step Loss: 0.3804\n",
            "Epoch [126/150], Step [64/64], Step Loss: 0.5813\n",
            "Epoch [126/150], Training Loss: 0.4435, Training Accuracy: 90.98%\n",
            "Epoch [126/150], Validation Loss: 1.6012, Validation Accuracy: 61.08%\n",
            "--------- Epoch 127 ----------\n",
            "Epoch [127/150], Step [32/64], Step Loss: 0.3463\n",
            "Epoch [127/150], Step [64/64], Step Loss: 0.2520\n",
            "Epoch [127/150], Training Loss: 0.4671, Training Accuracy: 89.71%\n",
            "Epoch [127/150], Validation Loss: 1.5875, Validation Accuracy: 60.78%\n",
            "--------- Epoch 128 ----------\n",
            "Epoch [128/150], Step [32/64], Step Loss: 0.4385\n",
            "Epoch [128/150], Step [64/64], Step Loss: 0.5460\n",
            "Epoch [128/150], Training Loss: 0.4784, Training Accuracy: 90.15%\n",
            "Epoch [128/150], Validation Loss: 1.5956, Validation Accuracy: 60.98%\n",
            "--------- Epoch 129 ----------\n",
            "Epoch [129/150], Step [32/64], Step Loss: 0.4168\n",
            "Epoch [129/150], Step [64/64], Step Loss: 0.3980\n",
            "Epoch [129/150], Training Loss: 0.4691, Training Accuracy: 90.00%\n",
            "Epoch [129/150], Validation Loss: 1.5870, Validation Accuracy: 60.78%\n",
            "--------- Epoch 130 ----------\n",
            "Epoch [130/150], Step [32/64], Step Loss: 0.4888\n",
            "Epoch [130/150], Step [64/64], Step Loss: 0.3701\n",
            "Epoch [130/150], Training Loss: 0.4514, Training Accuracy: 90.20%\n",
            "Epoch [130/150], Validation Loss: 1.6031, Validation Accuracy: 61.47%\n",
            "Epoch 00130: reducing learning rate of group 0 to 1.0000e-07.\n",
            "--------- Epoch 131 ----------\n",
            "Epoch [131/150], Step [32/64], Step Loss: 0.3598\n",
            "Epoch [131/150], Step [64/64], Step Loss: 0.1828\n",
            "Epoch [131/150], Training Loss: 0.4828, Training Accuracy: 89.17%\n",
            "Epoch [131/150], Validation Loss: 1.5747, Validation Accuracy: 61.67%\n",
            "--------- Epoch 132 ----------\n",
            "Epoch [132/150], Step [32/64], Step Loss: 0.3367\n",
            "Epoch [132/150], Step [64/64], Step Loss: 0.3322\n",
            "Epoch [132/150], Training Loss: 0.4741, Training Accuracy: 89.85%\n",
            "Epoch [132/150], Validation Loss: 1.5925, Validation Accuracy: 61.18%\n",
            "--------- Epoch 133 ----------\n",
            "Epoch [133/150], Step [32/64], Step Loss: 0.4547\n",
            "Epoch [133/150], Step [64/64], Step Loss: 0.4246\n",
            "Epoch [133/150], Training Loss: 0.4721, Training Accuracy: 89.66%\n",
            "Epoch [133/150], Validation Loss: 1.5854, Validation Accuracy: 61.18%\n",
            "--------- Epoch 134 ----------\n",
            "Epoch [134/150], Step [32/64], Step Loss: 0.6656\n",
            "Epoch [134/150], Step [64/64], Step Loss: 0.5448\n",
            "Epoch [134/150], Training Loss: 0.4594, Training Accuracy: 89.90%\n",
            "Epoch [134/150], Validation Loss: 1.5996, Validation Accuracy: 60.78%\n",
            "--------- Epoch 135 ----------\n",
            "Epoch [135/150], Step [32/64], Step Loss: 0.4482\n",
            "Epoch [135/150], Step [64/64], Step Loss: 0.5695\n",
            "Epoch [135/150], Training Loss: 0.4806, Training Accuracy: 89.75%\n",
            "Epoch [135/150], Validation Loss: 1.5930, Validation Accuracy: 61.37%\n",
            "--------- Epoch 136 ----------\n",
            "Epoch [136/150], Step [32/64], Step Loss: 0.5391\n",
            "Epoch [136/150], Step [64/64], Step Loss: 0.5018\n",
            "Epoch [136/150], Training Loss: 0.4630, Training Accuracy: 90.34%\n",
            "Epoch [136/150], Validation Loss: 1.5869, Validation Accuracy: 60.88%\n",
            "--------- Epoch 137 ----------\n",
            "Epoch [137/150], Step [32/64], Step Loss: 0.3944\n",
            "Epoch [137/150], Step [64/64], Step Loss: 0.4190\n",
            "Epoch [137/150], Training Loss: 0.4626, Training Accuracy: 90.15%\n",
            "Epoch [137/150], Validation Loss: 1.5980, Validation Accuracy: 61.37%\n",
            "--------- Epoch 138 ----------\n",
            "Epoch [138/150], Step [32/64], Step Loss: 0.3627\n",
            "Epoch [138/150], Step [64/64], Step Loss: 0.1752\n",
            "Epoch [138/150], Training Loss: 0.4625, Training Accuracy: 89.61%\n",
            "Epoch [138/150], Validation Loss: 1.5880, Validation Accuracy: 61.27%\n",
            "--------- Epoch 139 ----------\n",
            "Epoch [139/150], Step [32/64], Step Loss: 0.2756\n",
            "Epoch [139/150], Step [64/64], Step Loss: 0.8146\n",
            "Epoch [139/150], Training Loss: 0.4462, Training Accuracy: 89.95%\n",
            "Epoch [139/150], Validation Loss: 1.6001, Validation Accuracy: 61.27%\n",
            "--------- Epoch 140 ----------\n",
            "Epoch [140/150], Step [32/64], Step Loss: 0.5837\n",
            "Epoch [140/150], Step [64/64], Step Loss: 0.4119\n",
            "Epoch [140/150], Training Loss: 0.4784, Training Accuracy: 89.80%\n",
            "Epoch [140/150], Validation Loss: 1.5925, Validation Accuracy: 61.37%\n",
            "--------- Epoch 141 ----------\n",
            "Epoch [141/150], Step [32/64], Step Loss: 0.4161\n",
            "Epoch [141/150], Step [64/64], Step Loss: 0.1848\n",
            "Epoch [141/150], Training Loss: 0.4525, Training Accuracy: 90.29%\n",
            "Epoch [141/150], Validation Loss: 1.5774, Validation Accuracy: 61.27%\n",
            "Epoch 00141: reducing learning rate of group 0 to 1.0000e-08.\n",
            "--------- Epoch 142 ----------\n",
            "Epoch [142/150], Step [32/64], Step Loss: 0.4373\n",
            "Epoch [142/150], Step [64/64], Step Loss: 0.9581\n",
            "Epoch [142/150], Training Loss: 0.5013, Training Accuracy: 89.51%\n",
            "Epoch [142/150], Validation Loss: 1.5844, Validation Accuracy: 61.57%\n",
            "--------- Epoch 143 ----------\n",
            "Epoch [143/150], Step [32/64], Step Loss: 0.5909\n",
            "Epoch [143/150], Step [64/64], Step Loss: 0.5589\n",
            "Epoch [143/150], Training Loss: 0.4668, Training Accuracy: 90.54%\n",
            "Epoch [143/150], Validation Loss: 1.5862, Validation Accuracy: 61.67%\n",
            "--------- Epoch 144 ----------\n",
            "Epoch [144/150], Step [32/64], Step Loss: 0.4037\n",
            "Epoch [144/150], Step [64/64], Step Loss: 0.5082\n",
            "Epoch [144/150], Training Loss: 0.4599, Training Accuracy: 90.49%\n",
            "Epoch [144/150], Validation Loss: 1.5927, Validation Accuracy: 61.08%\n",
            "--------- Epoch 145 ----------\n",
            "Epoch [145/150], Step [32/64], Step Loss: 0.2961\n",
            "Epoch [145/150], Step [64/64], Step Loss: 0.2246\n",
            "Epoch [145/150], Training Loss: 0.4793, Training Accuracy: 90.25%\n",
            "Epoch [145/150], Validation Loss: 1.5851, Validation Accuracy: 61.18%\n",
            "--------- Epoch 146 ----------\n",
            "Epoch [146/150], Step [32/64], Step Loss: 0.2421\n",
            "Epoch [146/150], Step [64/64], Step Loss: 0.1850\n",
            "Epoch [146/150], Training Loss: 0.4477, Training Accuracy: 90.44%\n",
            "Epoch [146/150], Validation Loss: 1.5821, Validation Accuracy: 61.76%\n",
            "--------- Epoch 147 ----------\n",
            "Epoch [147/150], Step [32/64], Step Loss: 0.4869\n",
            "Epoch [147/150], Step [64/64], Step Loss: 0.1791\n",
            "Epoch [147/150], Training Loss: 0.4647, Training Accuracy: 89.75%\n",
            "Epoch [147/150], Validation Loss: 1.5981, Validation Accuracy: 61.18%\n",
            "--------- Epoch 148 ----------\n",
            "Epoch [148/150], Step [32/64], Step Loss: 0.4262\n",
            "Epoch [148/150], Step [64/64], Step Loss: 0.2137\n",
            "Epoch [148/150], Training Loss: 0.4369, Training Accuracy: 90.49%\n",
            "Epoch [148/150], Validation Loss: 1.5818, Validation Accuracy: 60.98%\n",
            "--------- Epoch 149 ----------\n",
            "Epoch [149/150], Step [32/64], Step Loss: 0.4168\n",
            "Epoch [149/150], Step [64/64], Step Loss: 0.4845\n",
            "Epoch [149/150], Training Loss: 0.4816, Training Accuracy: 89.12%\n",
            "Epoch [149/150], Validation Loss: 1.5914, Validation Accuracy: 60.98%\n",
            "--------- Epoch 150 ----------\n",
            "Epoch [150/150], Step [32/64], Step Loss: 0.4730\n",
            "Epoch [150/150], Step [64/64], Step Loss: 0.6120\n",
            "Epoch [150/150], Training Loss: 0.4791, Training Accuracy: 89.85%\n",
            "Epoch [150/150], Validation Loss: 1.5914, Validation Accuracy: 61.67%\n",
            "Training complete in: 01h 18m 20s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29569cc81afe4070885303dce4d147a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▂▃▅▆▆▇▇▇▇▇▇▇▇▇▇████████████████████████</td></tr><tr><td>train_loss</td><td>█▇▅▄▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▄▅▅▆▅▆▆▆▆▆▆▇▆▇████████████████████████</td></tr><tr><td>val_loss</td><td>█▆▅▄▃▃▅▃▃▂▂▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>89.85294</td></tr><tr><td>train_loss</td><td>0.47913</td></tr><tr><td>val_acc</td><td>61.66667</td></tr><tr><td>val_loss</td><td>1.59139</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">0.0001</strong> at: <a href='https://wandb.ai/fartffart/final-tests/runs/s114eadu' target=\"_blank\">https://wandb.ai/fartffart/final-tests/runs/s114eadu</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230509_124855-s114eadu/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Timer setup\n",
        "print(f\"Starting training with learning rate {LEARNING_RATE:.7f}\")\n",
        "start_time = time.time()\n",
        "\n",
        "best_acc = 0\n",
        "best_epoch = -1\n",
        "\n",
        "# Train the CNN\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f'--------- Epoch {epoch + 1} ----------')\n",
        "    cnn.train()\n",
        "    train_loss = 0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        labels = torch.eye(102)[labels]  # one hot encode\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = cnn(images)  # train\n",
        "        labels = torch.argmax(labels, dim=1)  # one hot decode\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        train_total += labels.size(0)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        if (i + 1) % 32 == 0:\n",
        "            print(f\"Epoch [{epoch + 1}/{EPOCHS}], Step [{i + 1}/{len(train_loader)}], Step Loss: {loss.item():.4f}\")\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_accuracy = 100 * train_correct / train_total\n",
        "    print(f'Epoch [{epoch + 1}/{EPOCHS}], Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%')\n",
        "\n",
        "    # Evaluate model after each training epoch\n",
        "    cnn.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = cnn(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_accuracy = 100 * correct / total\n",
        "    print(f'Epoch [{epoch + 1}/{EPOCHS}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "\n",
        "    # wandb stuff, REMOVE\n",
        "    wandb.log({\"train_acc\": train_accuracy, \"train_loss\": train_loss, \"val_acc\": val_accuracy, \"val_loss\": val_loss})\n",
        "\n",
        "    # save plot data\n",
        "    val_accuracies.append(val_accuracy)\n",
        "    val_losses.append(val_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # Update the learning rate scheduler\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    if val_accuracy > best_acc:\n",
        "      best_acc = val_accuracy\n",
        "      torch.save(cnn.state_dict(), 'best-model-parameters.pt')\n",
        "      best_epoch = epoch + 1\n",
        "      print(\"  **Better model found. Updated best model.\")\n",
        "\n",
        "# End time\n",
        "end_time = time.time()\n",
        "print(\"Training complete in: \" + time.strftime(\"%Hh %Mm %Ss\", time.gmtime(end_time - start_time)))\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test model."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "i3pOHSKXJp0T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- Best Model Testing ----------\n",
            "  Epoch: 119\n",
            "  Validation accuracy: 61.86%\n"
          ]
        }
      ],
      "source": [
        "# Test the best model on the test set\n",
        "best_model = torch.load(\"best-model-parameters.pt\")\n",
        "cnn.load_state_dict(best_model)\n",
        "print(\"---------- Best Model Testing ----------\")\n",
        "print(f'  Epoch: {best_epoch}')\n",
        "print(f'  Validation accuracy: {best_acc:.2f}%')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d_NGRt-Jp0U",
        "outputId": "c9f138b9-9202-4a78-cce9-54bd3ca2c128"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 56.77%\n"
          ]
        }
      ],
      "source": [
        "# Test the CNN on the test set\n",
        "cnn.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = cnn(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_accuracy = 100 * correct / total\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}%')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVaYKS7GJp0V",
        "outputId": "79dcef50-ce28-4138-fc0d-ba289b520ace"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot training data"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "sFTuTLYZJp0V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqwAAAGwCAYAAABsPjdNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACPzklEQVR4nO3dd3xT1fsH8M9Nm+6UtnRDS6tsyp4VQQTZQ4YiQ2Wo/GQICE6G7CF+QUAUFRUclKWCisgQZMqeZaPSMtrSQjelbdrc3x8lIbtJmjZJ83n76veb3Nx77vMkoXl6cu45giiKIoiIiIiI7JTE1gEQERERERnDgpWIiIiI7BoLViIiIiKyayxYiYiIiMiusWAlIiIiIrvGgpWIiIiI7BoLViIiIiKya662DqC8KRQKJCUlQSaTQRAEW4dDREREJhBFETk5OQgPD4dEwv41Z1fpC9akpCRERETYOgwiIiKywM2bN1G9enVbh0E2VukLVplMBqDkDe/r62u1duVyOXbu3IkuXbpAKpVarV175mw5O1u+AHN2hpydLV/A+XKuLPlmZ2cjIiJC9TlOzq3SF6zKYQC+vr5WL1i9vLzg6+vr0L8QzOFsOTtbvgBzdoacnS1fwPlyrmz5cjgfAbzoioiIiIjsHAtWIiIiIrJrLFiJiGwsLaMIp6/kIy2jyNah2L2Kfq742hDZh0o/hpWIqLykZRThVmoRqge7Isjfsl+n2w7lYnFcOkQRkAjApCEB6NHWx8qRWod6vgD05m6N58SQbYdysSQuHQorPVelxWrt81kzNqPHZhbj5j0fpGUWIzzo0RjWsrx+5fm6EpmC7zoisglH+gDUF+vvh3KwJC6jTIVmWkaRqlgFAIUILFmXjpb1PRDk71ouBaJ6MSN1FUw+Vr14U14CI6Ik99f6+qF2pBuu3ijAqi1Zegu8shZL5/8tMPpcmfpcKPfRjlWZg/JYfa/N4rh0eHoIiHnMXSMHQ7fNLQSVx5YWm2nH1sKWk6mq18CS18/c19Xe/x2TY+O7i4gqXHn1XFnzw9NYYRPoJ8HitRmqfY0VmsbiSEyRqwoiVVsKYO+pPCgUIr7ckgXRggLDUGGjXsxsPpGqt019RVdaRpHq9VIeo577F5szdXJTf06OX8zXKP4EPee9nFiAr355mK8ATNZTaOmcQwHcTitCkL8rft2fg2UbHv0BoZ6PvKikSP92WzbW7bgP7abUc1Ae+8+tQp3XRhSBOV/f04lDmY86cwtB9de4tNjMOXZxXDrkxQos35CpysfU18+U19VWPdDkfFiwElG50i7etIsffT1lltAugg0Vb9oxKYsZ9R5H9eJJnaEPcUCz0DRURAKaheCZawV621r5k+Y5zC0wtAsbZeFrSpv6imOJAL0FY2kUCmDrwVz8sD1b4/zKm4ZyEUXgf2t1Cy190jKK8OWWDKzfmaM3H2VOImoBuF96zEZeY0P0hWduIWjK02vJsaIILFuve0xZKBTAbwdysHZHjtEebyJr4ruKiEplzteZpX21KYqiTvGj3lNm7lfHAPR+XayveKse7KrRK/RILfz8sMexLLQLTUMFhiAAg7vIsGl3juq+saLMXJYUXUqmFMfm+P6PbIuPNaXQWvBteqn7WPGppYd+2J6js0393zGRtfFdRURGaV8UVNpXkqZ8talNEIBqQa5mj7MD9H8da+p5bUUUgbgdjz7wX3u2ClxcBJ2C114p53G3ZpFtzrmnj6wKX28J3lqeViHnfLm7L77X6iV2ZOX1+kkkJf+OicoD31lEZJC+C09K+0rSks9AqSvwd3ye2ePsLD2ftQgC8GI33zL1IgLAV79mYcVbIQa/ei+PAkN4+D/mtjlmgB+eauYFoKQ37UpiAVb9kgWFoqRgee1ZP0gkur3NqvOWIReJBJg0OAAdmnvj9JV88xvQauu1Z/1Qp4abRg769uv5pA+CA1yxZF06FArNHAzdNpf6sabGZujYkb1kuJ14DtvPRWvEoiz2Gzy8aMzQ66d9XlNeV+Vrw95VKi98ZxGRXmkZRdj4Z/n2Kv1fvyr4aU8u7mYVW32cnbUY+xCfNDgALet7YO32bIvGeCopFEB+oYhJQwJURZH6eZW9VqYWGMZyGdlLhozkU+jXqy2krq46bRoruiQS4KlmXqqiJMjfFU1qe6BjC2/cTitCtaBH45S/+DlT4zkxtVgKCXDBnG/uGSy0lOeuHuyqU+Ar97uTXqQ3H2VPvfI5VbalnoO+1zjI3xU92vqgZX0PVZ7KHAzdNqcQ1H6NTY3N0LF+PiK2bctE3XpVsGyjZi4dmnurni9Dr5/2eU19XVmsUnniu4uIdGw/nIelG3Qv1LEmiQRoXMsDX27Jslqb+goWffsIKCl0NHrHAFWPo3YxYOxDHIDBQtOcQrBaUEnxoF4UaRcAphYYxgqbkmImF0F+LpBKXfW2Cegvugz1oAX5a8Ya5O+q85yYUyzl5YtGjzXlHOrtyouKsHnrIfTr1RbhQR66L4BaDoZiMpSnodvmFILacVgSm/qxcrkcANAt1gttGhre31BexvIt7XUlKi8sWIlIQ06+FKvNLFYNfS1aWu/kgwLR4HlM+XpV+1z6ChZDvaL6ihllj6O5H+7avW+GihOg9ELQUPFQWgzq240VNspiprQ2TSmQjDH0nJiSi6nHGttPvV25XET1gJIi3RSmvAZlaacs7Zt7rLVyUTL1tSGyNr7TiEglLbMYx/8N0Vskjhngh2KFaNJXkuq3S/uK0dDXuqaMszN0LqD04k1fMaPscbSEOb1UZSkEyxpPRbZTEcdauyCj0vE5J1vgO47IQZmzqo8p+1xJLLn6XkSQzj7qYxdN/TqzIr46NnYuY+e1B/YYExGRveJvS6IyqsilCdVXLFJOBm9oknxTVpMytoqQkiVfWZujLF8dExGRc+Bvf3Ia5VFYWnOJUVMm4de3YpH2JPmThpSM0dReTUp9HXTl1/HqU1bpo5zCqLwLRRajRERkDD8hyCmYWliqF41+PoYfUxV8a9M1lpm0dGlCQxPmG5qE3xBlYTqos49Or6lyHXRlj2yBXGG0WNWewoiIiMhW+ElElV5pa9erf82uvozohBeqqNrQt079mav5uqs5mbnEqDI+9Z7Osk7CL4rAup25Bh83ZeUnicBJwImIyH7w04gqvVupRXrXrt97Kg8KhWjwa/al67PQrZEfHkssNGm1J6CkRzQjpxgbdmVptKtcPlTfeNNbqUV2seSj9qTyhuarJCIiqmgsWMlhGRqTqt2zmZ5dpPf40tZtFwH8cS4af5y7Z3JMIkq+dte3HdA/3rTYgiWSzFnhyJR10JVjVdUnlSciIrIXNi1Yi4uLMXPmTPzwww9ISUlBeHg4hg8fjmnTpkF4OCO4KIqYMWMGVq1ahczMTLRt2xYrV65ErVq1bBk62di2Q7mqXk/1MamGxoKWt15PemHrwTyzjlGIwOK16fAsmW5U1QtryiT8+uY3vfBfgc6SlvrWQdemPlbV0KTyREREtmTTgvXDDz/EypUr8e2336JBgwY4ceIERowYgSpVqmD8+PEAgEWLFmH58uX49ttvER0djenTp6Nr1664ePEiPDz4laUzUo5JVf+KfvHadMiLFVi+IVPvWFCll7r74vs/si06ryAYXlazaR1PswtWoCTGvIKS2yP7VEGDx9xNmoRfW5C/Kzo0d9W7pGWQv+Y66KYut0lERGQvbPop9ffff+PZZ59Fz549AQBRUVFYt24djh07BqCkd3Xp0qWYNm0ann32WQDAd999h5CQEGzZsgWDBg3SabOgoAAFBQWq+9nZJcWJXC63au+Rsi1n6pEq75zTMosfFWZGvpJOSC7QvQIewLL1maWeIyJEorOykpJEAEb2liE4wAULvs3U7KkUgI/frIqCQhFXb8jxzW85jy7OGlgFdSJdDLarvka9Mat/y8J3M4Ph51Oyo5+PC5Rlt/J2ac9951buaFI7GElpRQh/+Dwqj/HzKWmnQbQX2jVx17sP39eVn7PlCzhfzpUlX0ePn6xLEEXbXe4xf/58fPnll9i5cydq166Ns2fPokuXLliyZAmGDh2K//77D48//jhOnz6NJk2aqI576qmn0KRJEyxbtkynzZkzZ2LWrFk62+Pi4uDl5VWe6VAZnL8VgD0XIiFCgAARHRvcQEz1dL37Zua54dsD9fHoS3/TCBAx4qkLSLwr0zjXE7VvI7TKA1TxKoDMQ25SPDn5UmTluRs9Rr1dAMjKc8edLC8cuhoO0UDsA1peQ/UAw1f4ExE5i7y8PAwZMgRZWVnw9fW1dThkYzYtWBUKBaZMmYJFixbBxcUFxcXFmDdvHt5//30AJT2wbdu2RVJSEsLCwlTHDRw4EIIgYMOGDTpt6uthjYiIwN27d636hpfL5di1axc6d+4MqVRqtXbtWVlyNtR7mpZZjAvXC7FQT4/mdzODEeTnonEsAKzbkYPf/35Q6jnVezaV01R1i/VSnVe9h1Gf5LR8/LbjGHp3bYUwE6+YN6XdtMxiXLxeqLcXV5mzrfB9XflzdrZ8AefLubLkm52djcDAQBasBMDGQwI2btyItWvXIi4uDg0aNMCZM2cwceJEhIeHY9iwYRa16e7uDnd3d53tUqm0XP7hlle79szcnNUvkBIEYNTDaZ0MrdwElHy1fuhcIRQKUTU3qvZFVE819cRTzbx0LjQSBGD6yKpo8FjJ+0Df+M/wICnCg4zHHRYEVA/IRViQh8n5mtJuyT4eKJRLdMab2stUUnxfV37Oli/gfDk7er6OHDtZn00L1rfffhvvvfeeaixqw4YNkZiYiAULFmDYsGEIDQ0FANy5c0ejh/XOnTsaQwTIfulMim/CpPVK2tNOade1B84+wJjn/DF5SIBO4dehubdqP3u9oEj9QihjF1QRERE5O5t+Qubl5UEikWhsc3FxgeLh3DvR0dEIDQ3F7t27VQVqdnY2jh49itGjR1d0uGSBG3fk5TYpvnJVKUcu/IL8HSteIiIiW7DpJ2Xv3r0xb948REZGokGDBjh9+jSWLFmCkSNHAgAEQcDEiRMxd+5c1KpVSzWtVXh4OPr27WvL0MkEaRlF2HnE9AuIBAF4sZvp005JJFCNa2XhR0REVHnZ9BP+k08+wfTp0zFmzBikpqYiPDwc//d//4cPPvhAtc8777yD+/fvY9SoUcjMzMSTTz6J7du3cw5WO6c+btUUyq/yW9b3wNrt2fqnh9KaRJ/zhxIRETkHm37ay2QyLF26FEuXLjW4jyAImD17NmbPnl1xgZHF0jKKcP7fAp1iVXkh1J30Io1J6/Wt3DRJa0yq+j5A6ZPoExERUeXCT3wqs7SMItxKLcLVGwWqK/q1iSLgJ3NBh+be6NjC22jRWdqYVBaqREREzoWf/FQm2w7lYklcut4iVZ254005JpWIiIiUJKXvQqRfWkaRycUqx5sSERGRpVhBkMVupRYZLVbVJ/BnsUpERESWYhVBFpMY6Z/XN4E/ERERkSVYsJLJ0jKLcfOeD9IyiyERgKXr0jUeN3TVPxEREVFZsKIgkzy6uKoWfj6RqvHYkK4ytKjnySKViIiIygUvuqJSlXZx1fpdOSxWiYiIqNywYKVSlXZxlUJRMpk/ERERUXlgwUqlqh5svOdUfY5VIiIiImtjwUo60jKKcPpKPtIySnpN72YWazwuoGTKKoBzrBIREVH5K1OVIZfLcfXqVRQXF6NOnTpwd3e3VlxkI9sO5WJxXDpEEZAIwKQhATh64QEAoF0TDwRL49GvV1tIXV2NLq9KREREZC0WVxoHDhzAoEGDIJfLUVRUBFdXV3z33Xfo1q2bNeOjCpSWUaQqVgFAIQKL16ZDOXz1xW4+uHg6F0F+LpBKWagSERFRxTB5SIBCodC4P3HiRKxduxapqalIT0/H3LlzMXr0aKsHSBXn4vVCVbGqpH73coK8QuMhIiIiAswoWFu3bo1Tp06p7hcWFiIyMlJ1PzIyEvn5+daNjipMyl051mzNNLrPsg1ZyMmXVkxARERERA+Z/J3uihUr8Oqrr+Kpp57C3LlzMWPGDDRv3hx16tSBXC7H5cuX8cknn5RnrFROth3Kxf/WPlq1ShCg09MKlAwRyMrjOGUiIiKqWGb1sB4/fhzBwcFo3rw53NzccOXKFUydOhXTp0/H1atXMXLkyPKMlcqBctyqtomD/FQzAShJBKCKV0EFRUZERERUwqxprVxcXPD+++/j999/xyeffILRo0ejefPm6Nu3L6pVq1ZeMVI5Scsowrqd2brjVkUgMtQNk4cEQPLwHSKRABNeqAKZB8exEhERUcUy6zLvCxcu4PLly2jYsCF27dqFb7/9Fu3atcPkyZMxZsyY8oqRrCgtowi3Uotw9UYBvtySpferf+VCAE1qe6BlfQ/V9FV+PiK2bav4mImIiMi5mdzDumTJErRs2RIfffQRYmNjsWrVKgwbNgxHjx7FkSNHEBsbi/j4+PKMlcpo26FcDJqWhMnLUvHFZsPFqvpCAEH+JYUrp7AiIiIiWzG5Clm0aBF+//13PP3000hMTES3bt3w2muvITAwEN999x127dqFgQMH4tKlS+UZL1lIe45VfcYM8MNTzbxYnBIREZFdMbmHVRRFSB4OaHRxcYGoVfl07twZp0+ftm50ZDW3UouMFqsSCVisksNLzknG4RuHkZyTbNL2ijg3VRx7ew3sIR71GEyJx9yY7SFHcg4mVydvv/02evTogcaNG+Pq1auYP3++zj4eHh5WDY6sJ9DP8N8m2sMAiCyRnJOMhIwERPlHAYDe22GyMLPaMWV/pY3xGzF151QoRAUkggTzuszDwIYDDW63Ju1zvNP+HcSExBjN39I8TWVu++W9v6FjgdKfH/V9DO2/4dwGTNs1Te9rUCQvwrW8a0jJSYGr1LXUuM2NT9/283fOY9H+RVZ5T5jyXKjfVub79cmvsfjQYihEBQSUTPsiQjQYj6kxG9q/PP5tESmZXKG89dZb6Nq1q+qiq7p161olgNu3b+Pdd9/FH3/8gby8PNSsWROrV69GixYtAJT07M6YMQOrVq1CZmYm2rZti5UrV6JWrVpWOb+zOHutUOO+RAK89qwf6tRwQ7UgLrNKllF+kJ5LOYeP9n8E8eHaaAIEiBCNfkia8iGv/gForEBKzklWFYwAoBAVmLJjCgqLCjFrzyyN7VN3TkWdwDrIk+fpFDMRAREm56z84D55+ySm7Jiiyl0hKrBw30LV86Avf3MLA3NvG2tfX/FmzUKltGJPvbg35fnRfj+pv8fmdZmH9tHt8dP5n/DxoY9Vr5Gh12DlNytV+5hStJn7+h25cQSfHvlUFWNp8agfey75HD468JHO9jPJZ7D4wGKdf1vat9Wptt9+tE19P0PxmBKzsf2n7pyKdlHtyuUPMCJB1P5uvwJlZGSgadOmePrppzF69GgEBQXh2rVrePzxx/H4448DAD788EMsWLAA3377LaKjozF9+nTEx8fj4sWLJvXoZmdno0qVKsjKyoKvr6/VYpfL5di2bRt69OgBqdS+V38SRRGvzU/Bf7fleLGbL5rV9bCoSHWknK3B2fIFNHO+m3/X5MLDXMaKE3UCBCzrtQxJOUn4cN+Hqg9z7Z6cwzcO48WNL1qUs/LD3dxCzdAHd1kYKgxMKRhMjceUgsdQm8YKJOXrZKzYC5OFYeLWiVZ9zsi+rB24Fm0i21ilrfL6/CbHZNNutQ8//BARERFYvXq1alt0dLTqtiiKWLp0KaZNm4Znn30WAPDdd98hJCQEW7ZswaBBgyo8Zkd08Ewe/rsth9QVeK6TDL7eLrYOiexUSk6K3q8SlQWGslhsF9XO4mIV0Oy9MUaEiPFbx+scO2XHFHhLvdGsWjMAwKVUyy/21NczCujvJdZ3nDWpt2nKbUviMaUtQ48bO7f262SoR48qL4kgQQ3/GrYOgyopmxasv/76K7p27Yrnn38e+/btQ7Vq1TBmzBi89tprAIDr168jJSUFzzzzjOqYKlWqoHXr1jh8+LDegrWgoAAFBY9WY8rOzgZQ0nMkl1tv0ntlW9ZsszxsP5yHj9dnAQDkRcC+k7noFutlUVuOkrO1OFu+P57/ER/s+aCkCDXyVeLUnVOxuNtii4tVa9BXIJmitB5F7XOo/z+RIyuPbwTUSQQJZnecjUCPQKv9znSW371kGpsOCVB+pT9p0iQ8//zzOH78OCZMmIDPP/8cw4YNw99//422bdsiKSkJYWGPxsQMHDgQgiBgw4YNOm3OnDkTs2bN0tkeFxcHLy/LCjVHlZMvxep9DSDi0RqrAkSMeOoCV6wiDZnyTMxJmGPyh1k9z3q49MBwr6Y5Xztb24DAAfj57s8653w55GUESAOw7Naycovn5ZCXkVGUga33ttosf0djyvNjzvuptNfA3NfD0tdPgICeVXsi0iMSN/NvWu09YSgXfbfVYwiUBgIA7srvGozH1JgNte8n9bMoJ0Py8vIwZMgQDgkgADYuWN3c3NCiRQv8/fffqm3jx4/H8ePHcfjwYYsKVn09rBEREbh7967Vx7Du2rULnTt3ttvxjWeuFeDdFek62xeNC0DjWu5mt+cIOVuTM+V75OYRDP95uMXHSwQJJj8xGTGhMahRpeQrwcSsRI3b5++cVw0zKK2dcN9wTN4+2aJe3G8HfIubmTdVvcXKnp/nYp4DoNmTXJZeJ+0xmurnSMlJMZq/+vOlvt3cMayGbpvbvqX7G3udjD23AgQs6b4ETcOalvr8GHo/1ahSAwcTDxp8ndVfA3mRHJt3b0a/Tv0gdZXqnM/Qc2Hu66d9bKgsVJWzpe8JU58L9dvq+Ub467+QUF88psRsbH9ry87ORmBgIAtWAmBBwRoVFYWRI0di+PDhiIyMLNPJa9Sogc6dO+Orr75SbVu5ciXmzp2L27dv47///sPjjz+O06dPo0mTJqp9nnrqKTRp0gTLli0r9RzOfNFVWkYRXpiapLFNIgHWzQm3aFYAR8jZmpwp3+ScZLT7op3B4gIwXHgs670MzcKbmTwVUmJGIuLvxOtcZd0wpCFq+NfQe1GXcp9wWTgm/j7RYCErESTYP2o/wmRhqnOpt6kdRw3/GiiSF2Hjjo3wjvY2qVBTjxWAwXMYy197f/Xt6m2W5bah9pX5Duw6EK5SV4vjMfY6aT8/2q+3oemPjL1m5j6n6gz9WzaUp7Hprkp7viyZ4svabVaW31286IrUmV21TJw4EWvWrMHs2bPx9NNP45VXXkG/fv3g7m5+j13btm1x5coVjW1Xr15FjRolvzyio6MRGhqK3bt3qwrW7OxsHD16FKNHjzb7fM4m0M8F3h4C7uc/vGCG862SAWGyMDxZ40kcSDwAAHoLj21XtmH+Xs35l0WIqOpZ1eQP1DBZGMJkYWgT2Qa96vYy+oE8sOFAtItqp7PPffl9g9MizesyT7Wf8lzG4gBKPtxretVEj+Y98GyDZ80qBJVtmcpQTNrbrXVbX/vKfENloZBKpWWKBzD8Oqnvb8rrre+8prDkGEPHltaOqa9fWWKwRptElZFFBevEiRNx6tQprFmzBm+88QbGjBmDIUOGYOTIkWjWrJnJbb355pt44oknMH/+fAwcOBDHjh3Dl19+iS+//BIAIAgCJk6ciLlz56JWrVqqaa3Cw8PRt29fc0N3OgnJctzPF+HmCsx5PQhRYVIWq2RQbmEuAKCTfydM7zddZ07SHnV6YOG+hRq9m2W5KtiUD2R9+2gXSIB5vZzmnM+cYsaZWfpaEhGZyuSlWbU1a9YMy5cvR1JSEmbMmIGvvvoKLVu2RJMmTfDNN9/oLN2qT8uWLbF582asW7cOMTExmDNnDpYuXYqhQ4eq9nnnnXfwxhtvYNSoUWjZsiVyc3Oxfft2rqplglOX8wEAjWp5oGV9TxardsheljV8IH+A+DvxAIA2VdroHZcWJgvDvC7zIBFKfm1o92hWJGWvnXqPLYshIqLKy+IKRi6XY/PmzVi9ejV27dqFNm3a4JVXXsGtW7cwZcoU/Pnnn4iLiyu1nV69eqFXr14GHxcEAbNnz8bs2bMtDdVpnXxYsDary+LeHm04twFTd07V+DrbVssank0+iyJFEUJ8QhDgGmBwv9K+/iUiIioPZhesp06dwurVq7Fu3TpIJBK8/PLL+PjjjzWWau3Xrx9atmxp1UDJPEXFIs5eK5ktoTkLVrujXEpUfdJ6Wy5rePz2cQBA8/DmEETB6L78apeIiCqa2QVry5Yt0blzZ6xcuRJ9+/bVewVidHQ0V6GyscsJhXhQIMLXW4LHqznuVaKVVUJGgs5V9wpRgcSMRJsUgydunQBQUrCqLxpARERkD8wuWP/77z/VVfyGeHt7ayy3ShVPORygaR0PSCTGe8zIfMk5yap15i0pMH3ddadoMXQBk/q5AJTpvPraDPIOwumk0wCAFuEt8O/tfy1ul4iIqDyYXbCmpqYiJSUFrVu31th+9OhRuLi4oEWLFlYLjsyTllGEW6lFqB7siqPnHwAAake62Tgqx5WSk4JredeQkpOiccW89ryTlow9PXn7pM62yCqRuJ5+HcCjK9LVz6VvCqfSzquvsNaOf3Tr0bgvvw+Zuwy1AmvhX7BgJSIi+2L2LAFjx47FzZs3dbbfvn0bY8eOtUpQZLq0jCKcvpKPuO1ZGDQtCZOXpeKFqUm4nFgIAPjql0xsO5Rr4ygdz8b4jei4uiNW3l6Jjqs7YmP8RgCPxp4qp3ZSjj019yr/3y7/BgAYHzsei3sshovggoTMBLy06SW0/7I9Vh1fha2XtmLKjimqc4kP/9N3Xn2zDWyM34j2X7bHixtfRPsv22Nj/Ea98X965FMAQIPgBqoZAIiIiOyJ2T2sFy9e1DvXatOmTXHx4kWrBEWm2XYoF0vi0qEwMoOYKAJL1qWjZX0PTmtlgHYvpKGitF1UOyRkJOissmTK2FP1cxQrinEq6RQECBjUeBAUokKjTYWowMJ9C0uNW3ne/df368w20C6qnU4OU3ZMwcgWIw2uEnX05lH8eP5HeMGr1HMTERFVJLMrGHd3d9y5cwePPfaYxvbk5GS4urIgqihpGUWlFqtKCgVwO63I7gvWso4LtYS+r/cjqkQYLEqV40jVlTZ5vvY52tVoBwBoEtYEIT4hOHzjsEVr2UsECTylnnpnG1jac6lODiJEfH3ia4PtiRDxwZ4PMK3GNLNjISIiKk9mf//XpUsXvP/++8jKylJty8zMxJQpU9C5c2erBkeG3UotMqlYBUqWZK0WZN/Fqr6vr61N/Wvz5JxkbL28FVN2TtHpSfWSeqnGiyopi9IQnxC4uWiOCx7WbBgSMhL0DgvQ11u7L2EfAOBM8hlsjN+IKP8ok76KFx7+pzQudhzu5d3TO9uAvFhuwjOiSyEqcFd+16JjiYiIyovZVcz//vc/tG/fHjVq1EDTpk0BAGfOnEFISAi+//57qwdI+lUPNvzSCQ9rGlEsKVYnDQ6w695VY1/Bm9rTauhKeuXt+JR4LNq/qNSeTIWowMGEg/Bw9cCDogeq7TM6zkCYLAz/3vsXhcWFcHdxR4OQBjiVdAqrT67G6pOrIREkeKf9O4gJiVH1EusbQqAkQsTUnVOxf9R+zOsyT+M5UCdAwLLey9AsvGQozuRtk3H05lFcSbuiurpfnUSQ4Nq9a6U+Z2+0eQOfHv1UZ6nVQGlgqccSERFVJLOrmGrVquHcuXNYu3Ytzp49C09PT4wYMQKDBw/WOycrlY+AKi7wcBOQX1hSgEkkwGvP+qFODTdVb+rttCJUC3K162IVgMXjQpUMXUmvftscSw4tAQBU9ayKBwUPkKfIQ63AWgCgWr60QUgDfNDxA/T9oa9GzMqxp8rhBVF+UUbPpcxTfQWp+DslxbX6MIWedXqqjnnvqffQ74d+2HFth2qbAEGVZ5B3ENacWgMAmP70dAR5B2Hi7xN1CtMXGr+A8CrhGsMVZnecDa8bHMNKRET2xaJKxtvbG6NGjbJ2LGSGywmFyC8U4eUBzB4VhIgQqU5hau+FKlDSM/r3jb91tquPCzU2tlW7d1a9OLVkXKi6jPwM1Pasjct5l3Em+QxaR7TG+TvnAQAxITHILTQ8+4Kyl/ipqKeMnkM9T+UKUm0i26BX3V4Glz8N8g7S29acZ+Zg1u5ZuJN7R7XNU+qJnnV74r78vs5Y3TBZmM5Sq4Eegdh2Y5tJzw8REVFFsbiiuXjxIm7cuIHCwkKN7X369ClzUFS6YxdKvq5uWd8Lzep62jgay6j3jGob3GgwwmRhpc55auwrd1MJEDA2dixWHF6hsV0hKuDv6g+gZLwpAMSnlPSwNgxtqBp7auj8ClGBv67/BQD47rnv4CJx0dt7qq8X2djypwkZCTrbRIio4lEFxWKxxvZpu6ahfXR7ncJUvW31c8nllo19JSIiKk8WrXTVr18/xMfHQxAEiGJJL5bwcOBkcXGxscPJSo5eKFnJqnUDDxtHYprSpo4CSgrHLjW7YMc/O3D57mW9Y1un7JgCb6k3mlVrhjBZmN6r9kujbwL+dlHt8NmRz3S+Nq/jVQeHsw/jTNIZFCuKceHOBQBAw5CGCJOFGR17qu52zm0MbDiw1N5TU+grlJUXbRlb7tVYEUxERGTPzC5YJ0yYgOjoaOzevRvR0dE4duwY7t27h8mTJ+N///tfecRIWtKzi3H1RknPdqv6lveuVtQ0Utq9pO+0fwcF8gK90y71qdcHe/7bg5O3T2LVsVV69xm/dbyqHe0r9g2NYVXu3zCkoeoreO2iUb34VI7ndE1whYvggtT7qTiUeAgPih7AS+qFxwJKpnUzNPZUm/pFZGUtHLULZWXR3axaM72FrLEpt4iIiByB2QXr4cOHsWfPHgQGBkIikUAikeDJJ5/EggULMH78eJw+rXvVMlnXiYslwwFqRUgRUMXFojassbyoKfT1khqaFF8iSNA4vDEahjbEqaRT+Pb0twbb1W6nYUhDvPfUezrFqPpt7SJR+76h8Zx1AuvgYtpF/HDmBwBA/eD6cJG4aLSjPvZ025VtmL93vk68pl5EZgpDX/HrK2TZq0pERI7O7IK1uLgYMpkMABAYGIikpCTUqVMHNWrUwJUrV6weIOnadzoPABDzuLtFx1t7Giljx1xPv27SGFNlcQUAp5PN/6PnQuoFjcJNe4ymqfSN52wc2hgX0y5iz797AJSMXzV2fI86PbBw38Jy7+nU11NrbKwqERGRozJ74YCYmBicPXsWANC6dWssWrQIhw4dwuzZs3VWvyLr23owB4fjS8avbtmXi22HDF+pboixaaSMSclJwbW8a/j65NcmTfKfnJOMXy7+Umo8UzuUzEU6sOFAJGQkqMZFq3ujzRtGJ9c3JX5LNQptBODR+NCYkBij+yu/slfGW9E9ncreXharRERUWZjdwzpt2jTcv38fADB79mz06tUL7dq1Q9WqVbFhwwarB0iPpGUU4eN1Gar7oggsWZeOlvU9zJrCSt+FSgIE3Mu7p1qtSbv3VOOK/tuPjjPUO7sxfiOm7JhS6tRSEkGC7nW6q441dEGR9pyh+topr7GajcMaa9wP9Qkt9Rj2dBIREVmP2QVr165dVbdr1qyJy5cvIz09Hf7+/qqZAqh8nPunANqdjwpFyQIB5hSsWflZOtuUFzOpT0CvvFApTBZmtPjUHp+pHHKgvr9ytaak7CSj0zoZuqBIe85QU6eHsoYovyh4uHogv6ikZ/ulTS+ZNOaXV+UTERFZh1kFq1wuh6enJ86cOYOYmEdfiwYEBFg9MNJ0I6UQqzZn6GyXSKBa2cpUa06uAQA8/djTaBPRBgv2LVA9pl5kGrtASiMGrd5NfUMORIio6lkVPev0LHVaJ1PmDLXG9FCmSs1NVRWrgGVjfomIiMhyZlU6UqkUkZGRnGu1gv1+MAeL4x4Vq4JQMhxAIgEmDQ4wq3f1YupFbL64GQAwuvVoFBYXlnJE6bR7N6P8ozR6agH9KzoZY619rCEhM0Fnm7Wv+iciIiLDzL7oaurUqZgyZQrS09PLIx7SkpZRhCVxuj2rH7xSFevmhKNHWx+T29oYvxF9vuuDIkURAOCfe/+oxoyaQyJIMPGJiZA8fPu0jWyr8XiYLAytI1tr7O/I0ytF+ek+R5zflIiIqOKYXbCuWLEC+/fvR3h4OOrUqYNmzZpp/JB1nb1WoDNyVBQBP5mLWT2r+saVTts1DQA0rmgXHv6njwABL4e8jD0j9uCNJ95Ak/AmAID9Cft19s0rLJl6a2ybsaoZABxVqCzUplf9ExEROTuzL7rq27dvOYRB+qSmyxG3Q/cCKUvGrRqbykp7zCgAvRc2ze44G143vBAqK7lKvn1Ue5xKOoUDCQcwuPFgVbsFRQW4lHoJAPBczHOVorDjVf9ERES2Y3bBOmPGjPKIAwsXLsT777+PCRMmYOnSpQCA/Px8TJ48GevXr0dBQQG6du2Kzz77DCEhIeUSgz3ZdigXi9emq/pDyzJuFdA/lZWxcaX6LmxSrvyk1C66HZb+vRR/3/gbRYoiuEpKYrqUdglyhRwBngGIqBJhXuJ2jFf9ExER2YbZQwLKw/Hjx/HFF1+gUaNGGtvffPNN/Pbbb9i0aRP27duHpKQk9O/f30ZRVpy0jCIsjkvXGQpgybhVJXcXd41xmKZ+rW1sEvqGIQ3h5+GHnIIcnEk+o9quvN04rDGnOiMiIqIyM7tglUgkcHFxMfhjrtzcXAwdOhSrVq2Cv7+/antWVha+/vprLFmyBB07dkTz5s2xevVq/P333zhy5IjZ53Ekt1KLdOZbNXfcanJOMg7fOKxaCOC3y79BISpQJ7AO1g5ca5VxpS4SF7StUXLB1boz61TnOptcshKa9oT7RERERJYwe0jA5s2bNe7L5XKcPn0a3377LWbNmmV2AGPHjkXPnj3xzDPPYO7cuartJ0+ehFwuxzPPPKPaVrduXURGRuLw4cNo06aN3vYKCgpQUFCgup+dna2KU7k2vDUo27Jmm0qBVXQn6JcIQLC/aef78fyP+GDPBxpjT386/xMA4LkGz6F5WHMA5seuL2c3iRsAYMulLfj18q+Y3XE2ziSdAQDEBMWUy/NTUcrzNbZXzLnyc7Z8AefLubLk6+jxk3UJor6F2y0QFxeHDRs24JdfSl87Xmn9+vWYN28ejh8/Dg8PD3To0AFNmjTB0qVLERcXhxEjRmgUnwDQqlUrPP300/jwww/1tjlz5ky9hXNcXBy8vLzMS8pG/r1TBVvPPAZABB7OaNqxwQ3EVC99KrFMeSbmJMzRWWVKhAgJJJgZPRM+ruYPKTD3XAAw97G58HJxjOeciIjsS15eHoYMGYKsrCz4+vraOhyyMbN7WA1p06YNRo0aZfL+N2/exIQJE7Br1y54eHhYKwy8//77mDRpkup+dnY2IiIi0KVLF6u+4eVyOXbt2oXOnTtDKpVarV0AmPZ5OoAC9GrrhfZNPREe5Iogv3CTjj2UeAhigubfIMoCMjYyFgP7WD4MQDvnIzePGDxXlF8Unuv9nMXnsgfl+RrbK+Zc+XN2tnwB58u5suSr/IaUCLBSwfrgwQMsX74c1apVM/mYkydPIjU1VWPu1uLiYuzfvx8rVqzAjh07UFhYiMzMTPj5+an2uXPnDkJDQw226+7uDnd3d53tUqm0XP7hWrvdlHtFOHG5pFf5hc5+qBZsvO3knGQkZCSoZgHYdGGTwX3/vvE3Nl/eXOaxq8qcawbVhESQ6EyXBQB1guo49C9KdeX13rFnzLnyc7Z8AefL2dHzdeTYyfrMLlj9/f01rvwWRRE5OTnw8vLCDz/8YHI7nTp1Qnx8vMa2ESNGoG7dunj33XcREREBqVSK3bt3Y8CAAQCAK1eu4MaNG4iNjTU3bIfx055siCLQ4DG3UovVDec2qBYDUE72r+zh1F4aVfnY1J1T0S6qnVWmZwqThWFel3mYunOqTtG689pObIzf6NALBhAREZF9MLtg/fjjjzUKVolEgqCgILRu3VrjKv/SyGQyxMTEaGzz9vZG1apVVdtfeeUVTJo0CQEBAfD19cUbb7yB2NhYgxdcObqtB3Pw01+5AICL1wux7VCuwSmstFeu0i5OAWBc7DisOLxCY5tysQBrzSeqnFD/1O1TGL91vGq7tYtjIiIicl5mF6zDhw8vhzD0+/jjjyGRSDBgwACNhQMqo7SMIny8LkN1XxSBJevS0bK+h96prBIyEvQWqarjIaJ21do6X9mrLxZgLWGyMAR4Behst3ZxTERERM7J7HlYV69ejU2bdMdJbtq0Cd9++22Zgtm7d69qlSsA8PDwwKeffor09HTcv38fP//8s9Hxq45M39yrCgVwO61I7/7VfI2PF5YIEjSr1gzzusxTLRhg6mIBlojyj9JYmEB5PmsXx0REROR8zC5YFyxYgMDAQJ3twcHBmD9/vlWCckae7rorQkkkQLUg/Z3gNzJvaNwXHv4HaBamAxsOxP5R+622WIAhyvGsFVEcExERkXMxe0jAjRs3EB0drbO9Ro0auHHjhp4jyBTHLuZr3JdIgFf6ueCfnOMoco3SKfx2/bMLANC7bm8MajRI1ZOZmJGIGv41NPYPk4VVSOGoHM+qLwYiIiIiS5ldsAYHB+PcuXOIiorS2H727FlUrVrVWnE5lWKFiG2HSi62Gve8Hx6r5oaTd//A9L/fhnhahESQ4J327yAmJAZR/lEI9QnFn//8CQB4tv6zaBP56CI0WxeJFVUcExERkfMwu2AdPHgwxo8fD5lMhvbt2wMA9u3bhwkTJmDQoEFWD9AZnLiUj9SMYsi8JOj1pAz38lOw4Ne3VRdVKUQFFu5bCKDkq/bRrUcjJTcF3lJvPBH5hC1DJyIiIip3Zhesc+bMQUJCAjp16gRX15LDFQoFXn75ZY5htdBPe3IAAE828YSbVMDlG5cNzgCgEBX49MinAIBW1VvB3VV3kQQiIiKiysTsgtXNzQ0bNmzA3LlzcebMGXh6eqJhw4aoUYNXg1ti459ZOHGpZPzq9sP30SDaHWcKD5t07N7rezk5PxEREVV6Fi/NWqtWLdSqVcuasTidtIwifP5zluq+KAKL4+4htcYOQAIIggBRe64rNZycn4iIiJyB2dNaDRgwAB9++KHO9kWLFuH555+3SlDO4sTlfJ1toiiguKDk4rV32r2DtQPX4r2n3tOZ41RJOTk/ERERUWVldsG6f/9+9OjRQ2d79+7dsX//fqsE5QxEUcQfD2cG0NiOYhRJbwMAPjrwEWr418BrLV/D/lH7sbzXck7OT0RERE7H7II1NzcXbm5uOtulUimys7OtEpQz+OHP2zj/XyEkAiA8XDNARDHSA5eg2PUuAM3e0zBZGHrW7cnJ+YmIiMjpmD2GtWHDhtiwYQM++OADje3r169H/fr1rRZYZfbBur04cCAaAgQUiwpk+n+BAo8rKJLeVhWrgP7eU07OT0RERM7G7IJ1+vTp6N+/P/7991907NgRALB7926sW7cOmzZtsnqAlc35m0k4cCBKtYyqAAn8MkbhduQgnWLVUO8pJ+cnIiIiZ2J2wdq7d29s2bIF8+fPx48//ghPT080atQIf/75J5566qnyiLFSOZuQDAFBGtsEuMBVXk1VsE7tMBXd63RnUUpEREQEC6e16tmzJ3r27Kmz/fz584iJiSlzUJVZjcBAiBBVPayA5oVWEkHCYpWIiIhIjdkXXWnLycnBl19+iVatWqFx48bWiKlSO/nPHQgQVCtZqV9oxYuoiIiIiHRZvHDA/v378dVXX+Hnn39GeHg4+vfvj08//dSasVVKB86WTGUVHHUWz8ZWR6OoUFT1m4LEjKG8iIqIiIhID7MK1pSUFKxZswZff/01srOzMXDgQBQUFGDLli2cIcAEeQVy3EsJhwBgQPswDGzTTPUYC1UiIiIi/UweEtC7d2/UqVMH586dw9KlS5GUlIRPPvmkPGOrdH46ch6CwgsK13T0bdHE1uEQEREROQSTe1j/+OMPjB8/HqNHj0atWrXKM6ZKa+eJVABVERyeDDfXJrYOh4iIiMghmNzDevDgQeTk5KB58+Zo3bo1VqxYgbt375Z+IAEAFAoFbiUGAwBiHvOwcTREREREjsPkgrVNmzZYtWoVkpOT8X//939Yv349wsPDoVAosGvXLuTk5JRnnA5v9Oc7IBRVBQD8tTcaszb+ZeOIiIiIiByD2dNaeXt7Y+TIkTh48CDi4+MxefJkLFy4EMHBwejTp095xOjwzt9MwtXz9VT3BUiwd28Uzt9MsmFURERERI6hTPOw1qlTB4sWLcKtW7ewbt06a8VU6Ry9eguC1lMtwAXnElJsFBERERGR4yjzwgEA4OLigr59++LXX3+1RnOVzsUbWTrbRBSjUVSoDaIhIiIicixWKVgttWDBArRs2RIymQzBwcHo27cvrly5orFPfn4+xo4di6pVq8LHxwcDBgzAnTt3bBSx+URRxLmLPiW3oXj4/8Xo0CEBMRHhtgyNiIiIyCHYtGDdt28fxo4diyNHjmDXrl2Qy+Xo0qUL7t+/r9rnzTffxG+//YZNmzZh3759SEpKQv/+/W0YtXm2HL2E4vvVoBDyMWV0Hl4dfBefvO+OGQOftnVoRERERA7B4qVZrWH79u0a99esWYPg4GCcPHkS7du3R1ZWFr7++mvExcWhY8eOAIDVq1ejXr16OHLkCNq0aWOLsM2yelsaAB9UCbmGzg172jocIiIiIodj04JVW1ZWyVjPgIAAAMDJkychl8vxzDPPqPapW7cuIiMjcfjwYb0Fa0FBAQoKClT3s7OzAQByuRxyudxqsSrb0tdmSk4KEjITsH5XNnLuxkAAkJ3SADPW7ca059pbLYaKZiznysjZ8gWYszNwtnwB58u5suTr6PGTdQmiKIq2DgIomVi/T58+yMzMxMGDBwEAcXFxGDFihEYBCgCtWrXC008/jQ8//FCnnZkzZ2LWrFk62+Pi4uDl5VU+was5knUEm1I3QVJUFdVubNCYHUBEMZ5/4iiqyTzLPQ4iIiJHlpeXhyFDhiArKwu+vr62DodszG56WMeOHYvz58+rilVLvf/++5g0aZLqfnZ2NiIiItClSxervuHlcjl27dqFzp07QyqVAijpWZ28ejJEiHAtrK53KitZxOPo8UQTq8VRkfTlXJk5W74Ac3aGnJ0tX8D5cq4s+Sq/ISUC7KRgHTduHLZu3Yr9+/ejevXqqu2hoaEoLCxEZmYm/Pz8VNvv3LmD0FD9U0K5u7vD3d1dZ7tUKi2Xf7jq7d7KvYVHHda617OJKEbTx6o59C8QoPyeS3vlbPkCzNkZOFu+gPPl7Oj5OnLsZH02nSVAFEWMGzcOmzdvxp49exAdHa3xePPmzSGVSrF7927VtitXruDGjRuIjY2t6HBLFeUfpbrtkd8IACBCfPj/nMqKiIiIyBI27WEdO3Ys4uLi8Msvv0AmkyElpWTlpypVqsDT0xNVqlTBK6+8gkmTJiEgIAC+vr544403EBsba5czBAgQVLe97pdcXNWs1WU0fzwIjaJCERPBqayIiIiIzGXTgnXlypUAgA4dOmhsX716NYYPHw4A+PjjjyGRSDBgwAAUFBSga9eu+Oyzzyo4UtOcuH0CAFDTux3k8mi4uAAzB3aGzMumHdlEREREDs2mBaspExR4eHjg008/xaeffloBEZXNiVslBWt1RV9cB9C8jgeLVSIiIqIyYjVlRcoe1uzkegCApnU8bBkOERERUaXAgtVKsvOzcTntMnwzBuNeesk8q19uycS2Q7k2joyIiIjIsbFgtZKTSSchKaoK/4zXVNtEEViyLh1pGUU2jIyIiIjIsbFgtZITt07AVV4dUJspAAAUCuB2GgtWIiIiIkuxYLWSE7dPQBTydbZLJEC1ILtYn4GIiIjIIbFgtYLEjEScST4D94IGGtslEmDS4AAE+bNgJSIiIrIUK6ky+vH8j5i+ezpEiKrFAob18EXj2h6oFuTKYpWIiIiojFhNlUGmPBNz98yFCBEuRQFwz48BADRvnIeYCD/bBkdERERUSXBIgIVSclJwJvcMFKICAOB5vx0ESFDgfhG54g0bR0dERERUebCH1QIb4zdi6s6pqmLVpSgQsuweAIAHPvtRw/8NW4ZHREREVKmwYDVTck6yRrHqk90DAXcnQ3jYWd21ZneEycJsGSIRERFRpcIhAWZKyEjQ6FkNuDtJVawCwPHjNbhQABEREZEVsYfVTFH+UZAIEihEBVzl1SHAReNx5UIBnB2AiIjIfhUXF0Mul9s6DKcmlUrh4uJS+o5gwWq2MFkY5nWZh6k7p6JIegsiFBo9rFwogIiIyL7l5ubi1q1bEEXR1qE4NUEQUL16dfj4+JS6LysrCwxsOBCx1WKxccdGZAdKcOBUyXYuFEBERGTfiouLcevWLXh5eSEoKAiCIJR+EFmdKIpIS0vDrVu3UKtWrVJ7WllZWShUFoqaXjVxJN0dQAG6tvHGyN5VWKwSERHZMblcDlEUERQUBE9PT1uH49SCgoKQkJAAuVxeasHKi67KoKBIglOXCwAAA5+RsVglIiJyEOxZtT1zXgMWrGWQkFYF8mIgIsQVUWFSW4dDREREVCmxYLVQWmYxzt0IBAC0b+LFv9SIiIiIygkLVgtsO5SLl2amIimz5Ko2iWkzMhAREVElMHz4cAiCAEEQIJVKERISgs6dO+Obb76BQqEwq601a9bAz8+vTPEkJCSo4jH0s2bNmjKdw9ZYsJopLaMIS+LSoT4Txtrt2VwsgIiIyIl069YNycnJSEhIwB9//IGnn34aEyZMQK9evVBUVLE1QUREBJKTk1U/kydPRoMGDTS2vfDCCxUak7WxYDXTrdQiKLSmbVMuFkBERETOwd3dHaGhoahWrRqaNWuGKVOm4JdffsEff/yh0Zu5ZMkSNGzYEN7e3oiIiMCYMWOQm5sLANi7dy9GjBiBrKwsVU/ozJkzAQDff/89WrRoAZlMhtDQUAwZMgSpqal6Y3FxcUFoaKjqx8fHB66urggNDUV+fj7Cw8Nx4cIFjWOWLl2KGjVqQKFQYO/evRAEAb///jsaNWoEDw8PtGnTBufPn9c45uDBg2jXrh08PT0RERGB8ePH4/79+9Z7Uo1gwWqm6sGukGgNV+ViAURERNSxY0c0btwYP//8s2qbRCLB8uXLceHCBXz77bfYs2cP3nnnHQDAE088gaVLl8LX11fVE/rWW28BKJl+a86cOTh79iy2bNmChIQEDB8+3OyYoqKi8Mwzz2D16tUa21evXo3hw4dDInlUCr799ttYvHgxjh8/jqCgIPTu3Vu1Gti///6Lbt26YcCAATh37hw2bNiAgwcPYty4cWbHZAkWrGYK8nfFpCEBqqJVInCxACIiIipRt25dJCQkqO5PnDgRTz/9NKKiotCxY0fMnTsXGzduBAC4ubmhSpUqEARBo3cUAEaOHInu3bvjscceQ5s2bbB8+XL88ccfqt5Zc7z66qtYt24dCgpKpuI8deoU4uPjMWLECI39ZsyYgc6dO6Nhw4b49ttvcefOHWzevBkAsGDBAgwdOhQTJ05ErVq18MQTT2D58uX47rvvkJ+fb8lTZRaHKFg//fRTREVFwcPDA61bt8axY8dsGk+Ptj74bmYwBrS8hu9mBqNH29KXFCMiIqLKTxRFjZmD/vzzT3Tq1AnVqlWDTCbDSy+9hHv37iEvL89oOydPnkTv3r0RGRkJmUyGp556CgBw48YNs2Pq27cvXFxcVMXnmjVrVEW0utjYWNXtgIAA1KlTB5cuXQIAnD17FmvWrIGPj4/qp2vXrlAoFLh+/brZMZnL7gvWDRs2YNKkSZgxYwZOnTqFxo0bo2vXrgbHcVSUID8XVA/IRZAfpwggIiKiEpcuXUJ0dDSAkqv3e/XqhUaNGuGnn37CyZMn8emnnwIACgsLDbZx//59dO3aFb6+vli7di2OHz+uKjaNHWeIm5sbXn75ZaxevRqFhYWIi4vDyJEjzWojNzcX//d//4czZ86ofs6ePYtr167h8ccfNzsmc9n999hLlizBa6+9puq2/vzzz/H777/jm2++wXvvvaezf0FBgarLGwCys7MBlIwFUY7DsAZlW9Zs0945W87Oli/AnJ2Bs+ULOF/OlSVfR4x/z549iI+Px5tvvgmgpJdUoVBg8eLFqrGiyuEASm5ubiguLtbYdvnyZdy7dw8LFy5EREQEAODEiRNliu3VV19FTEwMPvvsMxQVFaF///46+xw5cgSRkZEAgIyMDFy9ehX16tUDADRr1gwXL15EzZo1yxSHpey6YC0sLMTJkyfx/vvvq7ZJJBI888wzOHz4sN5jFixYgFmzZuls37lzJ7y8vKwe465du6zepr1ztpydLV+AOTsDZ8sXcL6cHT3f0r4yt7WCggKkpKSguLgYd+7cwfbt27FgwQL06tULL7/8MgCgZs2akMvl+OSTT9C7d28cOnQIn3/+uUY7UVFRyM3Nxe7du9G4cWN4eXkhMjISbm5u+OSTT/D666/j/PnzmDNnTpnirVevHtq0aYN3330XI0eOhKenp84+s2fPRtWqVRESEoKpU6ciMDAQffv2BQC8++67aNOmDcaNG4dXX30V3t7euHjxInbt2oUVK1aUKTZT2HXBevfuXRQXFyMkJERje0hICC5fvqz3mPfffx+TJk1S3c/KykJkZCRiY2Mhk8msFptcLsdff/2Fp59+GlKpcyzL6mw5O1u+AHN2hpydLV/A+XKuLPnm5OQAKBkTao+2b9+OsLAwuLq6wt/fH40bN8by5csxbNgwVW9q48aNsWTJEnz44Yd4//330b59eyxYsEBV0AIlMwW8/vrreOGFF3Dv3j3MmDEDM2fOxJo1azBlyhQsX74czZo1w//+9z/06dOnTDG/8sor+Pvvvw0OB1i4cCEmTJiAa9euoUmTJvjtt9/g5uYGAGjUqBH27duHqVOnol27dhBFEY8//njFze8q2rHbt2+LAMS///5bY/vbb78ttmrVyqQ2bt68KQLgD3/4wx/+8Ic/Dvhz8+ZNq9YWDx48EC9evCg+ePDAqu06gtmzZ4sNGzbU2f7XX3+JAMSMjIwKjcec18Kue1gDAwPh4uKCO3fuaGy/c+cOQkNDTWojPDwcN2/ehEwm07hqr6yys7MRERGBmzdvwtfX12rt2jNny9nZ8gWYszPk7Gz5As6Xc2XJVxRF5OTkIDw83NahOLzc3FwkJCRgxYoVmDt3rq3DsYhdF6xubm5o3rw5du/erRpDoVAosHv3bpMnqpVIJKhevXq5xejr6+vQvxAs4Ww5O1u+AHN2Bs6WL+B8OVeGfKtUqWLrECqFcePGYd26dejbt6/ZswPYC7suWAFg0qRJGDZsGFq0aIFWrVph6dKluH//vs5kt0RERESka82aNRrLxWrr0KGD3Y4VVrL7gvWFF15AWloaPvjgA6SkpKBJkybYvn27zoVYRERERFQ52X3BCpR0ZVfUWrWmcnd3x4wZM+Du7m7rUCqMs+XsbPkCzNkZOFu+gPPl7Gz5knMQRHvvAyYiIiKykvz8fFy/fh3R0dHw8PCwdThOzZzXwu6XZiUiIiIi58aClYiIiIjsGgtWIiIiokri9ddfx6JFi0zat0GDBgaXurc3DnHRFREREVFl5uPjo7p9//59eHl5qRY8unjxIiIjI01q5/PPPzf5nBcuXDAvSBtiDysROR1BELBlyxZbh0FEDig5JxmHbxxGck6yVdvNzc1V/bi7u+PChQuq+8piVRRFKBQKq57XUbBgJaIKNXz4cAiCoPPTrVs3W4dGRE5GFEXkFeaZ/PPD6R/Q/sv2eHHji2j/ZXv8cPoHk44ry4RMw4cPx7hx49CxY0d4eXnh33//xTfffIPatWtDJpOhUaNG2Lt3r8b+yuVX16xZg44dO2L06NHw9fVF/fr1cerUKdW+UVFROHjwoOq48ePHo1OnTpDJZOjSpQvS09NV+65atQrVq1dHaGgoVq1aBUEQcOvWLYvzMheHBBBRhevWrRtWr16tsY1zRhJRRXsgf4CGyxtadKxCVGDG7hmYsXtGqfvGj4+Hl5uXRecBgPXr12PHjh1o3LgxRFHEtWvXsHv3boSHh+Obb77BoEGDkJiYqPf36IEDB/Daa69hxYoVmDFjBt58803s27dP73k2btyInTt3onbt2ujZsyeWLVuGWbNmIT4+Hm+//Tb+/PNPNGjQAGPGjLE4F0uxh5WIKpy7uztCQ0M1fvz9/QGUfF2/cuVKdO/eHZ6ennjsscfw448/ahwfHx+Pjh07wtPTE1WrVsWoUaOQm5ursc8333yDBg0awN3dHWFhYTqLj9y9exf9+vWDl5cXatWqhV9//bV8kyYistCAAQPQvHlzuLq6QiqVokePHoiIiICLiwtee+01CIKAa9eu6T22bt26GDx4MFxcXDBkyBCcPXvW4Hmef/55NGrUCB4eHhgwYIBq359++gn9+/dHixYt4OnpiWnTppVLnsawh5WI7M706dOxcOFCLFu2DN9//z0GDRqE+Ph41KtXD/fv30fXrl0RGxuL48ePIzU1Fa+++irGjRunWit75cqVmDRpEhYuXIju3bsjKysLhw4d0jjHrFmzsGjRInz00Uf45JNPMHToUCQmJiIgIMAGGRORLXhKPRE/Pt6kfVNyUtB1TVcoxEdjSCWCBDuG70CoLLTU85RF9erVNe5v2bIFs2fPxn///QcAyMnJwb179/Qeq76UvZeXl84f96bsm5KSohGDdjwVgT2sRFThtm7dCh8fH42f+fPnqx5//vnn8eqrr6J27dqYM2cOWrRogU8++QQAEBcXh/z8fHz33XeIiYlBx44dsWLFCnz//fe4c+cOAGDu3LmYPHkyJkyYgNq1a6Nly5aYOHGiRgzDhw/H4MGDUbNmTcyfPx+5ubk4duxYhT0HRGR7giDAy83LpJ/Hqj6GeV3mQSKUlE4SQYJ5XebhsaqPlXqs8mr/ssSpVFBQgMGDB2PevHm4d+8eMjMzERwcXKZxsqUJDQ3F7du3VfcrcuyqEntYiajCPf3001i5cqXGNvWezdjYWI3HYmNjcebMGQDApUuX0LhxY3h7e6seb9u2LRQKBa5cuQJBEJCUlIROnToZjaFRo0aq297e3vD19UVqaqqlKRGRExjYcCDaRbVDYkYiavjXQJgsrMJjKCgoQGFhIYKDgwEAy5YtQ1paWrmes1+/fnjqqacwduxY1K9fX6ODoaKwh5WIKpy3tzdq1qyp8WOtr+I9PU376k0qlWrcFwTBaaeLISLThcnC0CayjU2KVQDw9fXFRx99hK5duyI0NBT37t1DzZo1y/WcjRs3xsKFC9G7d29ERUWhefPmACr2YllBLM8+ZCIiLcOHD0dmZqbBeVAFQcDo0aPx2WefqbbFxsaiadOm+Oyzz7Bq1Sq8++67uHnzpqqXddu2bejduzeSkpIQEhKC6OhoDB06VDW1i75zbN68GX379lVt8/Pzw9KlSzF8+HBrpUpEdig/Px/Xr19HdHQ0PDw8bB2OQ7py5QoaNWqE/Pz8Mg13MOe1YA8rEVW4goICpKSkaPzcvXtX9fimTZvwzTff4OrVq5gxYwaOHTumusp/6NCh8PDwwLBhw3D+/Hn89ddfeOONN/DSSy+pLhiYOXMmFi9ejOXLl+PatWs4deqUagwsERGZb+vWrcjPz0dWVhbef/999OnTp8xjc83BgpWIKtz27dsRFham8fPkk0+qHp81axbWr1+PRo0a4bvvvsO6detQv359ACVXru7YsQPp6elo2bIlnnvuOXTq1AkrVqxQHT9s2DAsXboUn332GRo0aIBevXoZnPKFiIhKt2HDBoSEhCAqKgoKhaLCOwE4JICI7Iq+r+uJiKyFQwLsB4cEEBEREVGlwYKViIiIiOwa52ElIrvCUUpERKSNPaxEREREZNdYsBIRERGRXWPBSkREROSghg8frlok5cCBA2jcuLHBfTt06IAffvjBovN0794dGzZssOhYa2DBSkRERGRjXbp0wYIFC3S2f/DBB+jfv79JbbRr1w5nz54tcyxr1qzBM888o7Htjz/+wAsvvFDmti3FgpWIiIjIRGkZRTh9JR9pGUVWbffFF19EXFyczva4uDi8+OKLVj2XI2LBSkRERE5JFEU8KFCY/LNlXw4GTUvC5GWpGDQtCVv25Zh0nCmzn/Tv3x///fcf4uPjVduOHDmCe/fuIS0tDbVr14ZMJkOjRo2wd+9evW3s3bsXNWvWVN0/fvw4GjVqBF9fX7z++utQKBSqx44ePYqWLVvC19cXNWrUUK1c9d9//+H111/H3r174ePjgwYNGgDQHE6gUCgwY8YMREREICwsDOPHj0dBQQGAkt7Zjh07YvTo0fD19UX9+vVx6tQp814YPTitFRERETml/EIRPd+8ZdGxoggs35CB5RsySt3394+rw9NdMLqPj48Pnn32WcTFxamGBvzwww94/vnnERERgd27dyM8PBzffPMNBg0ahMTERLi7uxtsr7CwEP3798eUKVPw6quv4vPPP8dXX32FUaNGAQCkUim++OILNGnSBKdOnUKnTp3w5JNPomnTpvj888/xww8/4M8//9Tb9tdff40ff/wRhw8fhqenJ/r06YMFCxZg5syZAErG0r722mtYsWIFZsyYgTfffBP79u0r9XkyptIXrAqFAklJSZDJZBAE428WIiIisg+iKCInJwfh4eGQSJzjC+EXX3wRY8aMwfz581FcXIyNGzfixx9/RPv27VX7vPbaa/jggw9w7do1xMTEGGzr8OHDcHV1xejRowEA48aNw6JFi1SPN2vWTHW7RYsW6NGjBw4dOoSmTZuWGuf69evx1ltvoXr16gBKxtmOHz9eVbDWrVsXgwcPBgAMGTIEK1asMP1JMKDSF6xJSUmIiIiwdRhERERkgZs3b6oKI2vzcBPw+8emtX03swjDZ6dA/dt9iQCs/iAUgX7GyykPN9M6zLp06YIHDx7g0KFDyM7OhpeXF9q1a4ctW7Zg9uzZ+O+//wAAOTk5uHfvntG2kpOTNZ43QRA07l+4cAETJ07EmTNnUFhYiPz8fNStW9ekOJOSkhAZGam6X6NGDSQlJanuh4SEqG57eXkhNzfXpHaNqfQFq0wmA1Dyhvf19bVau3K5HDt37kSXLl0glUqt1q49c7acnS1fgDk7Q87Oli/gfDlXlnyzs7MRERGh+hwvD4IglPpVvVJEiBsmDwnAknXpUCgAiQSYNDgAESFuVovH1dUVL7zwAuLi4pCZmYkhQ4agsLAQgwcPxs8//4wuXbrAxcUFYWFhpY6LDQsLw61bmsMd1O+PGzcO7dq1w6+//gpPT08MHjxY1WZp30iHh4fjxo0bqvs3btxAeHi4uemapdIXrMon3dfX1+oFq5eXF3x9fR36F4I5nC1nZ8sXYM7OkLOz5Qs4X86VLV97Gs7Xo60PWtb3wO20IlQLckWQv/XLqBdffBE9evTAgwcPcPz4cRQUFKCwsBDBwcEAgGXLliEtLa3UdmJjYyGXy/Hll19ixIgR+PLLL5GcnKx6PCcnB35+fvDw8MCBAwfw+++/o06dOgCA4OBg3Lp1C0VFRXB11c3xhRdewOLFi9GlSxd4enpizpw5GDRokJWeAf2cY1AIERERkRUE+buiSW2PcilWAaBVq1aoWrUq6tSpg/r168PX1xcfffQRunbtitDQUNy7d09jJgBD3Nzc8NNPP+GTTz5B1apVce7cOTzxxBOqxz/88EN8+umn8PX1xdKlS9GnTx/VYx07dkRUVBSCgoLQqFEjnbZfeeUV9OvXD61atUL9+vXRuHFjvP/++9Z5Agyo9D2s5SUtsxg37/kgLbMY4UGO/xcsERER2YcrV65o3J80aRImTZqkuj979mzV7TVr1qhud+jQAf/884/qfuvWrTWmyVLXqVMn/Pvvv3ofc3d3x/bt2zW2qU+l5eLigjlz5mDOnDk6xw4fPhzDhw9X3Y+KikJRUdnnrGXBaoFth3KxJC4dCrEWtpxMxaQhAejR1sfWYRERERFVShwSYKa0jKKHxWrJfYUILFmXbvUVL4iIiIioBAtWM91KLVIVq0oKBXA7jQUrERERUXlgwWqm6sGukGhdsCiRANWCOLqCiIjIUZiyXCqVL3NeAxasZgryd8WkIQFQn2Vj0uCAcrtakIiIiKzHxcUFQMnSpWRbytdA+ZoYwyrLAj3a+qBeDQlemZ8GQECbhp62DomIiIhM4OrqCi8vL6SlpUEqlTrNsq/2RqFQIC0tDV5eXnrnetXGgtVC1UOk8PMqQGaeB/69VYiA+ixaiYiI7J0gCAgLC8P169eRmJho63CcmkQiQWRkpEmLQ7BgLYMg2YOSgvW2HC1ZsBIRETkENzc31KpVi8MCbMzNzc3kHm4WrGUQ6PsA1+74479bfMMTERE5EolEAg8PD1uHQSbiwI0yCJI9AAD8c0tu40iIiIiIKi8WrBZKyUlBjutFAMCNO3IUyjk9BhEREVF5YMFqgY3xG9FxdUesSVuCYkkWFAogIZm9rERERETlgQWrmZJzkjF151QoRAUgAIVu/wIATv6TZuPIiIiIiConFqxmSshIKClWH5K7lxSs569n2SokIiIiokqNBauZovyjIBEePW2Fbv8AADLSZbYKiYiIiKhSY8FqpjBZGOZ1macqWpVDAm6mcF1iIiIiovLAgtUCAxsOxJ4RexAiDYHcLRGCoMD9ByIuXud8rERERETWxoLVQqGyUDTwaQCfnC4QxZIlxcYvvoNth3JtHBkRERFR5eJQBevChQshCAImTpxo61AAAOGSBgi4OwlAScEqisCSdelIyyiybWBERERElYjDFKzHjx/HF198gUaNGtk6FJUqxbUhwEVjm0IB3E5jwUpERERkLa62DsAUubm5GDp0KFatWoW5c+ca3begoAAFBQWq+9nZ2QAAuVwOudx6k/vL5XIEywBAAfW6XyIAwf6w6rnshTKnypibPs6WL8CcnYGz5Qs4X86VJV9Hj5+sSxAd4NL2YcOGISAgAB9//DE6dOiAJk2aYOnSpXr3nTlzJmbNmqWzPS4uDl5eXlaP7btLCUi/0UfV0/pUvZtoEnnX6uchIiJyJnl5eRgyZAiysrLg6+tr63DIxuy+h3X9+vU4deoUjh8/btL+77//PiZNmqS6n52djYiICHTp0sWqb3i5XI5du3ZhaI8IvLdtEKonfQMUydCncxPEPO5mtfPYE2XOnTt3hlQqtXU45c7Z8gWYszPk7Gz5As6Xc2XJV/kNKRFg5wXrzZs3MWHCBOzatQseHh4mHePu7g53d3ed7VKptFz+4baObI1i17vIczsPr6JYJN5RoGldx/0FYYryei7tlbPlCzBnZ+Bs+QLOl7Oj5+vIsZP12fVFVydPnkRqaiqaNWsGV1dXuLq6Yt++fVi+fDlcXV1RXFxs6xCx//p+AID84QICu85dtmU4RERERJWOXfewdurUCfHx8RrbRowYgbp16+Ldd9+Fi4uLgSMrRqY8E3P3lFwEplyi9cx/GUjOSUaYLMyWoRERERFVGnZdsMpkMsTExGhs8/b2RtWqVXW220KaPA0KUQHg0RKt0sJo/HcvkQUrERERkZXY9ZAAexckDYJEKHkKi6RJUAgPIBHd4V4UaePIiIiIiCoPhytY9+7da3BKq4rmJ/XD7I6zS4pWQQG5238AgOzMKjaOjIiIiKjycLiC1d48F/Mc9o/ajwjfCNWwgH9vcbJjIiIiImthwWoFYbIwtIxoiUL3kguv/r1VaOOIiIiIiCoPFqxWEhMS86iH9TZ7WImIiIishQWrlTQIaQC5238QocC9rGLsP5OHtIwiW4dFRERE5PBYsFpJvaB6gKQAxS6ZAICZX97F4GlJ2HYo17aBERERETk4FqxW4u3mjWif5nAp9ldtU4jAknXp7GklIiIiKgMWrFYU5dkaAgSNbQoFcDuNBSsRERGRpViwWlGjqGCIUGhsk0iAakF2vaAYERERkV1jwWpFLaNrIj1wKUSIAACJAEwaHIAgfxasRERERJZiwWpFDUIaINf3NxS4XwAADOwqQY+2PjaOioiIiMixsWC1Ipm7DAGeAcj3PAUA+PrgDmyM32jjqIiIiIgcGwtWK0rOSUb6g3QUeJwFALjnN8TUnVORnJNs48iIiIiIHBcLVitKyEgAABR4XISIIrgWhUIoDEJiRqJtAyMiIiJyYCxYrSjKPwoSQQJRko9C92sAAM+CxqjhX8PGkRERERE5LhasVhQmC8O8LvMgQED+w2EBT1YdiTBZmI0jIyIiInJcLFitbGDDgfj2+W9R4HEOAJB5N8TGERERERE5Nhas5aBtjbZo+LgHACA5Dfhq12mcv5lk46iIiIiIHBML1nIyrNVzKHJJBQDEba6KNxYUYNbGv2wcFREREZHjYcFaTsI9GsClOEh1X4AL9u6NYk8rERERkZlYsJaT+MRUCBA0tglwwbmEFBtFREREROSYWLCWk8ZRYRBRrLFNRDEaRYXaKCIiIiIix8SCtZzERISjQ4cEiFAAAESIeOqpBMREhNs4MiIiIiLHwoK1HM0Y+DSad9mEYiEXAgQ8U6e1rUMiIiIicjgsWMvZi607I7fKLwCAdTszcfpKPtIyimwcFREREZHjYMFazhqFNoJ76N8QocClhCJMXpaKwdOSsO1Qrq1DIyIiInIILFjLmUSQoF1UW0BtxgCFCCxZl86eViIiIiIT2HXBunLlSjRq1Ai+vr7w9fVFbGws/vjjD1uHZbYGVTrpTHGlUAC301iwEhEREZXGrgvW6tWrY+HChTh58iROnDiBjh074tlnn8WFCxdsHZpZnmnQUDVbgJIgiKgW5GqjiIiIiIgch10XrL1790aPHj1Qq1Yt1K5dG/PmzYOPjw+OHDli69DMIrhnID1wsdoUVwrcC1yMItc0G0dGREREZP8cpouvuLgYmzZtwv379xEbG2twv4KCAhQUFKjuZ2dnAwDkcjnkcrnV4lG2ZUqb/6T9g1zfbVAIhQhKmwqFJAs5Pn/g37sDEegRaLWYyps5OVcGzpYvwJydgbPlCzhfzpUlX0ePn6xLEEVRtHUQxsTHxyM2Nhb5+fnw8fFBXFwcevToYXD/mTNnYtasWTrb4+Li4OXlVZ6hGpQpz8SchDkQRQmqJ/4MF4Uv7oRNwjv1esNP6meTmIiIiOxZXl4ehgwZgqysLPj6+to6HLIxuy9YCwsLcePGDWRlZeHHH3/EV199hX379qF+/fp699fXwxoREYG7d+9a9Q0vl8uxa9cudO7cGVKptNT9fzz/I6bvno6AtLfgk9MD9eolY+nrzawWT0UwN2dH52z5AszZGXJ2tnwB58u5suSbnZ2NwMBAFqwEwAGGBLi5uaFmzZoAgObNm+P48eNYtmwZvvjiC737u7u7w93dXWe7VCotl3+4prY7uOlgNAxriMGr5sEnpwduJITi3L9FiAyRosg1DQkZCYjyj0KYLMzqMVqbsZyTc5IdKhdTlNd7x54x58rP2fIFnC9nR8/XkWMn67P7glWbQqHQ6EF1JDGhMWgXE4iLKXm4/8ALby9PAwQR6YGLkSP7HRJBgnfav4OYkBiHLPg2xm/ElB1TIEKERJBgXpd5GNhwoK3DIiIiIgdn1wXr+++/j+7duyMyMhI5OTmIi4vD3r17sWPHDluHZrFeNYfi0i7PRxtEAf5pbyLP8yiKXe9i4b6FAOBwBV9yTjKm7pwKESUjTBSiAlN3TkW7qHYOV3gTERGRfbHraa1SU1Px8ssvo06dOujUqROOHz+OHTt2oHPnzrYOzWLSouo6iwgIcIGrvJrGNmXBl5yTXJHhWSwhIwEKUXOuWYWoQGJGoo0iIiIiosrCrntYv/76a1uHYHXF0tsQEQwBLqptIopRJL2ts6+y4HOEHsoo/ygIEFQ9rEBJL3EN/xo2jIqIiIgqA7vuYa2MGteIREbQx2qLCIjICPgcxa53dfY1VPAl5yTj8I3DdtX7GiYLQ0xIjOq+AAHzusxziGKbiIiI7BsL1goWJgvDlOeeRHLkYBRKr0OAgJZBvTG79SaMbzFDtZ+hgm9j/Ea0/7I9Xtz4Itp/2R4b4zdWdAoG3cu7p7rdNqqtw4y/JSIiIvtmUcF68+ZN3Lp1S3X/2LFjmDhxIr788kurBVaZDWw4EH+N/Rmv9S2ZV+7fK5H4el0gftvUAc8GLQYANAtvplHwJeckY+ulrZiyY4pqrKg9jXO9k3sHSTlJqvsp2Sk2jIaIiIgqE4sK1iFDhuCvv/4CAKSkpKBz5844duwYpk6ditmzZ1s1wMoqTBaG7o1jNLYpRODcsaZwKQpE/J143C+8D+BRr+qE3ydojBEtOcY+Lmw6k3wGABDgGQAASMxMRLGi2IYRERERUWVhUcF6/vx5tGrVCgCwceNGxMTE4O+//8batWuxZs0aa8ZXqd1O0y3oFKKAcLemKCwuxJGbR1TTRWlfga9kLxc2nUk6AwB4puYzcHNxg1whx+1s3QvJiIiIiMxlUcEql8tVq0n9+eef6NOnDwCgbt26SE62/dfTjqJ6sCskmjNcQSIB2tSMBgDs+28frqdfN1isAsDsZ2bbxYVNyh7W5uHNEeUfBQC4nnHddgERERFRpWFRwdqgQQN8/vnnOHDgAHbt2oVu3boBAJKSklC1alWrBliZBfm7YtKQAAhqReu45/3RpUFLAMC+6/tUhaA6AQJ8pD4AAH9P/4oI1agiRRHOpZwDADQJb4Jo/5KCmwUrERERWYNFBeuHH36IL774Ah06dMDgwYPRuHFjAMCvv/6qGipApunR1gdrZ4UhsErJS5GRXQyv/GbwUITjVvYtLD20FABUiw1IBAnmd52Pl5u/DAD4+sTXNp/i6kraFeQX5UPmLsNjAY+pCtaE9ASbxURERESVh0ULB3To0AF3795FdnY2/P0f9fCNGjUKXl5eVgvOWYQGSjGitx8++iEd3/+RDQAIwfe4F7gYub7bAADvtH8HjUIboYZ/DYTJwpCUnYSVR1biVNIpvLjxRZsu5brv+j4AQL2gepAIEtWQgITMhAqPhYiIiCofi3pYHzx4gIKCAlWxmpiYiKVLl+LKlSsIDg62aoDOonEtd60tEgTcnQSXokAAwEcHPlIVqwAgCJqrSilEBabsmILfL/9eob2tG+M3YvHBkqm4jt86jo3xGx8NCUjnkAAiIiIqO4sK1meffRbfffcdACAzMxOtW7fG4sWL0bdvX6xcudKqATqLO+m6MwYIcIGrvBoA3emrEjISdPYXIWL81vEVtqCAcgYD9fNP3TkVnlJPAMDt7NsoKCoo9ziIiIiocrOoYD116hTatWsHAPjxxx8REhKCxMREfPfdd1i+fLlVA3QW1YNdNS6+AgARxSiSlkwNpT19VZR/FCSC/pevohYUSMhI0JnBQCEqkF2QDZm7DCJEJGbafo5YIiIicmwWFax5eXmQyWQAgJ07d6J///6QSCRo06YNEhNZoFgiyN8VkzVmDBCREbgUxa53VeNT1aevCpOFYV6XeUaLVmWPbHJOcrlcmBXlH6W6GExJOYaVMwUQERGRtVhUsNasWRNbtmzBzZs3sWPHDnTp0gUAkJqaCl9fX6sG6Ex6tPXBmumh8PIQAAiY9sw7WDtwLfaP2q/3YqqBDQdi/6j9WN5ruU7hKkDAvbx7WHV8Fdp/2R4vbnzRoqECxordMFkYnn7sadV99cKaMwUQERGRtVhUsH7wwQd46623EBUVhVatWiE2NhZASW9r06ZNrRqgs4kIdcOgziVF/y97BLjlNYZrUZDB/cNkYehZt6dOb6tyPOvCfQtVX9ubO1RAuSSsstj98fyPOvsUFhcCAEY2G6lRWLOHlYiIiKzFooL1ueeew40bN3DixAns2LFDtb1Tp074+OOPrRacs+rbQQY3KXA7tQhvLU/D4GlJ2HYo1+gxyt7WJd2XGN1P++ItQ7SXhFWICnyw5wNkyjM12lIubNAvpp/GkIWogCgAwNmUszadI5aIiIgcn0UFKwCEhoaiadOmSEpKwq1btwAArVq1Qt26da0WnLN6kK9AofzRfYUILFmXjrSMIqPHhcnCECwzPq2Y9sVbhhi6oOqu/K7q/r/3/kVuYS48XT1RO7C2xr7/3P0HAHD17tUKm7WgvJXXWGAiIiIyzqKCVaFQYPbs2ahSpQpq1KiBGjVqwM/PD3PmzIFCYXjdezLNrVTdwlShAG6nGS9YAeOzBwDAy01f1ugJNdaONokgQaA0UHVf2bvaKLQRXCWP1qBIzknGZ0c/exR7Bc1aUJ42nNtQprHAREREZDmLCtapU6dixYoVWLhwIU6fPo3Tp09j/vz5+OSTTzB9+nRrx+h0qge7QiLobs/IKTapl1V9PKtEkOC9p95Dj9o9AAB7/9uLgwkHdYpH7d7DW1m3dNp+ucnL8JP6qe6fTj4NAGgS3kRjP0O9s6YMRTBHRfV4puSk6AyPcPQCnIiIyJFYtDTrt99+i6+++gp9+vRRbWvUqBGqVauGMWPGYN68eVYL0BkF+bti0pAALFmXDvUO6zlf34NEACYNCUCPtj4Gjx/YcCDaRbVDYkaianWsrPws/PXfX0jITMCwH4dpLOW6MX4jpuyYAhGiavu2KyVLwj5b71nkF+Vjx7UdOHLzCDzdPJGSk4KIgAicSToDAGgS1kTj/MpeXu2i9V7ePSTnJJvUw1uajfEbVUVkeS9Lm5CZoLGqGPCoALdGLkRERGScRQVrenq63rGqdevWRXp6epmDopIprlrW98CZqw+w4NsM1XbleNaW9T0Q5G/45QuThWkUU3nyPOQX5au1U7KUa2FRIWbunqkqyJTbRYiQQIKJbSfCS+qFv/77C5fvXsZlXMYXq7/A9I7TcfXuVQC6Bauyl1e9VxIAxm8db3JxmZyTjISMBET5R+kUhfouCJu6cyraRbUrlwIyyEt3lgZTxwITERFR2Vk0JKBx48ZYsWKFzvYVK1agUaNGZQ6KSgT5uyLQT6qz3dTxrOoSMnR7CUWImLF7ht7tAKCAAkduHoFcIYe8+NFVYApRgTl75kCEiGq+1RDso3uhl3LWgmW9lmnGrvV1ur6v9bWn01p1fJVqn+ScZPx26bcKGXKglJil2a6+hRyIiIio/FjUw7po0SL07NkTf/75p2oO1sOHD+PmzZvYtm2bVQN0dsrxrAq1mlIiANWCzHvpDH1NX5qpO6diac+ler8SB4A6gXUMHhsmC0NVr6o625XF5YGEAzpf67eLaqfTe7pw30IAUK2qpR0LUL49ngcTD2rcn/709HIbfkBERES6LOphfeqpp3D16lX069cPmZmZyMzMRP/+/XHhwgV8//331o7RqSnHs6pfhFU3yg23UotKvQBLXWlLuRqiLBwNHffXf38ZvWLe0KwF/9z7B1N2TtH5Wv/U7VMGi2rx4X/6hMpCEeITYjQXSy/SOpR4CAAQUSUCAHAz66ZJ5+A0WERERNZh8Tys4eHhmDdvHn766Sf89NNPmDt3LjIyMvD1119bMz5CyXjWdXPD8Xp/PwDAxeuFmLws1aQFBdSVtpTrrGdm6WyXCBI0q9bMYLErQjR6xbyhQnnG7hkQRf29tuZ4s+2b8JJ6ISk7CUsPLTUYh/YwA1Onpbonv4fErES4CC4Y2XwkAOBcyrlSz/HkF0+i3RftOA0WERGRFVhcsFLFCvJ3xdPNvTS2mbqggDp9S7lKBAnmd52PF5u8qLNdOVZzYMOB2DNiD54NfFanzdLGj6oXysqv9fWRCBLUC6oHdxd3k3KRCBIMiBmAJ2o8AQD49MineotDfRdpTdkxBb9f/r3UntAreVcAAE3Dm6rOc+HOBRQrinXOMWXHFI2iW/tCNlPOZw724BIRkbOwaAwr2YaxBQWMzRigj76pr4xtB0q+dm/s0xi/3dO86MmU8aNhsjAEeAUY/EofAHrX7Y2TSSdRUFyAcFk4FnVfhPN3zmPR/kVQiAqNMazKYhoA9vy759HzoTVjQHJOMrZd2abTeytCxPit4/W2qT4+9cr9koK1XVQ7RPtHw1vqjfvy+/jn3j+oE/Ro/O6V1CtGczP1fKaqyGm9iIiIbM2uC9YFCxbg559/xuXLl+Hp6YknnngCH374IerUMXyhT2Wm9wIsifkXYClpT31V2nYA8JP6YXbH2fhgzwcaxZKpq2dpX/glQMCABgPw44Uf8feNv3E25SwA4MWmLyI2MhaxkbHoVbeXqoAGoFFMH75x2OCMAeoXdRmiXmQqe0K9pd5oVq0Z8gvzcTnvMoCSgtVF4oKYkBgcvXUU8XfiNQpW7QuzTD2fJdNxlTatl7EpwYiIiByRWZVO//79jT6emZlZllh07Nu3D2PHjkXLli1RVFSEKVOmoEuXLrh48SK8vb2tei5HoFpQIC5dVbQO7uJrdu9qWT0X8xw61OygtxfWGO35WZXF7rP1nsXOf3Yi7X4a0u6nAQCkEqnGcernUL9taPaD00mnseTQErPHxerrCQWAS6mX0DisMWJCHxasKfF4LuY5AMDZ5LP44cwPAKCKxdiMBuoMLUBgrOg0tJLYtivbIC+W438H/lfmHlwiIiJ7YlalU6VKlVIff/nll8sUkLrt27dr3F+zZg2Cg4Nx8uRJtG/fXu8xBQUFKCgoUN3Pzs4GAMjlcsjlcr3HWELZljXbNEXnVu5oUjsYS+IycepKIa4mFuD4xVxUC3JFkJ9LuZ5bPedAj0AEhgVqbDdFv7r9EFstFolZiahRpQZCZaFIyU5BTkGOxn4L9i1A58c6I1QWarS9QI9AjR5fpf8d/J/e/ce0HoPPj31eaiGrXWhO/3M62ka0RYOgBgCAc8nnIJfL8eP5HzFt9zTVfpOemISGoQ1Ro0pJb/Dp5NOYvH2ywfNJBAmq+VTTeA5/PP+jRg/25Ccmo0FIA0T5RSFUFoowb/1/IMzfO1/jvrLnNbZabMnznJOChMwEVTtK6turepRMQ1bR72tbstW/ZVtxtnwB58u5suTr6PGTdQmi9qXaduyff/5BrVq1EB8fj5iYGL37zJw5E7NmzdLZHhcXBy8vLz1HOKZ7uR744VA9ACJKvlgX0bHBDcRUd7yVxq7lXcPK2yt1to+pNgY1vWqa1EamPBMJ+Qn4PuV7g72aAgRMj5qOy3mXsSl1k2q/kmev9H8GY6qNgZ+rH+YnzoeL4IJ3a7yLBQkLNI5VnsNP6qfadiTriMb51A0MHog2Vdqocriefx3fp+ifGk6AgOeDn4evqy++Svqq1HjV474rv6uKQYCAnlV7IsIjAjfyb2DbvW2q7c8HP6+Kh4jIlvLy8jBkyBBkZWXB19fX1uGQjTlMwapQKNCnTx9kZmbi4EHD4wX19bBGRETg7t27Vn3Dy+Vy7Nq1C507d4ZUqrsaVXlLyyzGizNSNbYJAN4f7of60W7l0ttaXjmn5KSg4+qOOhdy7Rmxp9QeVnVHbh7B8J+H631MIkgwu+Ns1df4KTkpql5ewLSe0D0j9iDEJwRtvmyDrPws1A+qj4tpF3X2/XbAt2hdvbVOjsrzpd5PxQsbXoAIEdte2obHAh7T6FU1RiJI0CK8BY7dPoYXYl5AtH80Fh5YaHT/9QPXY9DGQSYNj5AIEkyrMQ3P93jeJu9rW7D1v+WK5mz5As6Xc2XJNzs7G4GBgSxYCYCdX3SlbuzYsTh//rzRYhUA3N3d4e6uOy2SVCotl3+45dVuae6kF+tsEwHMX5MJiQBMGhKAHm19yuXc1s45IiBC79jWiIAIs9qpGVRT70Vdy3ovQ7PwZhpjQSMCIjTajwiIQL4iXxWDvqv5lfsHewcjKz9Lb7EqESR4PPBxnedH/XwRARHo+HhH7P53N366+BNGtBiB6bunm9TLqxAVOHb7GADg9TavQ+oixaKDiwwWo6E+ofgr4S+Tx/IqRAXuyu/a7H1tS86Ws7PlCzhfzo6eryPHTtbnEAXruHHjsHXrVuzfvx/Vq1e3dTh2Qd+MAUrK+Vlb1veo8AuyLGVsOi1TGbqoq2ednhbFUCQvwsYdGzGw60BVsZmck4x/7v2j93hzZkwY1GgQdv+7Gz9e+BGJmYkmFavajtw8goENB+rk/E77d1Ddtzre/P1NJOUkYeVR3eEWhkgECQKlgWbHQkREVJ7supoRRRFvvPEGNm/ejL179yI6OtrWIdkN1YwB69Kh0NN5plAAe0/loUMzL4cpWo1Np2Wqsha+6jHI5XLU9KqpMSwhISNBb3E5tcNUdK/T3eTztY9uD193X2TlZ+HPf//UeVzZM5yUnaSah1bnnA+nstKXc3JOMooUpi8ooTS742x43ag8Y72JiKhysOuVrsaOHYsffvgBcXFxkMlkSElJQUpKCh48eGDr0OxCj7Y+WDcnHB+8UhWCngWkVv6UafbyrZVBmCwMbSLblMscpMpptNRJBIlZxSoApN1P05kZQb29+V3no2ednnit5WvYP2o/pnSYorOf+gpj2jkbK6zfe+o9jdXMRrcaDQBwEVzQvXZ3k3MgIiKqKHbd9bZyZclXmR06dNDYvnr1agwfPrziA7JDQf6u6NDcFXn5ot7eVkccHmDPDA07MLc4NqenNkwWhh51emDhvoUmrzCmb35a9cJafTGGMFkYfrn0C5JyklQLNxAREdkTu65gHGQCA7vQo60PWtb3wN5TeVj5U6bGY5Yu30r6WWO8bWkFpTZzC+XS9tceftEqohW2XNyCE7dPoCZMm0qMiIioorCCqUSC/F3RoZkXvvg502rLt5J+ZR1va0lPrbmFsjn7t6zeElsubsHx28dNnvuWiIioorCKqWT0Ld/ap50Pe1ftkCU9teYWyqbu36p6KwDA2ZSzeD7qeZPbJyIiqgh2fdEVWaZHWx+smxuOji1KrvY+/28BTl15gLQM868ap/JVnheImSPaPxpVvaqisLgQNwpu2DQWIiIibSxYK6kgf1eMec4fLi7AP7fkeGtZmlPOGECmEQRB1ct6PPs4UnJSDO6bnJOMwzcOIzknuaLCK1cpOSm4lndNJ+fKlicRkSPj98SVWHGxiGK1BbE4YwAZ4yopeU8czT6Kjqs74p327yAmJAZR/lEASmY2OH/nvGpeWOUiBdr7lNdt9V7o5JzkMrWjPF49ny9Wf6HKp6x5GuoxNyVuc48193kJ9LDOwhBlycWa1OMw9FwUyYtUf5Sor3Bn7nNa3tvLEoP6saa8xobaNPe5NRQzkbWxaqnEbqXqDgHgjAGkT3JOMrZe2aq6rxAVWLhvIQBoLFOrztA+5XFbvWg8m3wW/zvwP514tI9Vf1x5XyJI0Ld+X2y5uEVnMQb1fMqSp6ECV70Ittax6vub2v7kJyYjNy8XKTkpcJW6WlT4lyUXa94+kHBAZ5U3Y8+FoT9KTHlOy3t7WWIw9zU25Q8yS847r8s8DGw4UOffEJE1CGIlnzsqOzsbVapUQVZWFnx9fa3Wrlwux7Zt29CjRw+7Xe84LaMIg6clac4YIADr5oZbVLA6Qs7W5Ez5Hr5xGC9ufNHWYVAlpf1Hj/YfFKYcb8nyxVSxz7VEkGD/qP1W62ktr89vckwcw1qJKWcMkKi9yqFVXXDzjpwXYJEGfSt4EVmL+PA/9fvmHk+WqcjnWn31PSJr4ydUJadcvnXKsAC4SICku8V4a3kaBk1LwoZd2Th9JZ/FK6nmhWXRSkSWMrb6HlFZcSCjEwjyd0Xj2h4ay7aKIvDF5kwAJcMEXuvrh9qRbqge7MrxrU5qYMOBiK0Wi407NsI72huLDy02OLauYUhDxN+JL3Uco7VuG2LJWFj1MazK8X73E+5r5FyWPE1hrWPLo31zVeS59J1bEASd8ciG4ivLPuWtLDHYKn59Y1h54RWVF1YmTuJWapHBX2UKreJ10pAA9GjrU2Gxkf0IlYWipldN9GjeA882eFa1qAEAnQUO2kS2Qa+6vfTuY+3b6kWjejFpSZthsjBMenKS6n6gRyC2pW7TydnSPA0VuKbEbe6x5j4v1vojoyLPZSyGeV3mqRbfMPZcFMmLdP4QM/c5Le/tZYnB3OfdlD/IzD2vpctUE5mKF11ZyNEuyNF3AZYhEgmwbo7uhVmOlnNZOVu+gH3nnJyTXC4fjOWRs3qsgHkf6OYea+7zcjP9Jjbu2IiBXQfCVepq8R8TZcnFWre1YzD0XKi/xnfz71r8nJb39rLEoM6U19hQm6bsU1GFKS+6InXsYXUSqiVb16VrDA3Qh1NfkT0yd1laW9KOtSzL6ZZ2rLnPi7IXPVQWCqlUavBcptwujbFcrHXb2PmsvU95b7fWsaa+xobatPS8ROWJFYkT6dHWBy3re+B2WhGuJBZg1S9ZeotXAUBGTrHqYqxbqUWoHuwKP44SICIiIhtgwepkgvxLLqpqUtsDHVt46y1eRQBzvr73cDRTyX2JAEx4oYqNoiYiIiJnxoLViWkXr8cvPcD/fshQPa4+3FUhAss2ZGF4e/sa10hERESVHyddJAAlxWtYVePFqEIEsvLcKygiIiIiohIsWEmlerArJILhxyUCUMWrAEDJrANcdICIiIgqAocEkIr2TALCw+JVOfFZQBUJ0nPdsWl3Lr75LQcKkfO2EhERUfljwUoa1GcSqBZU8vY4/28BPvzuHu5mKrDlZC3gZI5qf4UILFmXjpb1PTgNFhEREZULVhikQ3kxllLM44C82PD+CgWw91QeOjTzYtFKREREVscxrFSqW6lFKG09tJU/ZWLwtCRsO5RbMUERERGR02B3GJVKeTFWacu6KkRgcVw6PD0ExDzmzt5WIiIisgr2sFKplBdjKWcQkAjA//Xzw+gBfjr7imLJogODpyVhw65sziRAREREZcYuMDJJj7Y+aFLbFZu3HkK/Xm0RHuSBtIwifPFzpt6eV4UIfLE5EwBnEiAiIqKyYQ8rmSzIzwXVA3IR5OdScl/Z81rKu0g5k4Cyp5VzuBIREZE57L6Hdf/+/fjoo49w8uRJJCcnY/Pmzejbt6+tw6KHlNNgXfivAHO+uWfw4izlTAIKhYhVW7JUc7i+1tcPtSPdUD1Yc2aCtIwi3EotMnk7ERERVV52/4l///59NG7cGCNHjkT//v1tHQ7pEeTvig7NXZGXL6oWHdBn5U+ZGvcNDRvYdigXi+PSIYolixdM1rOdwwyIiIich90XrN27d0f37t1tHQaZQH3RgSuJBVj1S5bB4lWbQgQWr02HvEiBZRsyVdtFEfjf2nQ8KFTg002ZGvtzwQIiIiLnUOk+6QsKClBQUKC6n52dDQCQy+WQy+VWO4+yLWu2ae9MydnPB/DzcUGDaC+0a+KO/acf4MstOQb3VycCGsWqOvViVUmhABKT8+Hn4460zGKN1bmUt5XjbS3B19g5OFvOzpYv4Hw5V5Z8HT1+si5BFEubEt5+CIJQ6hjWmTNnYtasWTrb4+Li4OXlVY7RkT45+VKs3tcAIgS1rSIAQe3/LSWie6ME5OS74dDV8IfnUL6dBQgQ8UTt2wjxfQA/7wLIPPjLj4jIUeTl5WHIkCHIysqCr6+vrcMhG6t0Bau+HtaIiAjcvXvXqm94uVyOXbt2oXPnzpBKpVZr155ZmvP2w3lYtuHRhVYje8tQO1KKqzfk+Oa3nFIXJLAGiQBMeKEKusWa/kdLclo+ft1+DH26tUJYkIfVYlHvDS5LD3B54Pu68ufsbPkCzpdzZck3OzsbgYGBLFgJQCUcEuDu7g53d3ed7VKptFz+4ZZXu/bM3Jx7t6+CNg29HxVpD8ectqgPdG4t0zvDgCAAE17ww7INmXq3L12faVbMChFYuiELPt6uiHms5P2hnG1A/bYytm2HcrEkLgMKsRa2nMyw6AIvfTMalLSbXuosCbbG93Xl52z5As6Xs6Pn68ixk/XZzyckVWpB/voLMn0zDEgkwKTBJQWiq4tEZ3tYoGVvW+UqXIYoC8hgfxfVbATAowu8HqsmxYMC0WCRCzwqUpUXnYmiVrtr01WDFrRnSVAvXg21by2cHoyIiByJ3X9S5ebm4p9//lHdv379Os6cOYOAgABERkbaMDKyJvUZBtR7YfVtT8sogkSA3qEEwsMhsZYMdFEvIHUeUwBjP7pTMtXWw20idKfjUvaemtquvn0MtW+q0uaw1S6mOT0YERHZO7svWE+cOIGnn35adX/SpEkAgGHDhmHNmjU2iorKg7FeWPXtyhW21HteX3vWD3VquGnMEmDu1FqlURbB6vWoeu+req9smc6j1f7iuHR4egg6Qxn0FaNXbxToXZhBfTu02uf0YEREZO/s/hOqQ4cOcKDrwqiCGOqRVQryd0WT2h7o2MK71FW4SqM+94A+CgXw+c8ZVilW9dE3lMHUYrS0nl3g0SpkHZp5wY8drUREZIfsvmAlMsRQj6z2PtpjZNWHDRgbQiAA6Nb4Orp1aoE3P75ndDaDc/8Umhy3IADTR1bFnfQii3uATS1GTbXyp0x88XMmJrxQxWptEhERWQsLVnIK2j2yAHRuqw8hkEiACQOrQJGRibo13DSGIJgyTlZ9mIJ2u5MGB6BDc28AQMcW3jrnLss43LJQiMCyDVkY3p5X5hIRkX1hwUpOQ99YWPXbyiEEykLWz0fEtm0lj+srePeeysPKnzJ1zjNmgB+eaualal+7Xe3z6js3gDIPZTBEWUxLJNCJXyEC11L8kJZZjPAgFq5ERGQfWLASqVEvarWXBdQueDs088IXP2dqDBWQSKBRrBo6trRzAzA6lMEQYz276hemKWdb0I4fAA5cqY5DM1M5ewAREdkNFqxEFtI3W8GkwQFWvdre0FCG0opRwHjPrr741WnPTsAZBIiIyJb4KURUBqXNVmAN+oYylFaMGjrWUPz6hjcoZyfgXK1ERGRrElsHQOTolAVkRfdCWuu8Qf6u6NDMCxJB/+PK3ta/Tt5HWkaRwXbSMopw+kq+RfuYciwRETkv9rAS0aPhAXpW6gI0e1v1LSFraMEC9QUO1FcC014hTLnogiAAowwsUat+25QiXX3FL3OP1T6eQyKIiGyLv4WJCEDJ8IAmtV2x9uej2H4uWu/FXeYuM6ssXoP9XTRWAlP22sqLFVi+IfPRKmJG2lcu4GCoaDZUQJe21G1aZjFu3vNBWmYxpK6C3gJc/ZjSlr41tdAuS0FckcU0C3fHxtePKgu+e4lIJcjPBbVDM1G3XhUs21j2ZW2NFbiiCCxbr/8xvfub0Kax45THLokrWUr3QYGIqzcK8OWWLIhiLWw+kaqzv/IY5QVoqelFD/c30kusdl7tYll9dTJ97QClF77GerP17a99W170qEBXn7pM33mNFe7qTCnizS3uDd3WLrpMactQzqa0Y6jIM2V/W/0Ro1yxbvvhPCzbYPnrZ8q5DOVCZG18dxGRjm6xXmjTsOzL2tojhQiMWXRHZ7uxFPUtj6ssZPMLFVixKVNvO9rFsr5CWyECS9alo2V9Dxy/mK/RE13qssBabRraX7n9UQFdC1tOpqqKXeWsE8ZeZ+2ZIwDjBbR2Ua5vKWFDxb36bfX4tQv03w/l4vtt2Tr7aR9fQjNnU3vkLd3flDwN7W/uHyLax47sLcOtZD/s2Jml862Gqa+foWJUfWhPad9eEFmTIIqV6aNIV3Z2NqpUqYKsrCz4+vparV25XI5t27ahR48ekEqdY4J1Z8vZ2fIF9Oe87VCu3qmvyLpe7CbDD9tzbB2GyUorph2Bo+dQUfErx5YH+7tg7mrDf8BKJMC6OeFW62ktr89vckzsYSUio9Sn7jK0hKyhBQu0CQIw4QU/LFMbt6rcPn1kVdxJL9LbflmWq9VoB/ZboDhSsQrY7/NoDkfPoaLiNza2XJ1CUTJPNIcGUHngu4qISmVsCVntuWDV99Fe4GDS4JKvDF1dJDoLLnRo7g0ABttX3jZUNBsqoNWP9XATMO6jO3pnQhAe/o/68SEBLmYPibBWoU3kaCQSqP69EVkb31lEZBZ9CxkY2sfQAgfGFlww1n5pRbP6bX0rewHQWZ1sZC8ZMpJPoV+vtpC6uuocr748rrFCVtlL3ODh+EBTVieTSKCzYIN6e4DxYtyU4t3cAlrfuSwp3E1R1pgFoeQPDUUZczYUk7X2t+UfMYa+1bBW28Cj94q1V/ojUsd3FhGVK0OrbZW2Cpc5bZZWQKvTLpb9fERs25aLID8XSKW6MRkqrrULWfVeYn0x6Sve0zKK8MXPmRo9vqUVvsaW3zW0v/pteVERNm89BP+wZvhma47e5X31nUs9X1MKaFO2mxqz8ra+Hnt9SxebkrMpPfKmDIExdclkU/Kx9A8RnWP1zOyg/q2GuX8AaTP0HmWxSuWJF11ZiBfkVP6cnS1fgDmbm3NaRlGZP6zVL2pTHzZRXtTzzcwVzIpfPV9Af6Fi6DmxxnNlaTuGcjaUg6Hzmbu/uc+poedL/byGbqsfm5SWj81bD6Ffr7YID/IwKxd9+xga2lPeeNEVqeOfQ0REFipLL7GSseER5c3c+M0ZDlLWc5kaQ1mPL62tsu5vbjymnLfU18DPBdUDSr41MLVNY/sYGtpDVJH4riMisjFrFXNE5YXvUbI1ia0DICIiIiIyhgUrEREREdm1St+/r7ymLDs726rtyuVy5OXlITs726kuTnGmnJ0tX4A5O0POzpYv4Hw5V5Z8lZ/blfzacDJRpS9Yc3JKVo+JiIiwcSRERERkrpycHFSpUsXWYZCNVfpprRQKBZKSkiCTySAoJ5azguzsbERERODmzZtOM92Gs+XsbPkCzNkZcna2fAHny7my5CuKInJychAeHg6JhCMYnV2l72GVSCSoXr16ubXv6+vr0L8QLOFsOTtbvgBzdgbOli/gfDlXhnzZs0pK/JOFiIiIiOwaC1YiIiIismssWC3k7u6OGTNmwN3d3dahVBhny9nZ8gWYszNwtnwB58vZ2fIl51DpL7oiIiIiIsfGHlYiIiIismssWImIiIjIrrFgJSIiIiK7xoKViIiIiOwaC1YLffrpp4iKioKHhwdat26NY8eO2Tokq1iwYAFatmwJmUyG4OBg9O3bF1euXNHYJz8/H2PHjkXVqlXh4+ODAQMG4M6dOzaK2LoWLlwIQRAwceJE1bbKmO/t27fx4osvomrVqvD09ETDhg1x4sQJ1eOiKOKDDz5AWFgYPD098cwzz+DatWs2jLhsiouLMX36dERHR8PT0xOPP/445syZo7FGuSPnvH//fvTu3Rvh4eEQBAFbtmzReNyU3NLT0zF06FD4+vrCz88Pr7zyCnJzcyswC/MYy1kul+Pdd99Fw4YN4e3tjfDwcLz88stISkrSaMORci7tNVb3+uuvQxAELF26VGO7I+VLpI0FqwU2bNiASZMmYcaMGTh16hQaN26Mrl27IjU11dahldm+ffswduxYHDlyBLt27YJcLkeXLl1w//591T5vvvkmfvvtN2zatAn79u1DUlIS+vfvb8OoreP48eP44osv0KhRI43tlS3fjIwMtG3bFlKpFH/88QcuXryIxYsXw9/fX7XPokWLsHz5cnz++ec4evQovL290bVrV+Tn59swcst9+OGHWLlyJVasWIFLly7hww8/xKJFi/DJJ5+o9nHknO/fv4/GjRvj008/1fu4KbkNHToUFy5cwK5du7B161bs378fo0aNqqgUzGYs57y8PJw6dQrTp0/HqVOn8PPPP+PKlSvo06ePxn6OlHNpr7HS5s2bceTIEYSHh+s85kj5EukQyWytWrUSx44dq7pfXFwshoeHiwsWLLBhVOUjNTVVBCDu27dPFEVRzMzMFKVSqbhp0ybVPpcuXRIBiIcPH7ZVmGWWk5Mj1qpVS9y1a5f41FNPiRMmTBBFsXLm++6774pPPvmkwccVCoUYGhoqfvTRR6ptmZmZoru7u7hu3bqKCNHqevbsKY4cOVJjW//+/cWhQ4eKoli5cgYgbt68WXXflNwuXrwoAhCPHz+u2uePP/4QBUEQb9++XWGxW0o7Z32OHTsmAhATExNFUXTsnA3le+vWLbFatWri+fPnxRo1aogff/yx6jFHzpdIFEWRPaxmKiwsxMmTJ/HMM8+otkkkEjzzzDM4fPiwDSMrH1lZWQCAgIAAAMDJkychl8s18q9bty4iIyMdOv+xY8eiZ8+eGnkBlTPfX3/9FS1atMDzzz+P4OBgNG3aFKtWrVI9fv36daSkpGjkXKVKFbRu3dphc37iiSewe/duXL16FQBw9uxZHDx4EN27dwdQOXNWMiW3w4cPw8/PDy1atFDt88wzz0AikeDo0aMVHnN5yMrKgiAI8PPzA1D5clYoFHjppZfw9ttvo0GDBjqPV7Z8yfm42joAR3P37l0UFxcjJCREY3tISAguX75so6jKh0KhwMSJE9G2bVvExMQAAFJSUuDm5qb6pa8UEhKClJQUG0RZduvXr8epU6dw/PhxnccqY77//fcfVq5ciUmTJmHKlCk4fvw4xo8fDzc3NwwbNkyVl773uKPm/N577yE7Oxt169aFi4sLiouLMW/ePAwdOhQAKmXOSqbklpKSguDgYI3HXV1dERAQ4PD5AyXj0N99910MHjwYvr6+ACpfzh9++CFcXV0xfvx4vY9XtnzJ+bBgJYPGjh2L8+fP4+DBg7YOpdzcvHkTEyZMwK5du+Dh4WHrcCqEQqFAixYtMH/+fABA06ZNcf78eXz++ecYNmyYjaMrHxs3bsTatWsRFxeHBg0a4MyZM5g4cSLCw8Mrbc5UQi6XY+DAgRBFEStXrrR1OOXi5MmTWLZsGU6dOgVBEGwdDlG54JAAMwUGBsLFxUXnKvE7d+4gNDTURlFZ37hx47B161b89ddfqF69ump7aGgoCgsLkZmZqbG/o+Z/8uRJpKamolmzZnB1dYWrqyv27duH5cuXw9XVFSEhIZUqXwAICwtD/fr1NbbVq1cPN27cAABVXpXpPf7222/jvffew6BBg9CwYUO89NJLePPNN7FgwQIAlTNnJVNyCw0N1blotKioCOnp6Q6dv7JYTUxMxK5du1S9q0DlyvnAgQNITU1FZGSk6vdYYmIiJk+ejKioKACVK19yTixYzeTm5obmzZtj9+7dqm0KhQK7d+9GbGysDSOzDlEUMW7cOGzevBl79uxBdHS0xuPNmzeHVCrVyP/KlSu4ceOGQ+bfqVMnxMfH48yZM6qfFi1aYOjQoarblSlfAGjbtq3OVGVXr15FjRo1AADR0dEIDQ3VyDk7OxtHjx512Jzz8vIgkWj+unNxcYFCoQBQOXNWMiW32NhYZGZm4uTJk6p99uzZA4VCgdatW1d4zNagLFavXbuGP//8E1WrVtV4vDLl/NJLL+HcuXMav8fCw8Px9ttvY8eOHQAqV77kpGx91ZcjWr9+veju7i6uWbNGvHjxojhq1CjRz89PTElJsXVoZTZ69GixSpUq4t69e8Xk5GTVT15enmqf119/XYyMjBT37NkjnjhxQoyNjRVjY2NtGLV1qc8SIIqVL99jx46Jrq6u4rx588Rr166Ja9euFb28vMQffvhBtc/ChQtFPz8/8ZdffhHPnTsnPvvss2J0dLT44MEDG0ZuuWHDhonVqlUTt27dKl6/fl38+eefxcDAQPGdd95R7ePIOefk5IinT58WT58+LQIQlyxZIp4+fVp1RbwpuXXr1k1s2rSpePToUfHgwYNirVq1xMGDB9sqpVIZy7mwsFDs06ePWL16dfHMmTMav8sKCgpUbThSzqW9xtq0ZwkQRcfKl0gbC1YLffLJJ2JkZKTo5uYmtmrVSjxy5IitQ7IKAHp/Vq9erdrnwYMH4pgxY0R/f3/Ry8tL7Nevn5icnGy7oK1Mu2CtjPn+9ttvYkxMjOju7i7WrVtX/PLLLzUeVygU4vTp08WQkBDR3d1d7NSpk3jlyhUbRVt22dnZ4oQJE8TIyEjRw8NDfOyxx8SpU6dqFC+OnPNff/2l99/tsGHDRFE0Lbd79+6JgwcPFn18fERfX19xxIgRYk5Ojg2yMY2xnK9fv27wd9lff/2lasORci7tNdamr2B1pHyJtAmiqLbUCxERERGRneEYViIiIiKyayxYiYiIiMiusWAlIiIiIrvGgpWIiIiI7BoLViIiIiKyayxYiYiIiMiusWAlIiIiIrvGgpWIiIiI7BoLViJyOoIgYMuWLbYOg4iITMSClYgq1PDhwyEIgs5Pt27dbB0aERHZKVdbB0BEzqdbt25YvXq1xjZ3d3cbRUNERPaOPaxEVOHc3d0RGhqq8ePv7w+g5Ov6lStXonv37vD09MRjjz2GH3/8UeP4+Ph4dOzYEZ6enqhatSpGjRqF3NxcjX2++eYbNGjQAO7u7ggLC8O4ceM0Hr979y769esHLy8v1KpVC7/++mv5Jk1ERBZjwUpEdmf69OkYMGAAzp49i6FDh2LQoEG4dOkSAOD+/fvo2rUr/P39cfz4cWzatAl//vmnRkG6cuVKjB07FqNGjUJ8fDx+/fVX1KxZU+Mcs2bNwsCBA3Hu3Dn06NEDQ4cORXp6eoXmSUREphFEURRtHQQROY/hw4fjhx9+gIeHh8b2KVOmYMqUKRAEAa+//jpWrlypeqxNmzZo1qwZPvvsM6xatQrvvvsubt68CW9vbwDAtm3b0Lt3byQlJSEkJATVqlXDiBEjMHfuXL0xCIKAadOmYc6cOQBKimAfHx/88ccfHEtLRGSHOIaViCrc008/rVGQAkBAQIDqdmxsrMZjsbGxOHPmDADg0qVLaNy4sapYBYC2bdtCoVDgypUrEAQBSUlJ6NSpk9EYGjVqpLrt7e0NX19fpKamWpoSERGVIxasRFThvL29db6itxZPT0+T9pNKpRr3BUGAQqEoj5CIiKiMOIaViOzOkSNHdO7Xq1cPAFCvXj2cPXsW9+/fVz1+6NAhSCQS1KlTBzKZDFFRUdi9e3eFxkxEROWHPaxEVOEKCgqQkpKisc3V1RWBgYEAgE2bNqFFixZ48sknsXbtWhw7dgxff/01AGDo0KGYMWMGhg0bhpkzZyItLQ1vvPEGXnrpJYSEhAAAZs6ciddffx3BwcHo3r07cnJycOjQIbzxxhsVmygREVkFC1YiqnDbt29HWFiYxrY6derg8uXLAEqu4F+/fj3GjBmDsLAwrFu3DvXr1wcAeHl5YceOHZgwYQJatmwJLy8vDBgwAEuWLFG1NWzYMOTn5+Pjjz/GW2+9hcDAQDz33HMVlyAREVkVZwkgIrsiCAI2b96Mvn372joUIiKyExzDSkRERER2jQUrEREREdk1jmElIrvCUUpERKSNPaxEREREZNdYsBIRERGRXWPBSkRERER2jQUrEREREdk1FqxEREREZNdYsBIRERGRXWPBSkRERER2jQUrEREREdm1/wdC8vANmyi5hAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot\n",
        "fig, (ax_a, ax_l) = plt.subplots(2, sharex=True)\n",
        "\n",
        "ax_a.set_xlabel(\"Epoch\")\n",
        "ax_a.set_ylabel(\"Accuracy %\")\n",
        "ax_a.plot(val_accuracies, marker=\".\", c=\"forestgreen\")\n",
        "ax_a.plot(train_accuracies, marker=\".\", c=\"royalblue\")\n",
        "\n",
        "ax_l.set_xlabel(\"Epoch\")\n",
        "ax_l.set_ylabel(\"Loss\")\n",
        "ax_l.plot(val_losses, marker=\".\", c=\"forestgreen\")\n",
        "ax_l.plot(train_losses, marker=\".\", c=\"royalblue\")\n",
        "\n",
        "fig.legend(title=\"Data Type\", labels=[\"Training\", \"Validation\"], fontsize=\"small\", loc=3, bbox_to_anchor=(0.925, 0.425))\n",
        "fig.align_labels()\n",
        "plt.show()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "ZwA6bbIkJp0W",
        "outputId": "de4be16d-4e55-4bc2-8c91-d7457a63bec7"
      }
    }
  ]
}
